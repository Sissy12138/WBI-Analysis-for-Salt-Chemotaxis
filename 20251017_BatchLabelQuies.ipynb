{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86fa1525",
   "metadata": {},
   "source": [
    "## 标记静息状态Quiescence\n",
    "适用于10.16之前跑的旧数据，单独将运动数据输入打印是否有静息状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f72032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import heapq\n",
    "from scipy.ndimage import label\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.ndimage import grey_opening,grey_closing\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from matplotlib.lines import Line2D\n",
    "import networkx as nx\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy import ndimage\n",
    "from scipy.interpolate import splprep, splev\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "# 设置字体为 SimHei（黑体）\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 设置字体为 SimHei\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827991a7",
   "metadata": {},
   "source": [
    "### 输入总文件夹，读取运动处理文件，输出quies的标记图片\n",
    "可以用于快速判断哪些文件存在quiescent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be18e5e6",
   "metadata": {},
   "source": [
    "### 函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9828816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_low_spd(df, speed_thr = 0.01, dspeed_thr=0.002, ang_thr = 0.02):\n",
    "\n",
    "    speed = df['speed'].values\n",
    "    ang_spd = df['ang_velocity'].values\n",
    "    # 高斯平滑\n",
    "    sigma = 100   # 平滑参数，可调\n",
    "    speed_smooth = gaussian_filter1d(speed, sigma=sigma)\n",
    "\n",
    "    # speed 的导数，再平滑\n",
    "    dspeed = np.gradient(speed)  # 一阶导数\n",
    "    dspeed_smooth = gaussian_filter1d(dspeed, sigma=sigma)\n",
    "\n",
    "    # 头部摆动的角速度\n",
    "    # dang_velocity = np.gradient(ang_spd)\n",
    "\n",
    "    # 双条件筛选\n",
    "    mask = (np.abs(speed_smooth) < speed_thr) & (np.abs(dspeed_smooth) < dspeed_thr) & (np.abs(ang_spd) < ang_thr)\n",
    "    df['quies'] = 0\n",
    "    df.loc[mask,'quies'] = 1\n",
    "    return df\n",
    "def get_turn_interval(df, col_name):\n",
    "    # labels打印矩形\n",
    "    labels = df[col_name].values\n",
    "    n = len(labels)\n",
    "    # 找出连续的 label==1 区间\n",
    "    turn_intervals = []\n",
    "    in_turn = False\n",
    "    start = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        if labels[i] == 1 and not in_turn:\n",
    "            # turn开始\n",
    "            start = i\n",
    "            in_turn = True\n",
    "        elif labels[i] != 1 and in_turn:\n",
    "            # turn结束\n",
    "            end = i - 1\n",
    "            turn_intervals.append((start, end))\n",
    "            in_turn = False\n",
    "\n",
    "    # 如果最后一个点也是turn状态\n",
    "    if in_turn:\n",
    "        turn_intervals.append((start, n - 1))\n",
    "    return turn_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fba8f01",
   "metadata": {},
   "source": [
    "### 单文件处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317bc9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quies_single_f(p_f_all, file, p_output):\n",
    "    # # 重新读取df_merged_2\n",
    "    f_matched = [f for f in os.listdir(os.path.join(p_f_all, file)) if '_mot_vid_mid.pkl' in f]\n",
    "    if not len(f_matched):\n",
    "        f_matched = [f for f in os.listdir(os.path.join(p_f_all, file)) if '_mot_vid_mid.csv' in f]\n",
    "        df_merged_2 = pd.read_csv(os.path.join(p_f_all, file) +'\\\\'+f_matched[0])\n",
    "    else:\n",
    "        df_merged_2 = pd.read_pickle(os.path.join(p_f_all, file) +'\\\\'+f_matched[0])\n",
    "    \n",
    "\n",
    "    df = cal_low_spd(df_merged_2, speed_thr = 0.01, dspeed_thr=0.002, ang_thr=10)\n",
    "    quiet_ints = get_turn_interval(df, 'quies')\n",
    "    # 绘图\n",
    "    fig,ax = plt.subplots(3,1,figsize=(20,4), sharex=True)\n",
    "    for start, end in quiet_ints:\n",
    "        ax[0].axvspan(start, end, color='blue', alpha=1)  # alpha控制透明度\n",
    "    # 平滑\n",
    "    # 平滑turn\n",
    "    opened = ndimage.binary_closing(df['quies'].values, structure=np.ones(100))\n",
    "    # 再进行开操作（先腐蚀后膨胀）：去除小的噪声点\n",
    "    closed = ndimage.binary_opening(opened, structure=np.ones(200))\n",
    "    # 将结果转换为整数并添加到 DataFrame\n",
    "    df.loc[:,'quies_pc'] = closed.astype(int)\n",
    "    quiet_pc_ints = get_turn_interval(df, 'quies_pc')\n",
    "    for start, end in quiet_pc_ints:\n",
    "        ax[1].axvspan(start, end, color='blue', alpha=1)  # alpha控制透明度\n",
    "    ax[1].set_title('quies_pc')\n",
    "    ax[2].plot( gaussian_filter1d(df['speed'], sigma=50))\n",
    "    ax[0].set_title(f'{file}_Quiescence')\n",
    "    plt.grid(True)\n",
    "    output_path = p_output+f'\\\\{file}quis_pc_check.png'  # 替换为你的目标文件夹路径\n",
    "    plt.savefig(output_path, bbox_inches='tight', dpi=300)\n",
    "    # df_merged_3 = df.copy()\n",
    "    # df_merged_3.to_pickle(os.path.join(p_f,basename+ '_mot_vid_mid.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d459f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_f_all = r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\done'\n",
    "key_word = ''\n",
    "nokey_word = '*'\n",
    "path_output = f'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\quies_plot'\n",
    "files = [f_p for f_p in os.listdir(p_f_all) if ('redo' not in f_p)&\n",
    "              ('done' not in f_p)&\n",
    "             os.path.isdir(os.path.join(p_f_all,f_p))&\n",
    "             (key_word in f_p)&(nokey_word not in f_p)]\n",
    "print(files)\n",
    "# files = get_inbtw_file(files, start_str = '20241201', end_str='20250830')\n",
    "for file in files:\n",
    "    print(f'=====开始处理{file}======')\n",
    "    df_p_cor = plot_quies_single_f(p_f_all, file, path_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e1d0d6",
   "metadata": {},
   "source": [
    "## 标记静息全为0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe4c633",
   "metadata": {},
   "source": [
    "确定没有静息状态的文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43428b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_quiet_trival(p_f):\n",
    "    folder_name = os.path.basename(os.path.normpath(p_f))\n",
    "\n",
    "    # 激光段运动数据\n",
    "    files = [f for f in os.listdir(p_f) if '_mot_midline_cut' in f]\n",
    "    # 优先找 .pkl\n",
    "    pkl_files = [f for f in files if f.endswith('.pkl')]\n",
    "    csv_files = [f for f in files if f.endswith('.csv')]\n",
    "    if len(pkl_files):\n",
    "        f_mot_mid_cut = pkl_files[0]   # 如果有多个 .pkl，只取第一个\n",
    "        df_mot_midline_cut = pd.read_pickle(os.path.join(p_f,f_mot_mid_cut))\n",
    "    elif len(csv_files):\n",
    "        f_mot_mid_cut = csv_files[0]   # 没有 .pkl，但有 .csv\n",
    "        df_mot_midline_cut = pd.read_csv(os.path.join(p_f,f_mot_mid_cut))\n",
    "    else:\n",
    "        raise FileNotFoundError(\"没有找到符合条件的 _mot_midline_cut 文件\")\n",
    "    df_mot_midline_cut['quies'] = 0\n",
    "    df_mot_midline_cut['quies_pc'] = 0\n",
    "    f_cut_name = folder_name+'_mot_midline_cut.pkl'\n",
    "    df_mot_midline_cut.to_pickle(os.path.join(p_f, f_cut_name))\n",
    "\n",
    "    # 激光对时数据\n",
    "    mot_mid_pkl = [f for f in os.listdir(p_f) if 'MotionMidlineMatchVol.pkl' in f]\n",
    "    mot_mid_csv = [f for f in os.listdir(p_f) if 'MotionMidlineMatchVol.csv' in f]\n",
    "    if len(mot_mid_pkl):\n",
    "        print('read pickle')\n",
    "        df_mot_vol = pd.read_pickle(os.path.join(p_f, mot_mid_pkl[0])).reset_index(drop=True)\n",
    "    elif len(mot_mid_csv):\n",
    "        df_mot_vol = pd.read_csv(os.path.join(p_f, mot_mid_csv[0]))\n",
    "    else:\n",
    "        print('No df_mot_midline')\n",
    "    df_mot_vol['quies'] = 0\n",
    "    df_mot_vol['quies_pc'] = 0\n",
    "    f_vol_name = folder_name+'_MotionMidlineMatchVol.pkl'\n",
    "    df_mot_vol.to_pickle(os.path.join(p_f, f_vol_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ebe1f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20241219_0g-ov_05', '20241219_4.5g-ov_06', '20250115_4.5g-24d-ov_08', '20250116_4.5g-ov_05', '20250221_0g-ov-27.5d_6', '20250225_0g-ov-24d_003', '20250225_0g-ov-24d_004', '20250225_4.5g-ov-24d_002', '20250225_4.5g-ov-24d_016', '20250312_4.5g-24d-4h_007', '20250319_1g-23d-4h_001', '20250409_5g-ov-24d_011', '20250422_3g-lg9624-3h-24.5d_004', '20250422_4.5gNa-lg9624-6h-24d_015', '20250425_1g-9624-ov-24h_001', '20250609_lg9624-1g-00225-23.5d-ov_008', '20250609_lg9624-1g-00225-24d-ov_006', '20250805_lg9624-1gNa-24d-ov_009', '20250805_lg9624-1gNa-24d-ov_011', '20250805_lg9624-1gNa-24d-ov_013', '20250823_lg9624-1gNa-24.5d-1h-new_020', '20250823_lg9624-1gNa-24.5d-4h-new_016', '20250823_lg9624-1gNa-24d-1h-new_013', '20250823_lg9624-1gNa-24d-1h-old_006', '20250823_lg9624-1gNa-24d-4h-new_022']\n",
      "=====开始处理20241219_0g-ov_05======\n",
      "read pickle\n",
      "=====开始处理20241219_4.5g-ov_06======\n",
      "read pickle\n",
      "=====开始处理20250115_4.5g-24d-ov_08======\n",
      "read pickle\n",
      "=====开始处理20250116_4.5g-ov_05======\n",
      "read pickle\n",
      "=====开始处理20250221_0g-ov-27.5d_6======\n",
      "=====开始处理20250225_0g-ov-24d_003======\n",
      "read pickle\n",
      "=====开始处理20250225_0g-ov-24d_004======\n",
      "=====开始处理20250225_4.5g-ov-24d_002======\n",
      "read pickle\n",
      "=====开始处理20250225_4.5g-ov-24d_016======\n",
      "read pickle\n",
      "=====开始处理20250312_4.5g-24d-4h_007======\n",
      "read pickle\n",
      "=====开始处理20250319_1g-23d-4h_001======\n",
      "read pickle\n",
      "=====开始处理20250409_5g-ov-24d_011======\n",
      "read pickle\n",
      "=====开始处理20250422_3g-lg9624-3h-24.5d_004======\n",
      "=====开始处理20250422_4.5gNa-lg9624-6h-24d_015======\n",
      "read pickle\n",
      "=====开始处理20250425_1g-9624-ov-24h_001======\n",
      "=====开始处理20250609_lg9624-1g-00225-23.5d-ov_008======\n",
      "=====开始处理20250609_lg9624-1g-00225-24d-ov_006======\n",
      "=====开始处理20250805_lg9624-1gNa-24d-ov_009======\n",
      "read pickle\n",
      "=====开始处理20250805_lg9624-1gNa-24d-ov_011======\n",
      "read pickle\n",
      "=====开始处理20250805_lg9624-1gNa-24d-ov_013======\n",
      "read pickle\n",
      "=====开始处理20250823_lg9624-1gNa-24.5d-1h-new_020======\n",
      "read pickle\n",
      "=====开始处理20250823_lg9624-1gNa-24.5d-4h-new_016======\n",
      "read pickle\n",
      "=====开始处理20250823_lg9624-1gNa-24d-1h-new_013======\n",
      "read pickle\n",
      "=====开始处理20250823_lg9624-1gNa-24d-1h-old_006======\n",
      "read pickle\n",
      "=====开始处理20250823_lg9624-1gNa-24d-4h-new_022======\n",
      "read pickle\n"
     ]
    }
   ],
   "source": [
    "p_f_all = r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\done'\n",
    "key_word = ''\n",
    "nokey_word = '*'\n",
    "# path_output = f'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\quies_plot'\n",
    "files = [f_p for f_p in os.listdir(p_f_all) if ('redo' not in f_p)&\n",
    "              ('done' not in f_p)&\n",
    "             os.path.isdir(os.path.join(p_f_all,f_p))&\n",
    "             (key_word in f_p)&(nokey_word not in f_p)]\n",
    "print(files)\n",
    "# files = get_inbtw_file(files, start_str = '20241201', end_str='20250830')\n",
    "for file in files:\n",
    "    print(f'=====开始处理{file}======')\n",
    "    add_quiet_trival(os.path.join(p_f_all,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca00b304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
