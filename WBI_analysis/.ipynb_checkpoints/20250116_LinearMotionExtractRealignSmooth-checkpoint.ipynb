{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02db14a9",
   "metadata": {},
   "source": [
    "### 编辑人:苏则茜\n",
    "### Project:Prob-Na-Learning\n",
    "For motion extraction of worm trajectories on different shapes of Petri dish  \n",
    "Although it is called 'general' version for motion parameter extraction, it works **only to single point gradient or non-gradient test plate**  \n",
    "For probabilitic learning training plate, see ***Distribution_Extract*** codes\n",
    "\n",
    "\n",
    "### 编辑日志\n",
    "@23-12-02整理了所有处理和写出csv的步骤，输出为处理了基本运动参数和实验条件等信息的csv文件  \n",
    "@23-12-09增加了距离区间面积标签；将时间区间默认设置为10min一组，距离区间默认5mm一组  \n",
    "@23-12-11抽取运动参数批量化，可一次性跑一个文件下所有的实验文件，但是总时长需要一致  \n",
    "@23-12-12增加角速率列  \n",
    "@24-3-4与MP（multiple-point）的处理相区分，重命名为OP_Motion_Extract  \n",
    "@24-3-29解决warning bug\n",
    "@24-10-14加入了平滑，轨迹先平滑后计算运动参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ab4012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51328c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义角度计算公式\n",
    "def ang_cal(vec_1,vec_2):\n",
    "    dot_pro = np.dot(vec_1, vec_2)\n",
    "    mod_1 = np.sqrt(np.dot(vec_1,vec_1))\n",
    "    mod_2 = np.sqrt(np.dot(vec_2,vec_2)) \n",
    "    if mod_1 == 0 or mod_2 ==0:\n",
    "        angle = 0\n",
    "    else:\n",
    "        cos = dot_pro/(mod_1*mod_2)\n",
    "        if np.isnan(cos) == True:\n",
    "            angle = np.nan\n",
    "        else:  \n",
    "            angle = np.arccos(round(cos,1))  #弧度制\n",
    "    return angle\n",
    "\n",
    "def clws_delta_phi(vec_1, vec_2, vec_0 = [1,0]):\n",
    "    # vec_1 is the first vector, and it rotates to the vec_2\n",
    "    vec_0 = np.array(vec_0)\n",
    "    agl_1 = ang_cal(vec_1,vec_2)\n",
    "    agl_2 = ang_cal(vec_0, vec_1)\n",
    "    agl_3 = ang_cal(vec_0, vec_2)\n",
    "    if agl_1 == 0:\n",
    "        agl_1 = 0\n",
    "        # print('angle = 0°')\n",
    "    elif agl_1 == np.pi:\n",
    "        agl_1 = np.pi\n",
    "        # print('angle = 180°')\n",
    "    elif vec_1[1] >= 0 and vec_2[1] >= 0:    #同时在第一第二象限\n",
    "        if (agl_3 - agl_2) > 0:\n",
    "            agl_1 = (-1)*np.abs(agl_1)\n",
    "        else:\n",
    "            agl_1 = np.abs(agl_1)\n",
    "    elif vec_1[1] <= 0 and vec_2[1] <= 0:    #同时在第三第四象限\n",
    "        if (agl_3 - agl_2) > 0:\n",
    "            agl_1 = np.abs(agl_1)\n",
    "        else:\n",
    "            agl_1 = (-1)*np.abs(agl_1)\n",
    "    elif vec_1[1] >= 0 and vec_2[1] <= 0:\n",
    "        if (agl_3 + agl_2) > np.pi:\n",
    "            agl_1 = (-1)*np.abs(agl_1)\n",
    "        else:                                  #如果等于180°认为是顺时针旋转\n",
    "            agl_1 = np.abs(agl_1)\n",
    "    elif vec_1[1] <= 0 and vec_2[1] >= 0:\n",
    "        if (agl_3 + agl_2) < np.pi:\n",
    "            agl_1 = (-1)*np.abs(agl_1)\n",
    "        else:                                  #如果等于180°认为是顺时针旋转\n",
    "            agl_1 = np.abs(agl_1)   \n",
    "    return agl_1*180/np.pi              # 输出为角度制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69acde06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sliding_CTX_Calculation(df_worms, df_ROI, idx, hlf_spd_inv, hlf_spd_agl_inv, hlf_agl_inv, \n",
    "                            window_size=20, frame_rate=20, track_jump_frame=1, pixel_length=0.025):\n",
    "    \"\"\"\n",
    "    优化后的速度、角速度和CTX计算函数，计算速度和角速度完全独立。\n",
    "    \"\"\"\n",
    "    # 滤波与预处理\n",
    "    df_slide = df_worms[df_worms.ID == idx].copy()\n",
    "    df_slide['X'] = df_slide['X'].rolling(window=window_size, center=True).mean()\n",
    "    df_slide['Y'] = df_slide['Y'].rolling(window=window_size, center=True).mean()\n",
    "\n",
    "    # 数据准备\n",
    "    trajectory = df_slide[['X', 'Y', 'Timestamp']].values.astype(float)\n",
    "    x, y, timestamps = trajectory[:, 0], trajectory[:, 1], trajectory[:, 2] / frame_rate\n",
    "\n",
    "    # 定义辅助函数\n",
    "    def compute_delta(data, bins, scale_factor=1):\n",
    "        return (data[bins:] - data[:-bins]) * scale_factor\n",
    "\n",
    "    def smooth_velocity(x, y, timestamps, bins, pixel_length):\n",
    "        delta_x = compute_delta(x, bins, pixel_length)\n",
    "        delta_y = compute_delta(y, bins, pixel_length)\n",
    "        delta_t = compute_delta(timestamps, bins)\n",
    "        velocity = np.column_stack((delta_x / delta_t, delta_y / delta_t))\n",
    "        speed = np.linalg.norm(velocity, axis=1)\n",
    "        return velocity, speed, delta_t\n",
    "\n",
    "    # 速度计算与异常检测\n",
    "    bins_spd = int((hlf_spd_inv * frame_rate) // track_jump_frame) * 2\n",
    "    velocity_spd, speed_spd, delta_t_spd = smooth_velocity(x, y, timestamps, bins_spd, pixel_length)\n",
    "\n",
    "    mean_delta_t = np.nanmean(delta_t_spd)\n",
    "    threshold = hlf_spd_inv * 2\n",
    "    outlier_id = mean_delta_t > 1.25 * threshold\n",
    "\n",
    "    if outlier_id:\n",
    "        print(f'平均delta_t超出阈值 ({mean_delta_t:.2f} > {threshold:.2f}), ID: {idx}')\n",
    "\n",
    "    # 补充 NaN 填充\n",
    "    velocity_spd = np.pad(velocity_spd, ((bins_spd // 2, bins_spd // 2), (0, 0)), constant_values=np.nan)\n",
    "    speed_spd = np.pad(speed_spd, (bins_spd // 2, bins_spd // 2), constant_values=np.nan)\n",
    "\n",
    "    # 角速度计算\n",
    "    bins_agl = int((hlf_spd_agl_inv * frame_rate) // track_jump_frame) * 2\n",
    "    hlf_bins_agl = int((hlf_agl_inv * frame_rate) // track_jump_frame)\n",
    "    velocity_agl, _, time_step_agl = smooth_velocity(x, y, timestamps, bins_agl, pixel_length)\n",
    "\n",
    "    angular_velocity = np.zeros(len(time_step_agl))\n",
    "    valid_idx = np.arange(hlf_bins_agl, len(time_step_agl) - hlf_bins_agl)\n",
    "\n",
    "    for i in valid_idx:\n",
    "        delta_phi = clws_delta_phi(velocity_agl[i - hlf_bins_agl], velocity_agl[i + hlf_bins_agl])\n",
    "        delta_t = time_step_agl[i + hlf_bins_agl] - time_step_agl[i - hlf_bins_agl]\n",
    "        angular_velocity[i] = delta_phi / delta_t if delta_t > 0 else 0\n",
    "\n",
    "    # CTX计算\n",
    "    points = np.array([list(map(int, df_ROI.loc[0, col])) for col in df_ROI.columns])\n",
    "    vec_left, vec_right = points[1] - points[2], points[2] - points[1]\n",
    "    ctx = velocity_spd[:, 0] / np.linalg.norm(velocity_spd, axis=1)\n",
    "    bearing_left = np.arctan2(velocity_spd[:, 1], velocity_spd[:, 0]) - np.arctan2(vec_left[1], vec_left[0])\n",
    "    bearing_right = np.arctan2(velocity_spd[:, 1], velocity_spd[:, 0]) - np.arctan2(vec_right[1], vec_right[0])\n",
    "\n",
    "    # 合并结果\n",
    "    df_slide['speed'] = speed_spd\n",
    "    df_slide['x_velocity'], df_slide['y_velocity'] = velocity_spd[:, 0], velocity_spd[:, 1]\n",
    "    df_slide['agl_velocity'] = angular_velocity\n",
    "    df_slide['agl_speed'] = np.abs(angular_velocity)\n",
    "    df_slide['CTX'] = ctx\n",
    "    df_slide['bearing_left'] = bearing_left\n",
    "    df_slide['CTX_left'] = np.cos(bearing_left)\n",
    "    df_slide['bearing_right'] = bearing_right\n",
    "    df_slide['CTX_right'] = np.cos(bearing_right)\n",
    "    df_slide['X_org'] = df_worms[df_worms.ID == idx]['X']\n",
    "    df_slide['Y_org'] = df_worms[df_worms.ID == idx]['Y']\n",
    "\n",
    "    return df_slide, idx if outlier_id else False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6c9fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 速度，角速度，bearing angle, Dist_to_center, ctx计算函数\n",
    "# 输入：筛选为虫子的csv文件，画圆的csv文件，ID索引，速度平滑，角速度速度平滑，角速度平滑，追踪帧率，跳帧数量，像素长度\n",
    "def Sliding_CTX_Calculation(df_worms, df_ROI, idx, sm_inv, spd_sm_inv, hlf_sm_inv,window_size = 20, frame_rate = 20, track_jump_frame = 1, pixel_length = 0.025):\n",
    "    # 只适用于线性梯度，因为CTX只计算到左和右边缘的\n",
    "    # 速度平滑窗s sm_inv\n",
    "    # 计算角速度的速度平滑窗s spd_sm_inv\n",
    "    # 角速度平滑床s hlf_sm_inv\n",
    "    \n",
    "    # ======================================数据平滑=================\n",
    "    # 1. 移动窗口平滑\n",
    "    # 对X和Y坐标进行移动平均\n",
    "    df_slide = df_worms[df_worms.ID==idx].copy()\n",
    "    df_slide['X'] = df_slide['X'].rolling(window=window_size, center=True).mean()\n",
    "    df_slide['Y'] = df_slide['Y'].rolling(window=window_size, center=True).mean()\n",
    "\n",
    "    # ======================================速度计算=================\n",
    "    half_bins_spd = int((sm_inv*frame_rate)//track_jump_frame)\n",
    "    bins_spd = 2*half_bins_spd\n",
    "#     print(f'速度总平滑窗为{sm_inv*2}s,bins数量为{2*half_bins_spd}个')\n",
    "\n",
    "    trajectory_0 = df_slide[['X','Y','Timestamp']].values      # 提取x,y坐标和时间戳\n",
    "    trajectory_1 = (trajectory_0.copy()).astype('float')                            # 转float数据类型\n",
    "    x = trajectory_1[:,0]\n",
    "    y = trajectory_1[:,1]\n",
    "    delta_x = (x[bins_spd:]-x[:len(x)-bins_spd])*pixel_length                       # 得到减去头尾数据点的delta_x和delta_y\n",
    "    delta_y = (y[bins_spd:]-y[:len(y)-bins_spd])*pixel_length\n",
    "    time_step = trajectory_1[:,2]/frame_rate    \n",
    "    time_step_vec = time_step[bins_spd:]-time_step[:len(time_step)-bins_spd]        # 得到减去头尾数据点的对应delta-x和delta-y的时间\n",
    "    print('平均时间间隔'+str(np.average(time_step_vec))+'应该等于总平滑窗'+str(sm_inv*2))\n",
    "    \n",
    "    # 根据平均时长筛选轨迹\n",
    "    mean_time_inv = np.average(time_step_vec)   # 平均时间间隔\n",
    "    n = 1.25                                    # 平均时间间隔长度\n",
    "    outlier_id = False\n",
    "    if mean_time_inv/(sm_inv*2) >= n:\n",
    "        outlier_id = True\n",
    "        print(f'实际平均间隔大于{str(n)}倍，，ID为{idx}')\n",
    "    velocity_bef = np.dstack((delta_x/time_step_vec,delta_y/time_step_vec))[0]      # 使用dstack函数合并x,y方向计算的速度为一个矩阵\n",
    "    speed_bef = np.linalg.norm(velocity_bef, axis = 1).reshape(-1,1)\n",
    "    nan_bin_vec = np.full((half_bins_spd,2),np.nan)\n",
    "    nan_bin_spd = np.full((half_bins_spd,1),np.nan)\n",
    "    velocity = np.vstack((nan_bin_vec, velocity_bef, nan_bin_vec))                  # 速度向量\n",
    "    speed = np.vstack((nan_bin_spd, speed_bef, nan_bin_spd))                        # 速率向量\n",
    "#     print(f'补齐nan后的速度形状:{len(velocity)}应该等于轨迹形状')\n",
    "    df_idx = df_slide[['ID','X','Y','Timestamp']].copy()      \n",
    "    df_idx['speed'] = pd.Series(speed[:,0],index = df_idx.index)                    # 将speed和velocity加入dataframe\n",
    "    df_idx['x_velocity'] = pd.Series(velocity[:,0],index = df_idx.index)\n",
    "    df_idx['y_velocity'] = pd.Series(velocity[:,1],index = df_idx.index)\n",
    "    \n",
    "    # ======================================================角速度计算===========\n",
    "\n",
    "    half_bins_spd_agl = int((spd_sm_inv*frame_rate)//track_jump_frame)\n",
    "    bins_spd_agl = 2*half_bins_spd_agl                                 # 角速度速度平滑窗\n",
    "    hlf_agl_bins = int((hlf_sm_inv*frame_rate)//track_jump_frame)      # 角速度半平滑窗\n",
    "    trajectory_0 = df_slide[df_slide['ID']==idx][['X','Y','Timestamp']].values      # 提取x,y坐标和时间戳\n",
    "    trajectory_1 = (trajectory_0.copy()).astype('float')                            # 转float数据类型\n",
    "    x = trajectory_1[:,0]\n",
    "    y = trajectory_1[:,1]\n",
    "    delta_x = (x[bins_spd_agl:]-x[:len(x)-bins_spd_agl])*pixel_length                                      # 得到减去头尾数据点的delta_x和delta_y\n",
    "    delta_y = (y[bins_spd_agl:]-y[:len(y)-bins_spd_agl])*pixel_length\n",
    "    time_step = trajectory_1[:,2]/frame_rate    \n",
    "    time_step_vec = time_step[bins_spd_agl:]-time_step[:len(time_step)-bins_spd_agl]        # 得到减去头尾数据点的对应delta-x和delta-y的时间\n",
    "    velocity_bef = np.dstack((delta_x/time_step_vec,delta_y/time_step_vec))[0]             # 使用dstack函数合并x,y方向计算的速度为一个矩阵\n",
    "    speed_bef = np.linalg.norm(velocity_bef, axis = 1).reshape(-1,1)\n",
    "    nan_bin_vec = np.full((half_bins_spd_agl,2),np.nan)\n",
    "    nan_bin_spd = np.full((half_bins_spd_agl,1),np.nan)\n",
    "    velocity = np.vstack((nan_bin_vec, velocity_bef, nan_bin_vec))\n",
    "    speed = np.vstack((nan_bin_spd, speed_bef, nan_bin_spd))[:,0]\n",
    "    time_step_vector = np.vstack((nan_bin_spd, time_step_vec.reshape(-1,1), nan_bin_spd))[:,0]\n",
    "    \n",
    "    df_speed_cal = pd.DataFrame(speed,columns = ['speed'])              # 生成一个包含speed的df并提取索引\n",
    "    \n",
    "    idx_vec = df_speed_cal.index                                        # 生成索引列表时先掐头去尾再取非零值\n",
    "    df_washed_speed = df_speed_cal[half_bins_spd_agl:len(idx_vec)-half_bins_spd_agl]\n",
    "    idx_nz_vec = df_washed_speed[df_washed_speed['speed']!=0].index     # 索引是相对于总长度，但是这个列表中直接去掉了头尾速度为nan的和速率为0的点的索引\n",
    "    df_speed_cal['agl_velocity'] = pd.Series([np.nan]*len(idx_vec))\n",
    "\n",
    "    for i in range(hlf_agl_bins,len(idx_nz_vec)-hlf_agl_bins):\n",
    "        n = hlf_agl_bins\n",
    "        agl_i = clws_delta_phi(velocity[idx_nz_vec[i-n]],velocity[idx_nz_vec[i+n]])        \n",
    "        delta_t_i = time_step[idx_nz_vec[i+n]]-time_step[idx_nz_vec[i-n]]\n",
    "        agl_vel_i = agl_i/delta_t_i\n",
    "\n",
    "        if np.isnan(agl_vel_i) == False:\n",
    "            df_speed_cal['agl_velocity'].loc[idx_nz_vec[i]] = agl_vel_i\n",
    "        else:\n",
    "#             print(velocity[idx_nz_vec[i-n]],velocity[idx_nz_vec[i+n]])\n",
    "            df_speed_cal['agl_velocity'].loc[idx_nz_vec[i]] = 0 \n",
    "    # 将angular_velocity和angular_speed加入dataframe(df_idx)\n",
    "    df_idx['agl_velocity'] = pd.Series(df_speed_cal['agl_velocity'].values,index = df_idx.index)\n",
    "    df_idx.loc[:,'x_velocity_agl'] = velocity[:,0]\n",
    "    df_idx.loc[:,'y_velocity_agl'] = velocity[:,1]\n",
    "    df_idx.loc[df_idx.speed == 0, 'agl_velocity'] = 0                 # 将speed为0的点角速度设为0\n",
    "    df_idx['agl_speed'] = np.abs(df_idx['agl_velocity'])\n",
    "    \n",
    "    # ===========================================计算CTX=====================================\n",
    "    points = []\n",
    "    for col in df_ROI.columns[:]:\n",
    "        p = df_ROI.loc[0,col]\n",
    "        points.append([int(p[0]), int(p[1])])\n",
    "    points = np.array(points)\n",
    "\n",
    "    # 目标方向（left and right）\n",
    "    vec_left = points[1]-points[2]\n",
    "#     print(f'CTX_left的目标方向向量：{vec_left}')\n",
    "    vec_right = points[2]-points[1]\n",
    "#     print(f'CTX_right的目标方向向量：{vec_right}')\n",
    "    # 计算bearing angle和CTX\n",
    "    # 提取所有数据点速度向量\n",
    "    vel_vec = df_idx[['x_velocity','y_velocity']].values\n",
    "    bearing_left = []\n",
    "    bearing_right = []\n",
    "    # 不经过角度直接计算ctx\n",
    "    ctxs = []\n",
    "    for i in range(len(vel_vec)):\n",
    "        agl_i_left = clws_delta_phi(vec_left,vel_vec[i,:])\n",
    "        agl_i_left = agl_i_left/180*np.pi     # bearing angle使用的是弧度制\n",
    "        bearing_left.append(agl_i_left)                                      # 使用弧度制\n",
    "        \n",
    "        vel_vec_i = vel_vec[i,:]\n",
    "        ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n",
    "        \n",
    "        ctxs.append(ctx_i)\n",
    "        \n",
    "        agl_i_right = clws_delta_phi(vec_right,vel_vec[i,:])\n",
    "        agl_i_right = agl_i_right/180*np.pi\n",
    "        bearing_right.append(agl_i_right)\n",
    "        \n",
    "    df_idx['CTX'] = pd.Series(ctxs, index = df_idx.index)\n",
    "    df_idx['bearing_left'] = pd.Series(bearing_left, index = df_idx.index)\n",
    "    df_idx['CTX_left']=df_idx['bearing_left'].apply(np.cos,axis = 0)\n",
    "    df_idx['bearing_right'] = pd.Series(bearing_right, index = df_idx.index)\n",
    "    df_idx['CTX_right']=df_idx['bearing_right'].apply(np.cos,axis = 0)\n",
    "    df_idx['X_org'] = df_worms[df_worms.ID==idx]['X']                     # 将平滑前的轨迹也加入df\n",
    "    df_idx['Y_org'] = df_worms[df_worms.ID==idx]['Y']\n",
    "    \n",
    "    if outlier_id:\n",
    "        return df_idx, idx\n",
    "    else:\n",
    "        return df_idx, outlier_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e23cbfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Insert_SharpTurn(df_als, min_agl = 90):\n",
    "    print('=======================开始事件分类===================================')\n",
    "    print('注：事件分类仅完成分类（turn = 1, run = 0），tunrning rate的计算较为灵活，在汇总分析作图时使用')\n",
    "    # 新建一列为Event\n",
    "    if 'Event' in df_als:\n",
    "        df_als = df_als.drop('Event', axis = 1)\n",
    "    df_als.loc[:,'Event'] = 0\n",
    "    df_als.loc[df_als.agl_speed >= min_agl, 'Event'] = 1\n",
    "    return df_als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7389a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 边缘裁剪\n",
    "def Cut_edge(df, x_cut, y_cut, pixel_length = 0.025):\n",
    "    # 距离换算\n",
    "    x_cut_pixel = x_cut/pixel_length\n",
    "    y_cut_pixel = y_cut/pixel_length\n",
    "\n",
    "    print(f'裁剪的像素距离为：X {x_cut_pixel}， Y {y_cut_pixel}')\n",
    "    x_range = [min(df['X'].dropna()), max(df['X'].dropna())]\n",
    "    y_range = [min(df['Y'].dropna()), max(df['Y'].dropna())]\n",
    "    print('原X,Y距离范围分别为',x_range, y_range)\n",
    "    x_cut_range = [min(df['X'].dropna())+x_cut_pixel, max(df['X'].dropna())-x_cut_pixel]\n",
    "    y_cut_range = [min(df['Y'].dropna())+y_cut_pixel, max(df['Y'].dropna())-y_cut_pixel]\n",
    "    print('裁剪后距离范围分别为',x_cut_range, y_cut_range)\n",
    "    \n",
    "    # 裁剪\n",
    "    df_cut = df[(df.X >= x_cut_range[0]) & (df.X <= x_cut_range[1]) & (df.Y >= y_cut_range[0]) & (df.Y <= y_cut_range[1])]\n",
    "\n",
    "    return df_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91de325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def realign_xy(x, y, sin_phi, cos_phi):\n",
    "    \"\"\"\n",
    "    旋转坐标 (x, y) 角度，由 sin_phi 和 cos_phi 定义。\n",
    "    \"\"\"\n",
    "    rotation_mat = np.array([[cos_phi, sin_phi], [-sin_phi, cos_phi]])\n",
    "    return np.matmul(rotation_mat, np.array([x, y]))\n",
    "\n",
    "def realign_coordinate(df, df_roi):\n",
    "    \"\"\"\n",
    "    旋转坐标轴，将X轴对齐到两琼脂块中心的连线。\n",
    "    \"\"\"\n",
    "    # 提取points并调整原点到左下角点\n",
    "    points = np.array([list(map(int, p.strip('()').split(','))) for p in df_roi.iloc[0, :-1]])\n",
    "    origin = points[1]\n",
    "    points -= origin\n",
    "    df_realign = df.copy()\n",
    "    df_realign[['X', 'Y']] -= origin\n",
    "\n",
    "    # 计算旋转角度\n",
    "    new_x_axis = points[2] - points[1]\n",
    "    mod = np.linalg.norm(new_x_axis)\n",
    "    sin_phi, cos_phi = new_x_axis[1] / mod, new_x_axis[0] / mod\n",
    "\n",
    "    # 旋转df\n",
    "    df_realign[['X', 'Y']] = df_realign.apply(\n",
    "        lambda row: realign_xy(row.X, row.Y, sin_phi, cos_phi), axis=1, result_type='expand'\n",
    "    )\n",
    "\n",
    "    # 旋转points\n",
    "    rotated_points = np.array([realign_xy(p[0], p[1], sin_phi, cos_phi) for p in points])\n",
    "\n",
    "    # 恢复原点\n",
    "    df_realign[['X', 'Y']] += origin\n",
    "    rotated_points += origin\n",
    "\n",
    "    # 返回结果\n",
    "    point_fin = {f'point{i+1}': [rotated_points[i]] for i in range(4)}\n",
    "    df_ROI_fin = pd.DataFrame(point_fin)\n",
    "    return df_realign, df_ROI_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca162b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批量处理单个实验数据的主函数\n",
    "def process_experiment_data(df, df_ROI, file_info, time_len=3, plate_type=0, noise_lim=100, \n",
    "                            time_inv_min=5, max_dist=40, dist_inv=5, x_cut=2, y_cut=2, \n",
    "                            ws=40, track_jump_frame=1, remove_outlier=True, pixel_length=0.025):\n",
    "    \"\"\"\n",
    "    对单个实验数据进行处理，去噪、重定位坐标并计算相关特征。\n",
    "\n",
    "    参数：\n",
    "        df: 实验数据 DataFrame\n",
    "        df_ROI: ROI 数据\n",
    "        file_info: 文件信息列表 [日期, 条件, 分组ID]\n",
    "        time_len: 实验时长（小时）\n",
    "        plate_type: 平板类型（0: 圆形，1: 方形）\n",
    "        noise_lim: 噪声上限\n",
    "        time_inv_min: 时间间隔（分钟）\n",
    "        max_dist: 最大距离（mm）\n",
    "        dist_inv: 距离分组间隔（mm）\n",
    "        x_cut, y_cut: 边缘剪裁大小\n",
    "        ws: 滑动窗口大小\n",
    "        track_jump_frame: 允许的跳帧数\n",
    "        remove_outlier: 是否移除离群点\n",
    "        pixel_length: 单个像素长度（mm）\n",
    "\n",
    "    返回：\n",
    "        处理后的事件数据 DataFrame\n",
    "    \"\"\"\n",
    "    # 提取 ROI 顶点\n",
    "    points = [list(map(int, p.strip('()').split(','))) for p in df_ROI.iloc[0, :-1]]\n",
    "\n",
    "    # 去噪并筛选虫子轨迹\n",
    "    df_worms = df[df.Diagonal_Length > noise_lim]\n",
    "    print(f'Noise limit: {noise_lim}, Worm trajectories: {len(df_worms.ID.unique())} IDs')\n",
    "\n",
    "    # 坐标轴重定位\n",
    "    df_worms_aligned, df_ROI_aligned = realign_coordinate(df_worms, df_ROI)\n",
    "    unique_ids = df_worms_aligned['ID'].unique()\n",
    "    frame_rate = max(df_worms_aligned.Timestamp) / (time_len * 3600)\n",
    "    print(f'Frame rate: {frame_rate}')\n",
    "\n",
    "    # 滑动窗口特征计算\n",
    "    processed_data = []\n",
    "    outliers = []\n",
    "    for worm_id in unique_ids:\n",
    "        try:\n",
    "            data, outlier_id = Sliding_CTX_Calculation(\n",
    "                df_worms_aligned, df_ROI_aligned, worm_id, 1, 0.5, 0.5, ws, frame_rate, track_jump_frame, pixel_length\n",
    "            )\n",
    "            processed_data.append(data)\n",
    "            if outlier_id:\n",
    "                outliers.append(outlier_id)\n",
    "        except Exception as e:\n",
    "            print(f'Error processing ID {worm_id}: {e}')\n",
    "\n",
    "    # 合并所有轨迹数据\n",
    "    df_processed = pd.concat(processed_data, ignore_index=True)\n",
    "\n",
    "    # 去除离群点\n",
    "    if remove_outlier:\n",
    "        df_processed = df_processed[~df_processed.ID.isin(outliers)]\n",
    "        print(f'Removed outliers: {len(outliers)} IDs')\n",
    "\n",
    "    # 计算与中线的位移\n",
    "    mid_x = (points[1][0] + points[2][0] + points[0][0] + points[3][0]) / 4\n",
    "    df_processed['Disp_to_mid'] = df_processed['X'] - mid_x\n",
    "\n",
    "#     # 分割时间和距离区间\n",
    "#     df_processed = Insert_Period_idx(df_processed, time_inv_min, time_len)\n",
    "#     df_processed = Insert_Dist_idx(\n",
    "#         df_processed, df_ROI_aligned, plate_type, max_dist // dist_inv, max_dist, dist_inv, pixel_length\n",
    "#     )\n",
    "    df_processed = Cut_edge(df_processed, x_cut, y_cut, pixel_length)\n",
    "\n",
    "    # 事件分类\n",
    "    df_processed = Insert_SharpTurn(df_processed, min_agl=90)\n",
    "#     df_processed['frame_rate'] = frame_rate\n",
    "    df_processed['Date'] = file_info[0]\n",
    "    \n",
    "    # 判断是否多因素设计,如果是，设置为多列，按照Condition+0，1，2编号\n",
    "    condition_feature = file_info[-2]\n",
    "    condition_ls = condition_feature.split('-')\n",
    "    for i, c in enumerate(condition_ls):\n",
    "        if len(condition_ls) > 1:\n",
    "            con_col = 'Condition'+str(i)\n",
    "            df_processed[con_col] = c\n",
    "        else:\n",
    "            df_processed['Condition'] = c\n",
    "    df_processed['Group_id'] = file_info[-1]\n",
    "\n",
    "    print(f'Processed data for: Date={file_info[0]}, Conditions={condition_ls}, Group ID={file_info[-1]}')\n",
    "\n",
    "    return df_processed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f7363b",
   "metadata": {},
   "source": [
    "# 批量处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1a21dd",
   "metadata": {},
   "source": [
    "待处理文件的文件夹（包含merge文件夹中有merge后的文件，以及rectangle文件）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acddc967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_merge_files(path_dirs, key_word,slice_vec=[]):\n",
    "    \"\"\"查找符合条件的文件并记录路径。\"\"\"\n",
    "    merge_files, merge_paths, merge_dirs = [], [], []\n",
    "    for path_dir in path_dirs:\n",
    "        merge_dir = os.path.join(path_dir, 'merge_result')\n",
    "        files = os.listdir(merge_dir)\n",
    "        filtered_files = [f for f in files if 'second_clear' in f and (key_word in f if key_word else True)]\n",
    "        merge_files.extend(filtered_files)\n",
    "        merge_paths.extend([os.path.join(merge_dir, f) for f in filtered_files])\n",
    "        merge_dirs.extend([path_dir] * len(filtered_files))\n",
    "        \n",
    "        # 如果有切片，可以只选择其中一部分文件跑代码\n",
    "        if slice_vec:\n",
    "            merge_files = merge_files[slice_vec[0]:slice_vec[1]]\n",
    "            merge_paths = merge_paths[slice_vec[0]:slice_vec[1]]\n",
    "            merge_dirs = merge_dirs[slice_vec[0]:slice_vec[1]]\n",
    "    return merge_files, merge_paths, merge_dirs\n",
    "\n",
    "def save_data(df, output_path, save_as_pickle=True):\n",
    "    \"\"\"保存数据为指定格式（pickle 或 csv）。\"\"\"\n",
    "    if save_as_pickle:\n",
    "        df.to_pickle(output_path)\n",
    "    else:\n",
    "        df.to_csv(output_path, index=False)\n",
    "    print(f\"数据已保存到: {output_path}\")\n",
    "\n",
    "def process_single_file(merge_path, merge_file, merge_dir, key_params, plate_types, plate_type_idx):\n",
    "    \"\"\"处理单个文件。\"\"\"\n",
    "    # 加载轨迹数据和 ROI 数据\n",
    "    df_track = pd.read_csv(merge_path)\n",
    "    feature_name = merge_file.split('_second_clear')[0]\n",
    "    roi_file = f\"{feature_name}_{plate_types[plate_type_idx]}_info.csv\"\n",
    "    roi_path = os.path.join(merge_dir, roi_file)\n",
    "    df_ROI = pd.read_csv(roi_path)\n",
    "    \n",
    "    # 解析文件名并打印处理信息\n",
    "    file_info = feature_name.split('_')\n",
    "    print(f\"开始处理文件: {file_info}\")\n",
    "    \n",
    "    # 调用主处理函数\n",
    "    df_als = process_experiment_data(\n",
    "        df_track, df_ROI, file_info,\n",
    "        time_len=key_params[0], plate_type=plate_type_idx, noise_lim=key_params[1],\n",
    "        time_inv_min=key_params[2], max_dist=key_params[3], track_jump_frame=1,\n",
    "        x_cut=2, y_cut=2, ws=40\n",
    "    )\n",
    "    return df_als, feature_name\n",
    "\n",
    "def process_all_files(merge_paths, merge_files, merge_dirs, key_params, plate_types, plate_type_idx, save_as_pickle, concat_pkl, columns_for_concat):\n",
    "    \"\"\"批量处理所有文件。\"\"\"\n",
    "    all_data = []\n",
    "    for merge_path, merge_file, merge_dir in zip(merge_paths, merge_files, merge_dirs):\n",
    "        df_als, feature_name = process_single_file(merge_path, merge_file, merge_dir, key_params, plate_types, plate_type_idx)\n",
    "        \n",
    "        # 保存单文件结果\n",
    "        output_file = os.path.join(\n",
    "            merge_dir,\n",
    "            f\"{feature_name.split('.avi')[0]}_smh-als.{'pkl' if save_as_pickle else 'csv'}\"\n",
    "        )\n",
    "        save_data(df_als, output_file, save_as_pickle)\n",
    "        \n",
    "        # 如果需要合并，记录指定列\n",
    "        if concat_pkl:\n",
    "            all_data.append(df_als[columns_for_concat] if columns_for_concat else df_als)\n",
    "        # 合并需要用到file_info的前两项\n",
    "        file_info = feature_name.split('_')\n",
    "        file_keyinfo = f'{file_info[0]}_{file_info[1]}'\n",
    "    return all_data, file_keyinfo\n",
    "\n",
    "def save_concatenated_data(all_data, output_path):\n",
    "    \"\"\"保存合并后的数据。\"\"\"\n",
    "    if not all_data:\n",
    "        return\n",
    "    df_combined = pd.concat(all_data, ignore_index=True)\n",
    "    df_combined = df_combined[df_combined.speed != 0].reset_index(drop=True)\n",
    "    df_combined.to_pickle(output_path)\n",
    "    print(f\"合并后的数据已保存到: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98048119",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共找到 3 个文件，准备处理...\n",
      "20250113_Na-CTX_2.25gNaPre_0gNa-stdLB-cl-45start_1_second_clear.csv\n",
      "20250113_Na-CTX_2.25gNaPre_0gNa-stdLB-cl-45start_2_second_clear.csv\n",
      "20250113_Na-CTX_2.25gNaPre_0gNa-stdLB-op-45start_1_second_clear.csv\n",
      "开始处理文件: ['20250113', 'Na-CTX', '2.25gNaPre', '0gNa-stdLB-cl-45start', '1']\n",
      "Noise limit: 250, Worm trajectories: 34 IDs\n",
      "Frame rate: 20.000740740740742\n",
      "平均时间间隔1.9999890725931748应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔2.002135977261498应该等于总平滑窗2\n",
      "平均时间间隔1.9999259286693085应该等于总平滑窗2\n",
      "平均时间间隔1.9999451144514329应该等于总平滑窗2\n",
      "平均时间间隔1.999925928669308应该等于总平滑窗2\n",
      "平均时间间隔2.004095599862516应该等于总平滑窗2\n",
      "平均时间间隔2.0002089136958277应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999259286693083应该等于总平滑窗2\n",
      "平均时间间隔2.0026601297726945应该等于总平滑窗2\n",
      "平均时间间隔1.9999259286693085应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999259286693083应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999259286693085应该等于总平滑窗2\n",
      "平均时间间隔1.999944452848228应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.999944452848228应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.999944452848228应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999259286693085应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999467460517242应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999259286693087应该等于总平滑窗2\n",
      "平均时间间隔2.0040163146986605应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999379706125207应该等于总平滑窗2\n",
      "平均时间间隔2.0002215475405127应该等于总平滑窗2\n",
      "平均时间间隔2.0026440693840293应该等于总平滑窗2\n",
      "平均时间间隔1.9999259286693085应该等于总平滑窗2\n",
      "平均时间间隔1.9999259286693083应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.999925928669308应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔2.003350119465293应该等于总平滑窗2\n",
      "平均时间间隔2.002308894250688应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999259286693085应该等于总平滑窗2\n",
      "平均时间间隔1.9999259286693087应该等于总平滑窗2\n",
      "平均时间间隔1.9999259286693083应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999259286693083应该等于总平滑窗2\n",
      "平均时间间隔1.9999259286693083应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999259286693085应该等于总平滑窗2\n",
      "平均时间间隔1.9999259286693083应该等于总平滑窗2\n",
      "Removed outliers: 0 IDs\n",
      "裁剪的像素距离为：X 80.0， Y 80.0\n",
      "原X,Y距离范围分别为 [127.0, 3220.8] [49.0, 3005.15]\n",
      "裁剪后距离范围分别为 [207.0, 3140.8] [129.0, 2925.15]\n",
      "=======================开始事件分类===================================\n",
      "注：事件分类仅完成分类（turn = 1, run = 0），tunrning rate的计算较为灵活，在汇总分析作图时使用\n",
      "Processed data for: Date=20250113, Conditions=['0gNa', 'stdLB', 'cl', '45start'], Group ID=1\n",
      "数据已保存到: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250113_45start\\2\\20250113_Na-CTX_2.25gNaPre_0gNa-stdLB-cl-45start_1_smh-als.pkl\n",
      "开始处理文件: ['20250113', 'Na-CTX', '2.25gNaPre', '0gNa-stdLB-cl-45start', '2']\n",
      "Noise limit: 250, Worm trajectories: 52 IDs\n",
      "Frame rate: 20.000555555555554\n",
      "平均时间间隔1.9999444459876121应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999444459876121应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔2.000426195115304应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔2.001611622084634应该等于总平滑窗2\n",
      "平均时间间隔2.001611622084634应该等于总平滑窗2\n",
      "平均时间间隔1.9999444459876115应该等于总平滑窗2\n",
      "平均时间间隔1.9999444459876117应该等于总平滑窗2\n",
      "平均时间间隔1.9999444459876115应该等于总平滑窗2\n",
      "平均时间间隔1.9999444459876115应该等于总平滑窗2\n",
      "平均时间间隔2.0040511080943624应该等于总平滑窗2\n",
      "平均时间间隔2.0006111951588763应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999444459876117应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999444459876121应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔2.000185291543868应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999471719702824应该等于总平滑窗2\n",
      "平均时间间隔1.9999444459876117应该等于总平滑窗2\n",
      "平均时间间隔1.9999530560463596应该等于总平滑窗2\n",
      "平均时间间隔2.0001396895065824应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999444459876117应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999444459876117应该等于总平滑窗2\n",
      "平均时间间隔1.9999444459876115应该等于总平滑窗2\n",
      "平均时间间隔1.9999444459876117应该等于总平滑窗2\n",
      "平均时间间隔1.999944445987612应该等于总平滑窗2\n",
      "平均时间间隔1.9999444459876115应该等于总平滑窗2\n",
      "平均时间间隔1.9999444459876115应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔2.0000706146909395应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999444459876117应该等于总平滑窗2\n",
      "平均时间间隔1.999944445987612应该等于总平滑窗2\n",
      "平均时间间隔1.9999980031764175应该等于总平滑窗2\n",
      "平均时间间隔2.0033988954852266应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔2.0065753784826206应该等于总平滑窗2\n",
      "平均时间间隔1.999944445987612应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999444459876117应该等于总平滑窗2\n",
      "平均时间间隔1.999944445987612应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999444459876117应该等于总平滑窗2\n",
      "平均时间间隔1.9999444459876117应该等于总平滑窗2\n",
      "平均时间间隔1.9999444459876117应该等于总平滑窗2\n",
      "平均时间间隔1.999944445987612应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.999944445987612应该等于总平滑窗2\n",
      "平均时间间隔2.000004401752398应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.999986236869549应该等于总平滑窗2\n",
      "平均时间间隔1.9999640840909698应该等于总平滑窗2\n",
      "平均时间间隔1.9999444459876112应该等于总平滑窗2\n",
      "平均时间间隔1.9999444459876115应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999444459876117应该等于总平滑窗2\n",
      "平均时间间隔1.999944445987612应该等于总平滑窗2\n",
      "平均时间间隔1.9999444459876117应该等于总平滑窗2\n",
      "平均时间间隔1.9999444459876117应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.999944445987612应该等于总平滑窗2\n",
      "平均时间间隔1.999944445987612应该等于总平滑窗2\n",
      "平均时间间隔2.0000557919310715应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔2.0000557919310715应该等于总平滑窗2\n",
      "Removed outliers: 0 IDs\n",
      "裁剪的像素距离为：X 80.0， Y 80.0\n",
      "原X,Y距离范围分别为 [78.59776828552087, 3959.9127369480602] [63.96428300084216, 2985.2764113728986]\n",
      "裁剪后距离范围分别为 [158.59776828552089, 3879.9127369480602] [143.96428300084216, 2905.2764113728986]\n",
      "=======================开始事件分类===================================\n",
      "注：事件分类仅完成分类（turn = 1, run = 0），tunrning rate的计算较为灵活，在汇总分析作图时使用\n",
      "Processed data for: Date=20250113, Conditions=['0gNa', 'stdLB', 'cl', '45start'], Group ID=2\n",
      "数据已保存到: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250113_45start\\2\\20250113_Na-CTX_2.25gNaPre_0gNa-stdLB-cl-45start_2_smh-als.pkl\n",
      "开始处理文件: ['20250113', 'Na-CTX', '2.25gNaPre', '0gNa-stdLB-op-45start', '1']\n",
      "Noise limit: 250, Worm trajectories: 13 IDs\n",
      "Frame rate: 20.000740740740742\n",
      "平均时间间隔2.0005559433230173应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999259286693083应该等于总平滑窗2\n",
      "平均时间间隔1.9999259286693083应该等于总平滑窗2\n",
      "平均时间间隔1.9999259286693083应该等于总平滑窗2\n",
      "平均时间间隔1.9999259286693085应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔1.9999259286693083应该等于总平滑窗2\n",
      "平均时间间隔1.9999259286693085应该等于总平滑窗2\n",
      "平均时间间隔1.999937632355689应该等于总平滑窗2\n",
      "平均时间间隔2.0000685283043147应该等于总平滑窗2\n",
      "平均时间间隔2.0000090157136334应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔2.001896784474846应该等于总平滑窗2\n",
      "平均时间间隔2.0238301149405062应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均时间间隔2.029921090913559应该等于总平滑窗2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows11\\AppData\\Local\\Temp\\ipykernel_18496\\4106300736.py:121: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ctx_i = vel_vec_i[0]/np.linalg.norm(vel_vec_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed outliers: 0 IDs\n",
      "裁剪的像素距离为：X 80.0， Y 80.0\n",
      "原X,Y距离范围分别为 [54.46408918333153, 2174.390862286615] [67.39723296382697, 2981.186468521223]\n",
      "裁剪后距离范围分别为 [134.46408918333154, 2094.390862286615] [147.39723296382698, 2901.186468521223]\n",
      "=======================开始事件分类===================================\n",
      "注：事件分类仅完成分类（turn = 1, run = 0），tunrning rate的计算较为灵活，在汇总分析作图时使用\n",
      "Processed data for: Date=20250113, Conditions=['0gNa', 'stdLB', 'op', '45start'], Group ID=1\n",
      "数据已保存到: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250113_45start\\2\\20250113_Na-CTX_2.25gNaPre_0gNa-stdLB-op-45start_1_smh-als.pkl\n"
     ]
    }
   ],
   "source": [
    "# 主函数\n",
    "def main():\n",
    "    # 配置参数\n",
    "    path_dirs = [r'Z:\\data space+\\C. elegans chemotaxis\\2025\\20250113_45start\\2']\n",
    "    key_word = ''\n",
    "    # 选择哪一段数据进行处理\n",
    "    slice_vec = [3,6]\n",
    "    # 时长，noise_lim，time_inv, max_dist\n",
    "    key_params = [1.5, 250, 5, 100]\n",
    "    \n",
    "    plate_types = ['circle', 'rectangle']\n",
    "    plate_type_idx = 1\n",
    "    save_as_pickle = True\n",
    "    concat_pkl = False\n",
    "    columns_for_concat = []\n",
    "    \n",
    "    \n",
    "    # 查找文件\n",
    "    merge_files, merge_paths, merge_dirs = find_merge_files(path_dirs, key_word, slice_vec)\n",
    "    print(f\"共找到 {len(merge_files)} 个文件，准备处理...\")\n",
    "    print('\\n'.join(merge_files))\n",
    "    # 批量处理文件\n",
    "    all_data,file_keyinfo = process_all_files(\n",
    "        merge_paths, merge_files, merge_dirs, key_params,\n",
    "        plate_types, plate_type_idx, save_as_pickle, concat_pkl, columns_for_concat\n",
    "    )\n",
    "    \n",
    "    # 保存合并数据\n",
    "    if concat_pkl:\n",
    "        # 以日期_文件名+关键词信息输出总的df为pickle\n",
    "        concat_output_path = os.path.join(path_dirs[0], f'{file_keyinfo}_{key_word}_all.pkl')\n",
    "        save_concatenated_data(all_data, concat_output_path)\n",
    "\n",
    "# 运行主函数\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fa7413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_concatenated_data(pickle_folder_ls, output_path,\n",
    "                           columns_for_concat=[], key_1='.pkl',\n",
    "                           key_2='', key_3='',\n",
    "                           nokey_1='*'):\n",
    "    \"\"\"保存合并后的数据。\"\"\"\n",
    "    \n",
    "    pickle_files= []\n",
    "    file_ls_all = []\n",
    "    for pickle_folder in pickle_folder_ls:\n",
    "        file_ls = [f for f in os.listdir(pickle_folder) if (key_1 in f) and(key_2 in f) and(key_3 in f) and (nokey_1 not in f) ]\n",
    "        # 读取所有pickle文件并合并为一个Dataframe\n",
    "        file_ls_all+=file_ls\n",
    "        pickle_files += [os.path.join(pickle_folder, f) for f in file_ls]\n",
    "    print(f'共{len(file_ls_all)}个文件:\\n', *file_ls_all, sep='\\n')\n",
    "    # 读取所有数据并合并\n",
    "    all_data = []\n",
    "    for pickle_file in pickle_files:\n",
    "        print('reading:', pickle_file, '\\n')\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            df_p = pickle.load(f)  # 加载 Pickle 文件\n",
    "            if len(columns_for_concat):\n",
    "                all_data.append(df_p[columns_for_concat] if columns_for_concat else df_p)\n",
    "            else:\n",
    "                all_data.append(df_p)\n",
    "                \n",
    "    df_als = pd.concat(all_data, ignore_index=True)\n",
    "    df_als = df_als[df_als.speed != 0].reset_index(drop=True)      # 删除速度为0的点并且重置index\n",
    "    df_als.to_pickle(output_path)\n",
    "    print(f\"\\n合并后的数据已保存到: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb5e8684",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共32个文件:\n",
      "\n",
      "20240114_Na-CTX_2.25gNaPre_0gNa-0gLB-op-45start_1_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_0gNa-0gLB-op-45start_2_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_0gNa-stdLB-cl-45start_1_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_0gNa-stdLB-cl-45start_2_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_0gNa-stdLB-op-45start_1_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_0gNa-stdLB-op-45start_2_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_4.5gNa-0gLB-op-45start_1_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_4.5gNa-0gLB-op-45start_2_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_4.5gNa-stdLB-cl-45start_1_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_4.5gNa-stdLB-cl-45start_2_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_4.5gNa-stdLB-op-45start_1_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_4.5gNa-stdLB-op-45start_2_smh-als.pkl\n",
      "20250114_Na-CTX_2.25gNaPre_0gNa-0gLB-cl-45start_1_smh-als.pkl\n",
      "20250114_Na-CTX_2.25gNaPre_0gNa-0gLB-cl-45start_2_smh-als.pkl\n",
      "20250114_Na-CTX_2.25gNaPre_4.5gNa-0gLB-cl-45start_1_smh-als.pkl\n",
      "20250114_Na-CTX_2.25gNaPre_4.5gNa-0gLB-cl-45start_2_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_0gNa-0gLB-op-0start_1_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_0gNa-0gLB-op-0start_2_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_0gNa-stdLB-cl-0start_1_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_0gNa-stdLB-cl-0start_2_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_0gNa-stdLB-op-0start_1_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_0gNa-stdLB-op-0start_2_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_4.5gNa-0gLB-op-0start_1_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_4.5gNa-0gLB-op-0start_2_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_4.5gNa-stdLB-cl-0start_1_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_4.5gNa-stdLB-cl-0start_2_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_4.5gNa-stdLB-op-0start_1_smh-als.pkl\n",
      "20240114_Na-CTX_2.25gNaPre_4.5gNa-stdLB-op-0start_2_smh-als.pkl\n",
      "20250114_Na-CTX_2.25gNaPre_0gNa-0gLB-cl-0start_1_smh-als.pkl\n",
      "20250114_Na-CTX_2.25gNaPre_0gNa-0gLB-cl-0start_2_smh-als.pkl\n",
      "20250114_Na-CTX_2.25gNaPre_4.5gNa-0gLB-cl-0start_1_smh-als.pkl\n",
      "20250114_Na-CTX_2.25gNaPre_4.5gNa-0gLB-cl-0start_2_smh-als.pkl\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\1\\20240114_Na-CTX_2.25gNaPre_0gNa-0gLB-op-45start_1_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\1\\20240114_Na-CTX_2.25gNaPre_0gNa-0gLB-op-45start_2_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\1\\20240114_Na-CTX_2.25gNaPre_0gNa-stdLB-cl-45start_1_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\1\\20240114_Na-CTX_2.25gNaPre_0gNa-stdLB-cl-45start_2_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\1\\20240114_Na-CTX_2.25gNaPre_0gNa-stdLB-op-45start_1_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\1\\20240114_Na-CTX_2.25gNaPre_0gNa-stdLB-op-45start_2_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\2\\20240114_Na-CTX_2.25gNaPre_4.5gNa-0gLB-op-45start_1_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\2\\20240114_Na-CTX_2.25gNaPre_4.5gNa-0gLB-op-45start_2_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\2\\20240114_Na-CTX_2.25gNaPre_4.5gNa-stdLB-cl-45start_1_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\2\\20240114_Na-CTX_2.25gNaPre_4.5gNa-stdLB-cl-45start_2_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\2\\20240114_Na-CTX_2.25gNaPre_4.5gNa-stdLB-op-45start_1_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\2\\20240114_Na-CTX_2.25gNaPre_4.5gNa-stdLB-op-45start_2_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\3\\20250114_Na-CTX_2.25gNaPre_0gNa-0gLB-cl-45start_1_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\3\\20250114_Na-CTX_2.25gNaPre_0gNa-0gLB-cl-45start_2_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\3\\20250114_Na-CTX_2.25gNaPre_4.5gNa-0gLB-cl-45start_1_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\3\\20250114_Na-CTX_2.25gNaPre_4.5gNa-0gLB-cl-45start_2_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114_1\\1\\20240114_Na-CTX_2.25gNaPre_0gNa-0gLB-op-0start_1_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114_1\\1\\20240114_Na-CTX_2.25gNaPre_0gNa-0gLB-op-0start_2_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114_1\\1\\20240114_Na-CTX_2.25gNaPre_0gNa-stdLB-cl-0start_1_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114_1\\1\\20240114_Na-CTX_2.25gNaPre_0gNa-stdLB-cl-0start_2_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114_1\\1\\20240114_Na-CTX_2.25gNaPre_0gNa-stdLB-op-0start_1_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114_1\\1\\20240114_Na-CTX_2.25gNaPre_0gNa-stdLB-op-0start_2_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114_1\\2\\20240114_Na-CTX_2.25gNaPre_4.5gNa-0gLB-op-0start_1_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114_1\\2\\20240114_Na-CTX_2.25gNaPre_4.5gNa-0gLB-op-0start_2_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114_1\\2\\20240114_Na-CTX_2.25gNaPre_4.5gNa-stdLB-cl-0start_1_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114_1\\2\\20240114_Na-CTX_2.25gNaPre_4.5gNa-stdLB-cl-0start_2_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114_1\\2\\20240114_Na-CTX_2.25gNaPre_4.5gNa-stdLB-op-0start_1_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114_1\\2\\20240114_Na-CTX_2.25gNaPre_4.5gNa-stdLB-op-0start_2_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114_1\\3\\20250114_Na-CTX_2.25gNaPre_0gNa-0gLB-cl-0start_1_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114_1\\3\\20250114_Na-CTX_2.25gNaPre_0gNa-0gLB-cl-0start_2_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114_1\\3\\20250114_Na-CTX_2.25gNaPre_4.5gNa-0gLB-cl-0start_1_smh-als.pkl \n",
      "\n",
      "reading: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114_1\\3\\20250114_Na-CTX_2.25gNaPre_4.5gNa-0gLB-cl-0start_2_smh-als.pkl \n",
      "\n",
      "\n",
      "合并后的数据已保存到: Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\20250114_Na-CTX_18diffusion.pkl\n"
     ]
    }
   ],
   "source": [
    "paths_pickles = [r'Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\1',\n",
    "                r'Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\2',\n",
    "                r'Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\3',\n",
    "                r'Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114_1\\1',\n",
    "                r'Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114_1\\2',\n",
    "                r'Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114_1\\3',\n",
    "                ]\n",
    "\n",
    "output_folder = r'Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114'\n",
    "\n",
    "concat_name = '20250114_Na-CTX_18diffusion.pkl'\n",
    "output_path = os.path.join(output_folder, concat_name)\n",
    "save_concatenated_data(paths_pickles, output_path,key_1='smh-als', columns_for_concat=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b18b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'Z:\\data space+\\C. elegans chemotaxis\\2025\\20250114\\20250114_Na-CTX_18diffusion.pkl'\n",
    "df = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8e4cd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           20240114\n",
       "1           20240114\n",
       "2           20240114\n",
       "3           20240114\n",
       "4           20240114\n",
       "              ...   \n",
       "20720288    20250114\n",
       "20720289    20250114\n",
       "20720290    20250114\n",
       "20720291    20250114\n",
       "20720292    20250114\n",
       "Name: Date, Length: 20720293, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64548446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'X', 'Y', 'Timestamp', 'speed', 'x_velocity', 'y_velocity',\n",
       "       'agl_velocity', 'x_velocity_agl', 'y_velocity_agl', 'agl_speed', 'CTX',\n",
       "       'bearing_left', 'CTX_left', 'bearing_right', 'CTX_right', 'X_org',\n",
       "       'Y_org', 'Disp_to_mid', 'Event', 'Date', 'Condition0', 'Condition1',\n",
       "       'Condition2', 'Condition3', 'Group_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ac806a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Condition0':'TrainCon', 'Condition1':'LBType',\n",
    "                  'Condition2':'Lid',\n",
    "                  'Condition3':'TestCon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f98aed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemotaxis",
   "language": "python",
   "name": "chemotaxis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
