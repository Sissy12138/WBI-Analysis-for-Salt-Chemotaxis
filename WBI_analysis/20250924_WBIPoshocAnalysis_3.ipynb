{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0e61737",
   "metadata": {},
   "source": [
    "# Pos-hoc Batch Analysis\n",
    "合并多个数据集的结果，分析神经元编码变量的相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b118794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"D:\\data analysis\\code\\WBI_analysis\")  # 例如 r\"C:\\Users\\YourName\\Project\"\n",
    "import AnalysisMethod as am\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import WBIFunctions as WBI\n",
    "from datetime import datetime\n",
    "from matplotlib_venn import venn2, venn3\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import shutil\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from upsetplot import UpSet, from_contents\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from matplotlib.gridspec import GridSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb148d95",
   "metadata": {},
   "source": [
    "## 韦恩图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da95fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_eventnote_neuron_sets(df, neuron_col=\"Neuron\", event_col=\"EventNote\",\n",
    "                                title='',event_order = [],\n",
    "                                color_dict = {},save_path=None):\n",
    "    \"\"\"\n",
    "    根据 EventNote 将神经元集合可视化:\n",
    "    - 如果 EventNote 种类 <=3, 使用韦恩图\n",
    "    - 否则, 使用 UpSet plot\n",
    "    \"\"\"\n",
    "    # 按事件分组，取神经元集合\n",
    "    event_groups = df.groupby(event_col)[neuron_col].apply(set).to_dict()\n",
    "    event_notes = list(event_groups.keys())\n",
    "    \n",
    "\n",
    "    print(\"=== 统计信息 ===\")\n",
    "    total_neurons = len(set().union(*event_groups.values()))\n",
    "    print(f\"总神经元数: {total_neurons}\")\n",
    "    for ev, s in event_groups.items():\n",
    "        print(f\"{ev}: {len(s)} ({len(s)/total_neurons:.1%})\")\n",
    "    \n",
    "    # 绘图\n",
    "    if len(event_notes) == 2:\n",
    "        set1, set2 = event_groups[event_notes[0]], event_groups[event_notes[1]]\n",
    "        plt.figure(figsize=(10,8))\n",
    "        if len(color_dict):\n",
    "            color1 = color_dict[event_notes[0]]\n",
    "            color2 = color_dict[event_notes[1]]\n",
    "            venn2([set1, set2], set_labels=event_notes, set_colors=[color1, color2])\n",
    "        else:\n",
    "            venn2([set1, set2], set_labels=event_notes)\n",
    "        plt.title(title)\n",
    "        \n",
    "    elif len(event_notes) == 3:\n",
    "        set1, set2, set3 = event_groups[event_notes[0]], event_groups[event_notes[1]], event_groups[event_notes[2]]\n",
    "        plt.figure(figsize=(10,8))\n",
    "        if len(color_dict):\n",
    "            color1 = color_dict[event_notes[0]]\n",
    "            color2 = color_dict[event_notes[1]]\n",
    "            color3 = color_dict[event_notes[2]]\n",
    "            venn3([set1, set2, set3], set_labels=event_notes, set_colors=[color1, color2,color3])\n",
    "        else:\n",
    "            venn3([set1, set2, set3], set_labels=event_notes)\n",
    "        plt.title(title)\n",
    "        \n",
    "    else:\n",
    "        if len(event_order):\n",
    "            \n",
    "            event_groups_ordered = {k: event_groups[k] for k in event_order if k in event_groups}\n",
    "            print(event_groups_ordered)\n",
    "            upset_data = from_contents(event_groups_ordered)\n",
    "        else:\n",
    "            upset_data = from_contents(event_groups)\n",
    "\n",
    "        # 创建 UpSet 对象并绘制\n",
    "        up = UpSet(upset_data, show_counts=True, show_percentages=False,\n",
    "                   sort_by='degree', \n",
    "        orientation='horizontal')\n",
    "        up.plot()\n",
    "\n",
    "        # 总数（所有神经元去重后）\n",
    "        total = len(set().union(*event_groups.values()))\n",
    "\n",
    "        # 访问左侧条形图的 Axes（通常是第一个）\n",
    "        fig = plt.gcf()\n",
    "        print(len(fig.axes))\n",
    "        ax_left = fig.axes[-2]\n",
    "        # 遍历文字对象，替换为 \"数量 (比例%)\"\n",
    "        for txt in ax_left.texts:\n",
    "            count = int(txt.get_text())  # 原始数量\n",
    "            perc = 100 * count / total\n",
    "            txt.set_text(f\"{count} ({perc:.1f}%)\")\n",
    "            txt.set_fontsize(13)\n",
    "            txt.set_color(\"black\")\n",
    "        # 修改上方条形图\n",
    "        ax_top = fig.axes[-1]\n",
    "        # 修改 xlabel\n",
    "        ax_top.set_ylabel(\"# of Neuron\", fontsize=15, labelpad=0)\n",
    "\n",
    "        # 也可以修改 xtick label（旋转、改颜色等）\n",
    "        # plt.setp(ax_top.get_xticklabels(), rotation=45, ha=\"right\", fontsize=9, color=\"blue\")\n",
    "        plt.title(title+f'(n={total})', fontsize=20, pad=15)\n",
    "    if save_path:\n",
    "        print(save_path)\n",
    "        plt.savefig(save_path+'\\\\'+title+'.png',bbox_inches='tight', facecolor='white')\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf173f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_eventnote_neuron_sets_2(df, neuron_col=\"Neuron\", event_col=\"EventNote\",\n",
    "                                title='',event_order = [],\n",
    "                                color_dict = {},save_path=None):\n",
    "    \"\"\"\n",
    "    根据 EventNote 将神经元集合可视化:\n",
    "    - 如果 EventNote 种类 <=3, 使用韦恩图\n",
    "    - 否则, 使用 UpSet plot\n",
    "    \"\"\"\n",
    "    # 按事件分组，取神经元集合\n",
    "    event_groups = df.groupby(event_col)[neuron_col].apply(set).to_dict()\n",
    "    event_notes = list(event_groups.keys())\n",
    "    \n",
    "\n",
    "    print(\"=== 统计信息 ===\")\n",
    "    total_neurons = len(set().union(*event_groups.values()))\n",
    "    print(f\"总神经元数: {total_neurons}\")\n",
    "    for ev, s in event_groups.items():\n",
    "        print(f\"{ev}: {len(s)} ({len(s)/total_neurons:.1%})\")\n",
    "    \n",
    "    # 绘图\n",
    "\n",
    "    if len(event_order):\n",
    "        \n",
    "        event_groups_ordered = {k: event_groups[k] for k in event_order if k in event_groups}\n",
    "        print(event_groups_ordered)\n",
    "        upset_data = from_contents(event_groups_ordered)\n",
    "    else:\n",
    "        upset_data = from_contents(event_groups)\n",
    "\n",
    "    # 创建 UpSet 对象并绘制\n",
    "    up = UpSet(upset_data, show_counts=True, show_percentages=False,\n",
    "                sort_by='degree', \n",
    "    orientation='horizontal')\n",
    "    up.plot()\n",
    "\n",
    "    # 总数（所有神经元去重后）\n",
    "    total = len(set().union(*event_groups.values()))\n",
    "\n",
    "    # 访问左侧条形图的 Axes（通常是第一个）\n",
    "    fig = plt.gcf()\n",
    "    print(len(fig.axes))\n",
    "    ax_left = fig.axes[-2]\n",
    "    # 遍历文字对象，替换为 \"数量 (比例%)\"\n",
    "    for txt in ax_left.texts:\n",
    "        count = int(txt.get_text())  # 原始数量\n",
    "        perc = 100 * count / total\n",
    "        txt.set_text(f\"{count} ({perc:.1f}%)\")\n",
    "        txt.set_fontsize(13)\n",
    "        txt.set_color(\"black\")\n",
    "    # 修改上方条形图\n",
    "    ax_top = fig.axes[-1]\n",
    "    # 修改 xlabel\n",
    "    ax_top.set_ylabel(\"# of Neuron\", fontsize=15, labelpad=0)\n",
    "\n",
    "    # 也可以修改 xtick label（旋转、改颜色等）\n",
    "    # plt.setp(ax_top.get_xticklabels(), rotation=45, ha=\"right\", fontsize=9, color=\"blue\")\n",
    "    plt.title(title+f'(n={total})', fontsize=20, pad=15)\n",
    "    if save_path:\n",
    "        print(save_path)\n",
    "        plt.savefig(save_path+'\\\\'+title+'.png',bbox_inches='tight', facecolor='white')\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70c1061",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_fs = [r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\done',r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\to_do_q']\n",
    "sub_folder_path = []\n",
    "for p_f_all in p_fs:\n",
    "    sub_folder_path  += [os.path.join(p_f_all,f) for f in os.listdir(p_f_all) if os.path.isdir(p_f_all+'\\\\'+f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b972a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_order = ['Velocity', 'Speed','CTX','Angular Velocity','Curvature','Forw-Rev','RevStart','RevEnd', 'Turn', 'TurnStart','TurnEnd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb2305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p_cr = pd.read_csv(r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\done\\\\20250115_4.5g-24d-ov_08\\\\2025-10-23-16_AnalysisFigs\\\\CorrAnalysis\\\\20250115_4.5g-24d-ov_08_corr_p_cor.csv')\n",
    "    \n",
    "# df_p_cr['EventNote'] = df_p_cr['EventNote'].fillna(df_p_cr['Event'])\n",
    "df_p_cr.loc[(df_p_cr['true_r'].abs()>=0.3) & (df_p_cr['p_cor']<=0.05), 'sign']  = 1\n",
    "df_p_cr.loc[(df_p_cr['true_r'].isna()) & (df_p_cr['p_cor']<=0.05), 'sign']  = 1\n",
    "df_p_cr_sign = df_p_cr[df_p_cr['sign']==1]\n",
    "df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='curvature','EventNote'] = 'Curvature'\n",
    "df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='turn_pc','EventNote'] = 'Turn'\n",
    "df_p_cr_sign.loc[df_p_cr_sign['EventNote'] == 'turn_cor','EventNote'] = 'Turn'\n",
    "df_p_cr_sign.loc[df_p_cr_sign['EventNote'] == 'forward','EventNote'] = 'Forw-Rev'\n",
    "df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='CoilingStart','EventNote'] = 'TurnStart'\n",
    "df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='CoilingEnd','EventNote'] = 'TurnEnd'\n",
    "df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='sm_velocity','EventNote'] = 'Velocity'\n",
    "df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='sm_speed','EventNote'] = 'Speed'\n",
    "df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='sm_ang','EventNote'] = 'Angular Velocity'\n",
    "df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='sm_CTX','EventNote'] = 'CTX'\n",
    "df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='OmegaStart','EventNote'] = 'TurnStart'\n",
    "df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='OmegaEnd','EventNote'] = 'TurnEnd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f765133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p_cr_sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55869fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_path = r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI'+'\\\\251026vennplot'\n",
    "os.makedirs(s_path, exist_ok=True)\n",
    "# 合并所有的子df，满足条件的收集\n",
    "# df_p_sign_all = []\n",
    "for f_path in sub_folder_path:\n",
    "    f = os.path.basename(f_path)\n",
    "    fig_folder = [f for f in os.listdir(f_path) if 'AnalysisFigs' in f]\n",
    "\n",
    "    folders = [\n",
    "        f for f in os.listdir(f_path)\n",
    "        if 'AnalysisFigs' in f and os.path.isdir(os.path.join(f_path, f))\n",
    "    ]\n",
    "    if not folders:\n",
    "        # raise FileNotFoundError(\"No folder containing 'AnalysisFigs' found.\")\n",
    "        continue\n",
    "    # 步骤2：获取每个文件夹的最后修改时间\n",
    "    folder_with_time = [\n",
    "        (f, os.path.getmtime(os.path.join(f_path, f)))  # getmtime 返回时间戳\n",
    "        for f in folders\n",
    "    ]\n",
    "    # 步骤3：按修改时间降序排序，取最新的\n",
    "    latest_folder = max(folder_with_time, key=lambda x: x[1])[0]\n",
    "    file_name = f+'_corr_p_cor.csv'\n",
    "    file_path = f_path+'\\\\'+latest_folder+'\\\\CorrAnalysis\\\\'+file_name\n",
    "    print(file_path)\n",
    "    try:\n",
    "        df_p_cr = pd.read_csv(file_path)\n",
    "    except:\n",
    "        continue\n",
    "    df_p_cr['EventNote'] = df_p_cr['EventNote'].fillna(df_p_cr['Event'])\n",
    "    df_p_cr.loc[(df_p_cr['true_r'].abs()>=0.3) & (df_p_cr['p_cor']<=0.05), 'sign']  = 1\n",
    "    df_p_cr.loc[(df_p_cr['true_r'].isna()) & (df_p_cr['p_cor']<=0.05), 'sign']  = 1\n",
    "    df_p_cr_sign = df_p_cr[df_p_cr['sign']==1]\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='curvature','EventNote'] = 'Curvature'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='turn_pc','EventNote'] = 'Turn'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote'] == 'turn_cor','EventNote'] = 'Turn'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote'] == 'forward','EventNote'] = 'Forw-Rev'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='CoilingStart','EventNote'] = 'TurnStart'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='CoilingEnd','EventNote'] = 'TurnEnd'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='sm_velocity','EventNote'] = 'Velocity'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='sm_speed','EventNote'] = 'Speed'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='sm_ang','EventNote'] = 'Angular Velocity'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='sm_CTX','EventNote'] = 'CTX'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='OmegaStart','EventNote'] = 'TurnStart'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='OmegaEnd','EventNote'] = 'TurnEnd'\n",
    "    # df_p_cr_sign = df_p_cr_sign[df_p_cr_sign['EventNote'] != 'OmegaStart']\n",
    "    \n",
    "    # df_p_sign_all.append(df_p_cr_sign)\n",
    "\n",
    "    # colors_ls = ['#60A5FA',\"#DD8452\",'#55A868',\"#FDFB74\" ,'#8B5CF6','#819CA9']\n",
    "    # color_dict_1 = {'Speed':colors_ls[0],'Velocity':colors_ls[1], 'CTX':colors_ls[2],'RevStart':colors_ls[3]}\n",
    "    plot_eventnote_neuron_sets_2(df_p_cr_sign, neuron_col=\"Neuron\", \n",
    "                               event_col=\"EventNote\",event_order=event_order,\n",
    "                               color_dict={}, save_path=s_path, title=f)\n",
    "    # 可视化亚群\n",
    "    \n",
    "    # df_svc = df_p_cr_sign[df_p_cr_sign['EventNote'].isin(['Speed', 'Velocity','CTX'])]\n",
    "    # plot_eventnote_neuron_sets(df_svc, neuron_col=\"Neuron\", event_col=\"EventNote\", title=f+'_spdvelctx',color_dict=color_dict_1, save_path = s_path)\n",
    "    # df_svrs = df_p_cr_sign[df_p_cr_sign['EventNote'].isin(['Speed', 'Velocity','RevStart'])]\n",
    "    # plot_eventnote_neuron_sets(df_svrs, neuron_col=\"Neuron\", event_col=\"EventNote\", title=f+'_spdvelrevstart',color_dict=color_dict_1, save_path = s_path)\n",
    "    # df_cvrs = df_p_cr_sign[df_p_cr_sign['EventNote'].isin(['CTX', 'Velocity','RevStart'])]\n",
    "    # plot_eventnote_neuron_sets(df_cvrs, neuron_col=\"Neuron\", event_col=\"EventNote\", title=f+'_ctxvelrevstart',color_dict=color_dict_1, save_path = s_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b97bba2",
   "metadata": {},
   "source": [
    "# 汇总分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82398e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_fs = [r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\done',r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\to_do_q']\n",
    "sub_folder_path = []\n",
    "for p_f_all in p_fs:\n",
    "    sub_folder_path  += [os.path.join(p_f_all,f) for f in os.listdir(p_f_all) if os.path.isdir(p_f_all+'\\\\'+f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4453f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并所有的子df，满足条件的收集\n",
    "df_p_sign_all = []\n",
    "for f_path in sub_folder_path:\n",
    "    f = os.path.basename(f_path)\n",
    "    fig_folder = [f for f in os.listdir(f_path) if 'AnalysisFigs' in f]\n",
    "\n",
    "    folders = [\n",
    "        f for f in os.listdir(f_path)\n",
    "        if 'AnalysisFigs' in f and os.path.isdir(os.path.join(f_path, f))\n",
    "    ]\n",
    "    if not folders:\n",
    "        # raise FileNotFoundError(\"No folder containing 'AnalysisFigs' found.\")\n",
    "        continue\n",
    "    # 步骤2：获取每个文件夹的最后修改时间\n",
    "    folder_with_time = [\n",
    "        (f, os.path.getmtime(os.path.join(f_path, f)))  # getmtime 返回时间戳\n",
    "        for f in folders\n",
    "    ]\n",
    "    # 步骤3：按修改时间降序排序，取最新的\n",
    "    latest_folder = max(folder_with_time, key=lambda x: x[1])[0]\n",
    "    file_name = f+'_corr_p_cor.csv'\n",
    "    file_path = f_path+'\\\\'+latest_folder+'\\\\CorrAnalysis\\\\'+file_name\n",
    "    print(file_path)\n",
    "    try:\n",
    "        df_p_cr = pd.read_csv(file_path)\n",
    "    except:\n",
    "        continue\n",
    "    df_p_cr['EventNote'] = df_p_cr['EventNote'].fillna(df_p_cr['Event'])\n",
    "    df_p_cr.loc[(df_p_cr['true_r'].isna()) & (df_p_cr['p_cor']<=0.05), 'sign']  = 1\n",
    "    df_p_cr.loc[(df_p_cr['true_r'].abs()>=0.3) & (df_p_cr['p_cor']<=0.05), 'sign']  = 1\n",
    "    df_p_cr_sign = df_p_cr[df_p_cr['sign']==1]\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='curvature','EventNote'] = 'Curvature'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='turn_pc','EventNote'] = 'Turn'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='turn_cor','EventNote'] = 'Turn'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='forward','EventNote'] = 'Forw-Rev'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='CoilingStart','EventNote'] = 'TurnStart'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='sm_velocity','EventNote'] = 'Velocity'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='sm_speed','EventNote'] = 'Speed'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='sm_ang','EventNote'] = 'Angular Velocity'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='sm_CTX','EventNote'] = 'CTX'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='OmegaStart','EventNote'] = 'TurnStart'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='OmegaEnd','EventNote'] = 'TurnEnd'\n",
    "    # df_p_cr_sign = df_p_cr_sign[df_p_cr_sign['EventNote'] != 'OmegaStart']\n",
    "    # df_p_cr_sign = df_p_cr_sign[df_p_cr_sign['EventNote'] != 'turn_cor']\n",
    "    df_p_sign_all.append(df_p_cr_sign)\n",
    "df_sign_all = pd.concat(df_p_sign_all,axis=0)\n",
    "event_ls = df_sign_all['EventNote'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829ee1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_order_color = ['Velocity', 'Speed','CTX','Angular Velocity','Curvature','Forw-Rev','RevStart','RevEnd', 'Turn', 'TurnStart','TurnEnd']\n",
    "# 获取 colormap 对象（新 API）\n",
    "cmap = plt.colormaps['tab10']  # 或 'viridis', 'Set3' 等\n",
    "# 根据事件数量生成颜色字典\n",
    "# color_dict = {event: cmap(i / len(event_order_color)) for i, event in enumerate(event_order_color)}\n",
    "\n",
    "tol_bright_12 = [\n",
    "        \"#332288\",  # dark blue\n",
    "        \"#88CCEE\",  # cyan\n",
    "        \"#44AA99\",  # teal\n",
    "        \"#117733\",  # green\n",
    "        \"#AA4499\",  # purple\n",
    "        \"#6699CC\",  # sky blue\n",
    "        \"#888888\",  # gray\n",
    "        \"#661100\",  # brown\n",
    "        \"#DDCC77\",  # sand\n",
    "        \"#999933\",  # olive\n",
    "        \"#882255\",  \n",
    "        \"#CC6677\",  # rose\n",
    "    ]\n",
    "\n",
    "color_dict = {event: tol_bright_12[i % len(tol_bright_12)] for i, event in enumerate(event_order_color)}\n",
    "event_order = ['Velocity', 'Speed','CTX','Angular Velocity','Curvature','Forw-Rev','RevStart','RevEnd', 'Turn', 'TurnStart','TurnEnd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2099b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计每个 File 下每个 EventNote 的数量\n",
    "counts = df_sign_all.groupby(['File','EventNote']).size().unstack(fill_value=0)\n",
    "counts = counts[event_order]  # 按指定顺序\n",
    "\n",
    "# 绘制堆叠柱状图\n",
    "files = counts.index\n",
    "bottom = [0]*len(files)\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "ax = plt.gca()\n",
    "ax.set_axisbelow(True)  # ✅ 网格在柱子下方\n",
    "plt.grid(linestyle='dashed', color='grey',lw=2, alpha=0.3, which='major', axis='y',zorder=0)\n",
    "for event in event_order:\n",
    "    plt.bar(files, counts[event], bottom=bottom, color=color_dict[event], label=event)\n",
    "    # 更新底部位置\n",
    "    bottom = [b + c for b, c in zip(bottom, counts[event])]\n",
    "\n",
    "# plt.xlabel('File')\n",
    "plt.ylabel('# of Neurons',fontsize=18)\n",
    "new_labels = [f.split(\"_\")[0]+'_'+ str(int(f.split(\"_\")[-1])) for f in files]\n",
    "plt.xticks(ticks=range(len(files)), labels=new_labels, rotation=45, fontsize=15, ha='right')\n",
    "plt.tick_params(axis='y', labelsize = 15)\n",
    "plt.title('')\n",
    "plt.legend(title='Variable', loc='upper right', bbox_to_anchor = (1.16,0.9),fontsize = 15)\n",
    "plt.ylim([0,200])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad52efa",
   "metadata": {},
   "source": [
    "### 对每种变量的检出比例作图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33ace6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ====== 合并所有子 df（你的原始部分保持不变）======\n",
    "df_p_sign_all = []\n",
    "for f_path in sub_folder_path:\n",
    "    f = os.path.basename(f_path)\n",
    "    folders = [\n",
    "        f for f in os.listdir(f_path)\n",
    "        if 'AnalysisFigs' in f and os.path.isdir(os.path.join(f_path, f))\n",
    "    ]\n",
    "    if not folders:\n",
    "        continue\n",
    "    folder_with_time = [\n",
    "        (f, os.path.getmtime(os.path.join(f_path, f)))\n",
    "        for f in folders\n",
    "    ]\n",
    "    latest_folder = max(folder_with_time, key=lambda x: x[1])[0]\n",
    "    file_name = f + '_corr_p_cor.csv'\n",
    "    file_path = os.path.join(f_path, latest_folder, 'CorrAnalysis', file_name)\n",
    "    print(file_path)\n",
    "    try:\n",
    "        df_p_cr = pd.read_csv(file_path)\n",
    "    except:\n",
    "        continue\n",
    "    df_p_cr['EventNote'] = df_p_cr['EventNote'].fillna(df_p_cr['Event'])\n",
    "    df_p_cr.loc[(df_p_cr['true_r'].isna()) & (df_p_cr['p_cor'] <= 0.05), 'sign'] = 1\n",
    "    df_p_cr.loc[(df_p_cr['true_r'].abs() >= 0.3) & (df_p_cr['p_cor'] <= 0.05), 'sign'] = 1\n",
    "    df_p_cr_sign = df_p_cr[df_p_cr['sign'] == 1]\n",
    "\n",
    "    # 统一事件名称\n",
    "    mapping = {\n",
    "        'curvature': 'Curvature',\n",
    "        'turn_pc': 'Turn',\n",
    "        'turn_cor': 'Turn',\n",
    "        'forward': 'Forw-Rev',\n",
    "        'CoilingStart': 'TurnStart',\n",
    "        'sm_velocity': 'Velocity',\n",
    "        'sm_speed': 'Speed',\n",
    "        'sm_ang': 'Angular Velocity',\n",
    "        'sm_CTX': 'CTX',\n",
    "        'OmegaStart': 'TurnStart',\n",
    "        'OmegaEnd': 'TurnEnd'\n",
    "    }\n",
    "    df_p_cr_sign['EventNote'] = df_p_cr_sign['EventNote'].replace(mapping)\n",
    "    df_p_sign_all.append(df_p_cr_sign)\n",
    "\n",
    "df_sign_all = pd.concat(df_p_sign_all, axis=0)\n",
    "\n",
    "# ====== 绘图部分 ======\n",
    "\n",
    "event_order = [\n",
    "    'Velocity', 'Speed', 'CTX', 'Angular Velocity',\n",
    "    'Curvature', 'Forw-Rev', 'RevStart', 'RevEnd',\n",
    "    'Turn', 'TurnStart', 'TurnEnd'\n",
    "]\n",
    "\n",
    "tol_bright_12 = [\n",
    "    \"#332288\", \"#88CCEE\", \"#44AA99\", \"#117733\",\n",
    "    \"#AA4499\", \"#6699CC\", \"#888888\", \"#661100\",\n",
    "    \"#DDCC77\", \"#999933\", \"#882255\", \"#CC6677\"\n",
    "]\n",
    "\n",
    "color_dict = {event: tol_bright_12[i % len(tol_bright_12)] for i, event in enumerate(event_order)}\n",
    "\n",
    "# 统计每个文件下每种事件的数量\n",
    "counts = df_sign_all.groupby(['File', 'EventNote']).size().unstack(fill_value=0)\n",
    "# 计算每个文件总计\n",
    "counts['total'] = counts.sum(axis=1)\n",
    "# 计算比例\n",
    "proportions = counts[event_order].div(counts['total'], axis=0)\n",
    "\n",
    "# 绘制每个事件的折线图\n",
    "\n",
    "\n",
    "files = proportions.index\n",
    "new_labels = [f.split(\"_\")[0] + '_' + str(int(f.split(\"_\")[-1])) for f in files]\n",
    "x = range(len(files))\n",
    "\n",
    "for i, event in enumerate(event_order):\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.subplot(len(event_order), 1, i + 1)\n",
    "    y = proportions[event]\n",
    "    mean_y = y.mean()\n",
    "    plt.plot(x, y, color='black', linewidth=1.5, zorder=1)  # 黑色折线\n",
    "    plt.axhline(mean_y, color='red', linestyle='--', linewidth=2, alpha=0.8, zorder=0)\n",
    "    plt.scatter(x, y, color=color_dict[event], s=80, edgecolors='k', zorder=2)  # 圆点\n",
    "    plt.xticks(ticks=x, labels=new_labels, rotation=45, ha='right', fontsize=12)\n",
    "    plt.ylabel('Proportion', fontsize=14)\n",
    "    plt.title(event+' mean:'+str(round(mean_y,2)), fontsize=16, color=color_dict[event])\n",
    "    plt.grid(linestyle='dashed', color='grey', lw=1, alpha=0.4, axis='y')\n",
    "    # plt.ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3627f66b",
   "metadata": {},
   "source": [
    "### 总神经元数量检出相关神经元比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d5807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并所有的子df，满足条件的收集\n",
    "df_p_sign_all = []\n",
    "for f_path in sub_folder_path:\n",
    "    f = os.path.basename(f_path)\n",
    "    fig_folder = [f for f in os.listdir(f_path) if 'AnalysisFigs' in f]\n",
    "\n",
    "    folders = [\n",
    "        f for f in os.listdir(f_path)\n",
    "        if 'AnalysisFigs' in f and os.path.isdir(os.path.join(f_path, f))\n",
    "    ]\n",
    "    if not folders:\n",
    "        # raise FileNotFoundError(\"No folder containing 'AnalysisFigs' found.\")\n",
    "        continue\n",
    "    # 步骤2：获取每个文件夹的最后修改时间\n",
    "    folder_with_time = [\n",
    "        (f, os.path.getmtime(os.path.join(f_path, f)))  # getmtime 返回时间戳\n",
    "        for f in folders\n",
    "    ]\n",
    "    # 步骤3：按修改时间降序排序，取最新的\n",
    "    latest_folder = max(folder_with_time, key=lambda x: x[1])[0]\n",
    "    file_name = f+'_corr_p_cor.csv'\n",
    "    file_path = f_path+'\\\\'+latest_folder+'\\\\CorrAnalysis\\\\'+file_name\n",
    "    print(file_path)\n",
    "    try:\n",
    "        df_p_cr = pd.read_csv(file_path)\n",
    "    except:\n",
    "        continue\n",
    "    df_p_cr['EventNote'] = df_p_cr['EventNote'].fillna(df_p_cr['Event'])\n",
    "    df_p_cr.loc[(df_p_cr['true_r'].isna()) & (df_p_cr['p_cor']<=0.05), 'sign']  = 1\n",
    "    df_p_cr.loc[(df_p_cr['true_r'].abs()>=0.3) & (df_p_cr['p_cor']<=0.05), 'sign']  = 1\n",
    "    df_p_cr_sign = df_p_cr\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='curvature','EventNote'] = 'Curvature'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='turn_pc','EventNote'] = 'Turn'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='turn_cor','EventNote'] = 'Turn'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='forward','EventNote'] = 'Forw-Rev'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='CoilingStart','EventNote'] = 'TurnStart'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='sm_velocity','EventNote'] = 'Velocity'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='sm_speed','EventNote'] = 'Speed'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='sm_ang','EventNote'] = 'Angular Velocity'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='sm_CTX','EventNote'] = 'CTX'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='OmegaStart','EventNote'] = 'TurnStart'\n",
    "    df_p_cr_sign.loc[df_p_cr_sign['EventNote']=='OmegaEnd','EventNote'] = 'TurnEnd'\n",
    "    # df_p_cr_sign = df_p_cr_sign[df_p_cr_sign['EventNote'] != 'OmegaStart']\n",
    "    # df_p_cr_sign = df_p_cr_sign[df_p_cr_sign['EventNote'] != 'turn_cor']\n",
    "    df_p_sign_all.append(df_p_cr_sign)\n",
    "df_sign_all = pd.concat(df_p_sign_all,axis=0)\n",
    "df_sign_max = (\n",
    "    df_sign_all.groupby(['File', 'Neuron'], as_index=False)['sign']\n",
    "    .max()\n",
    ")\n",
    "sign_counts = (\n",
    "    df_sign_max.groupby(['File', 'sign'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    "    .rename(columns={0: 'Sign_0', 1: 'Sign_1'})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a56b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sign_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e775a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 3️⃣ 绘制堆叠柱状图 ===\n",
    "files = sign_counts.index\n",
    "x = range(len(files))\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "ax = plt.gca()\n",
    "ax.set_axisbelow(True)\n",
    "plt.grid(linestyle='dashed', color='grey', lw=1, alpha=0.3, axis='y', zorder=0)\n",
    "\n",
    "# 先绘制 sign=0（浅灰色）底层\n",
    "plt.bar(x, sign_counts['Sign_1'], color='#555555', label='Sign = 1', zorder=1)\n",
    "# 再绘制 sign=1（深灰色）上层\n",
    "plt.bar(x, sign_counts['Sign_0'], bottom=sign_counts['Sign_1'],\n",
    "        color='#D3D3D3', label='Sign = 0', zorder=2)\n",
    "\n",
    "# === 4️⃣ 坐标轴美化 ===\n",
    "new_labels = [f.split(\"_\")[0] + '_' + str(int(f.split(\"_\")[-1])) for f in files]\n",
    "plt.xticks(ticks=x, labels=new_labels, rotation=45, ha='right', fontsize=12)\n",
    "plt.ylabel('# of Neurons', fontsize=14)\n",
    "plt.xlabel('File', fontsize=14)\n",
    "plt.title('Significant vs Non-significant Neurons per File', fontsize=16)\n",
    "plt.legend(fontsize=12, loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4afc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sign_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ed20b9",
   "metadata": {},
   "source": [
    "# 汇总分析2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6503d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_fs = [r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\done',r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\to_do_q']\n",
    "sub_folder_path = []\n",
    "for p_f_all in p_fs:\n",
    "    sub_folder_path  += [os.path.join(p_f_all,f) for f in os.listdir(p_f_all) if os.path.isdir(p_f_all+'\\\\'+f)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67957cd6",
   "metadata": {},
   "source": [
    "## 绘制各个数据集的运动参数图\n",
    "多个子图分别可视化运动参数\n",
    "连续性变量：前进速度，curvature曲率，角速度\n",
    "离散型变量：前进后退，转向行为\n",
    "标记：将mask和quiescence底色标记出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06651fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 求1的开始和结束点\n",
    "def get_turn_interval(df, col_name):\n",
    "    # labels打印矩形\n",
    "    labels = df[col_name].values\n",
    "    n = len(labels)\n",
    "    # 找出连续的 label==1 区间\n",
    "    turn_intervals = []\n",
    "    in_turn = False\n",
    "    start = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        if labels[i] == 1 and not in_turn:\n",
    "            # turn开始\n",
    "            start = i\n",
    "            in_turn = True\n",
    "        elif labels[i] != 1 and in_turn:\n",
    "            # turn结束\n",
    "            end = i - 1\n",
    "            turn_intervals.append((start, end))\n",
    "            in_turn = False\n",
    "\n",
    "    # 如果最后一个点也是turn状态\n",
    "    if in_turn:\n",
    "        turn_intervals.append((start, n - 1))\n",
    "    return turn_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a93423",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_path = r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI'+'\\\\251030MotVar'\n",
    "os.makedirs(s_path, exist_ok=True)\n",
    "# 合并所有的子df，满足条件的收集\n",
    "# df_p_sign_all = []\n",
    "for f_path in sub_folder_path:\n",
    "    f = os.path.basename(f_path)\n",
    "    file_df = [f for f in os.listdir(f_path) if '_MotionMidlineMatchVol.pkl' in f]\n",
    "    \n",
    "    if not len(file_df):\n",
    "        # raise FileNotFoundError(\"No folder containing 'AnalysisFigs' found.\")\n",
    "        continue\n",
    "    df_mot_vol = pd.read_pickle(os.path.join(f_path,file_df[0]))\n",
    "    print(df_mot_vol.columns)\n",
    "    df_mot_vol[\"head_velocity\"] = df_mot_vol.apply(WBI.signed_norm, axis=1)\n",
    "    df_mot_vol[\"head_speed\"] = df_mot_vol[\"head_velocity\"].abs()\n",
    "    # 连续运动变量平滑\n",
    "    window_size = 15\n",
    "    # 计算移动平均值\n",
    "    df_mot_vol['sm_velocity'] = df_mot_vol['head_velocity'].rolling(window=window_size, min_periods=1).mean()\n",
    "    df_mot_vol['sm_speed'] = df_mot_vol['head_speed'].rolling(window=window_size, min_periods=1).mean()\n",
    "    # # 平滑ctx\n",
    "    window_size = 15\n",
    "    # 计算移动平均值\n",
    "    df_mot_vol['sm_CTX'] = df_mot_vol['CTX_left'].rolling(window=window_size, min_periods=1).mean()\n",
    "    df_mot_vol['sm_ang'] = df_mot_vol['ang_velocity'].rolling(window=15, min_periods=1).mean()\n",
    "    df_mot_vol['sm_curvature'] = df_mot_vol['curvature'].rolling(window=1, min_periods=1).mean()\n",
    "    df_t = df_mot_vol[['Vol_Time','mask','head_velocity','quies_pc', 'head_speed','CTX_left','sm_ang','sm_curvature','forward','turn_pc']]\n",
    "    n_sub_figs = 5\n",
    "    max_t  = df_t.Vol_Time.max()\n",
    "    fig,ax = plt.subplots(n_sub_figs,1, figsize=(max_t/600*8,8),sharex=True)\n",
    "    fig.suptitle(f)\n",
    "    turn_pc_ints = get_turn_interval(df_t, 'turn_pc')\n",
    "    forward_ints = get_turn_interval(df_t, 'forward')\n",
    "    mask_ints = get_turn_interval(df_t, 'mask')\n",
    "    quies_ints = get_turn_interval(df_t, 'mask')\n",
    "    ax0 = ax[0].plot(df_t['Vol_Time'],df_t['head_velocity'])\n",
    "    ax[0].set_title('Velocity')\n",
    "    ax[1].plot(df_t['Vol_Time'],df_t['head_speed'])\n",
    "    ax[1].set_title('Speed')\n",
    "    ax[2].plot(df_t['Vol_Time'],df_t['CTX_left'])\n",
    "    ax[2].set_title('CTX_left')\n",
    "    ax[3].plot(df_t['Vol_Time'],df_t['sm_curvature'])\n",
    "    ax[3].set_title('Curvature')\n",
    "    ax[4].plot(df_t['Vol_Time'],df_t['sm_ang'])\n",
    "    ax[4].set_title('sm_ang')\n",
    "    for i in range(n_sub_figs):\n",
    "        for start, end in forward_ints:\n",
    "            ax[i].axvspan(df_t['Vol_Time'].iloc[start],df_t['Vol_Time'].iloc[end] , color=\"#51E6FA\", alpha=1)  # alpha控制透明度\n",
    "            # ax[i].set_title('Reverse')\n",
    "        for start, end in turn_pc_ints:\n",
    "            ax[i].axvspan(df_t['Vol_Time'].iloc[start],df_t['Vol_Time'].iloc[end] , color=\"#F7FA51\", alpha=1)  # alpha控制透明度\n",
    "            # ax[i].set_title('Turn')\n",
    "        for start, end in mask_ints:\n",
    "            ax[i].axvspan(df_t['Vol_Time'].iloc[start],df_t['Vol_Time'].iloc[end] , color=\"#3F3F4E\", alpha=0.7)  # alpha控制透明度\n",
    "        for start, end in quies_ints:\n",
    "            ax[i].axvspan(df_t['Vol_Time'].iloc[start],df_t['Vol_Time'].iloc[end] , color=\"#3F3F4E\", alpha=0.7)  # alpha控制透明度\n",
    "    ax[-1].set_xlabel('Time(s)')\n",
    "    plt.tight_layout()\n",
    "    # break\n",
    "    plt.savefig(s_path+'//'+f+'_mot_var.png',bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3613145",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_path = r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI'+'\\\\251022TrajPlots'\n",
    "os.makedirs(s_path, exist_ok=True)\n",
    "# 合并所有的子df，满足条件的收集\n",
    "# df_p_sign_all = []\n",
    "for f_path in sub_folder_path:\n",
    "    f = os.path.basename(f_path)\n",
    "    file_df = [f for f in os.listdir(f_path) if '_MotionMidlineMatchVol.pkl' in f]\n",
    "    \n",
    "    if not len(file_df):\n",
    "        # raise FileNotFoundError(\"No folder containing 'AnalysisFigs' found.\")\n",
    "        continue\n",
    "    df_mot_vol = pd.read_pickle(os.path.join(f_path,file_df[0]))\n",
    "    print(df_mot_vol.columns)\n",
    "    df_mot_vol[\"head_velocity\"] = df_mot_vol.apply(WBI.signed_norm, axis=1)\n",
    "    df_mot_vol[\"head_speed\"] = df_mot_vol[\"head_velocity\"].abs()\n",
    "    # 连续运动变量平滑\n",
    "    window_size = 15\n",
    "    # 计算移动平均值\n",
    "    df_mot_vol['sm_velocity'] = df_mot_vol['head_velocity'].rolling(window=window_size, min_periods=1).mean()\n",
    "    df_mot_vol['sm_speed'] = df_mot_vol['head_speed'].rolling(window=window_size, min_periods=1).mean()\n",
    "    # # 平滑ctx\n",
    "    window_size = 15\n",
    "    # 计算移动平均值\n",
    "    df_mot_vol['sm_CTX'] = df_mot_vol['CTX_left'].rolling(window=window_size, min_periods=1).mean()\n",
    "    df_mot_vol['sm_ang'] = df_mot_vol['ang_velocity'].rolling(window=15, min_periods=1).mean()\n",
    "    df_mot_vol['sm_curvature'] = df_mot_vol['curvature'].rolling(window=1, min_periods=1).mean()\n",
    "    df_t = df_mot_vol[['Vol_Time','mask','head_velocity','quies_pc', 'head_speed','CTX_left','sm_ang','sm_curvature','forward','turn_pc']]\n",
    "    n_sub_figs = 7\n",
    "    fig,ax = plt.subplots(n_sub_figs,1, figsize=(10,10),sharex=True)\n",
    "    fig.suptitle(f)\n",
    "    turn_pc_ints = get_turn_interval(df_t, 'turn_pc')\n",
    "    forward_ints = get_turn_interval(df_t, 'forward')\n",
    "    mask_ints = get_turn_interval(df_t, 'mask')\n",
    "    quies_ints = get_turn_interval(df_t, 'mask')\n",
    "    ax0 = ax[0].plot(df_t['Vol_Time'],df_t['head_velocity'])\n",
    "    ax[0].set_title('Velocity')\n",
    "    ax[1].plot(df_t['Vol_Time'],df_t['head_speed'])\n",
    "    ax[1].set_title('Speed')\n",
    "    ax[2].plot(df_t['Vol_Time'],df_t['CTX_left'])\n",
    "    ax[2].set_title('CTX_left')\n",
    "    ax[3].plot(df_t['Vol_Time'],df_t['sm_curvature'])\n",
    "    ax[3].set_title('Curvature')\n",
    "    ax[4].plot(df_t['Vol_Time'],df_t['sm_ang'])\n",
    "    ax[4].set_title('sm_ang')\n",
    "    for start, end in forward_ints:\n",
    "        ax[5].axvspan(df_t['Vol_Time'].iloc[start],df_t['Vol_Time'].iloc[end] , color='blue', alpha=1)  # alpha控制透明度\n",
    "        ax[5].set_title('Reverse')\n",
    "    for start, end in turn_pc_ints:\n",
    "        ax[6].axvspan(df_t['Vol_Time'].iloc[start],df_t['Vol_Time'].iloc[end] , color='orange', alpha=1)  # alpha控制透明度\n",
    "        ax[6].set_title('Turn')\n",
    "    for i in range(n_sub_figs):\n",
    "        for start, end in mask_ints:\n",
    "            ax[i].axvspan(df_t['Vol_Time'].iloc[start],df_t['Vol_Time'].iloc[end] , color='grey', alpha=0.3)  # alpha控制透明度\n",
    "        for start, end in quies_ints:\n",
    "            ax[i].axvspan(df_t['Vol_Time'].iloc[start],df_t['Vol_Time'].iloc[end] , color='grey', alpha=0.6)  # alpha控制透明度\n",
    "    plt.tight_layout()\n",
    "    break\n",
    "    # plt.savefig(s_path+'//'+f+'_traj.png',bbox_inches='tight')\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4090fd2c",
   "metadata": {},
   "source": [
    "## 提取子文件夹文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0aca61",
   "metadata": {},
   "source": [
    "提取每个子文件夹的图片，存储在指定文件夹下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a74b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder = \"Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\clusteringplots\"  # 请修改为实际路径\n",
    "for f_path in sub_folder_path:\n",
    "    f = os.path.basename(f_path)\n",
    "    fig_folder = [f for f in os.listdir(f_path) if 'AnalysisFigs' in f]\n",
    "    folders = [\n",
    "        f for f in os.listdir(f_path)\n",
    "        if 'AnalysisFigs' in f and os.path.isdir(os.path.join(f_path, f))\n",
    "    ]\n",
    "    if not folders:\n",
    "        # raise FileNotFoundError(\"No folder containing 'AnalysisFigs' found.\")\n",
    "        continue\n",
    "    # 步骤2：获取每个文件夹的最后修改时间\n",
    "    folder_with_time = [\n",
    "        (f, os.path.getmtime(os.path.join(f_path, f)))  # getmtime 返回时间戳\n",
    "        for f in folders\n",
    "    ]\n",
    "    # 步骤3：按修改时间降序排序，取最新的\n",
    "    latest_folder = max(folder_with_time, key=lambda x: x[1])[0]\n",
    "    file_name = 'cluster_calcium_heatmap(smooth_10).png'\n",
    "    file_path = f_path+'\\\\'+latest_folder+'\\\\HierClustering\\\\'+file_name\n",
    "\n",
    "    # 检查源文件是否存在\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"文件不存在: {file_path}\")\n",
    "        continue\n",
    "    \n",
    "    # 构建新文件名和目标路径\n",
    "    # 使用子文件夹名称作为新文件名的一部分，避免重复\n",
    "    new_file_name = f\"{f}_cluster(smh_10).png\"  # 可以根据需要调整命名规则\n",
    "    target_path = os.path.join(target_folder, new_file_name)\n",
    "    \n",
    "    try:\n",
    "        # 复制文件到目标文件夹\n",
    "        shutil.copy2(file_path, target_path)\n",
    "        print(f\"成功复制: {file_path} -> {target_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"复制失败: {file_path}, 错误: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26281efd",
   "metadata": {},
   "source": [
    "## 汇总做轨迹图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae42ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_path = r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI'+'\\\\251022TrajPlots'\n",
    "os.makedirs(s_path, exist_ok=True)\n",
    "# 合并所有的子df，满足条件的收集\n",
    "# df_p_sign_all = []\n",
    "for f_path in sub_folder_path:\n",
    "    f = os.path.basename(f_path)\n",
    "    file_df = [f for f in os.listdir(f_path) if '_MotionMidlineMatchVol.pkl' in f]\n",
    "    \n",
    "    if not len(file_df):\n",
    "        # raise FileNotFoundError(\"No folder containing 'AnalysisFigs' found.\")\n",
    "        continue\n",
    "    df = pd.read_pickle(os.path.join(f_path,file_df[0]))\n",
    "\n",
    "    df_t = df[['Vol_Time','X','Y','CTX_left']]\n",
    "    fig,ax = plt.subplots(2,1, figsize=(6,4))\n",
    "    fig.suptitle(f)\n",
    "    ax0 = ax[0].scatter(df_t['X'],df_t['Y'],c=df_t['Vol_Time'], cmap='cool',s=0.8)\n",
    "    ax[0].set_aspect(1)\n",
    "    ax[0].set_xlim(0,40)\n",
    "    divider = make_axes_locatable(ax[0])\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)  # size控制宽度，pad控制间距\n",
    "    cbar = plt.colorbar(ax0, cax=cax)\n",
    "    ax[0].set_title('Time')\n",
    "    # cbar.set_label('Time', rotation=270, labelpad=15) \n",
    "    ax1 = ax[1].scatter(df_t['X'],df_t['Y'],c=df_t['CTX_left'], cmap='bwr',vmin=-1,vmax=1,s=0.8)\n",
    "    ax[1].set_aspect(1)\n",
    "    ax[1].set_xlim(0,40)\n",
    "    ax[1].set_title('CTX_left')\n",
    "    divider = make_axes_locatable(ax[1])\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)  # size控制宽度，pad控制间距\n",
    "    cbar = plt.colorbar(ax1, cax=cax)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(s_path+'//'+f+'_traj.png',bbox_inches='tight')\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07959129",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_path = r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI'+'\\\\251022TrajPlots_2'\n",
    "os.makedirs(s_path, exist_ok=True)\n",
    "\n",
    "for f_path in sub_folder_path:\n",
    "    f = os.path.basename(f_path)\n",
    "    file_df = [f for f in os.listdir(f_path) if '_MotionMidlineMatchVol.pkl' in f]\n",
    "    if not len(file_df):\n",
    "        continue\n",
    "    df = pd.read_pickle(os.path.join(f_path,file_df[0]))\n",
    "\n",
    "\n",
    "    \n",
    "    df_t = df[['Vol_Time','X','Y','CTX_left']]\n",
    "    \n",
    "    # 计算数据的高宽比，但限制在合理范围内\n",
    "    x_range = 40\n",
    "    y_range = df_t['Y'].max() - df_t['Y'].min()\n",
    "    aspect_ratio = y_range / x_range\n",
    "    \n",
    "    # 设置高度限制\n",
    "    min_height = 2  # 最小高度\n",
    "    max_height = 10 # 最大高度\n",
    "    \n",
    "    fixed_width = 6\n",
    "    subplot_height = max(min_height, min(max_height, fixed_width * aspect_ratio))\n",
    "    total_height = subplot_height * 2 + 0.8\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 1, figsize=(fixed_width, total_height))\n",
    "    fig.suptitle(f)\n",
    "    \n",
    "    # 绘图代码与方法1相同\n",
    "    ax0 = ax[0].scatter(df_t['X'], df_t['Y'], c=df_t['Vol_Time'], cmap='cool', s=0.8)\n",
    "    ax[0].set_aspect('equal')\n",
    "    ax[0].set_xlim(0, 40)\n",
    "    ax[0].set_ylim(df_t['Y'].min(), df_t['Y'].max())\n",
    "    divider = make_axes_locatable(ax[0])\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar = plt.colorbar(ax0, cax=cax)\n",
    "    ax[0].set_title('Time')\n",
    "    \n",
    "    ax1 = ax[1].scatter(df_t['X'], df_t['Y'], c=df_t['CTX_left'], cmap='bwr', vmin=-1, vmax=1, s=0.8)\n",
    "    ax[1].set_aspect('equal')\n",
    "    ax[1].set_xlim(0, 40)\n",
    "    ax[1].set_ylim(df_t['Y'].min(), df_t['Y'].max())\n",
    "    ax[1].set_title('CTX_left')\n",
    "    divider = make_axes_locatable(ax[1])\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    cbar = plt.colorbar(ax1, cax=cax)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(s_path + '//' + f + '_traj.png', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c0ada1",
   "metadata": {},
   "source": [
    "## 汇总分别对单数据热图标记显著神经元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4863110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcium_heatmap_sign(calcium_intensity,df, col_draw, suptitle, neuron_ids,model,w_p2m,\n",
    "                     show_id_stride=20, show_vol_stride=10,\n",
    "                    heatmap_range=(None,0.5),\n",
    "                    unit_w=0.05, unit_h = 0.2, cal_height_ratio=20, wspace=0.125, hspace = 0.125\n",
    "                    ,bound_cluster = [],smooth_kernel=15,\n",
    "                    font_size=90, font_color='black',\n",
    "                   idx=None,vmin=0,vmax=1,threshold=None,xlabel='',\n",
    "                   cmap='jet',level=None,sig_matrix=None, signal_save_path=None, filename=''):\n",
    "    '''\n",
    "    calcium_intensity: （神经元个数 x 时间点）\n",
    "    df： PCA和行为对齐\n",
    "    col_draw: 需要画图的列名\n",
    "    unit_w: 单位宽度(对应时间)\n",
    "    unit_h: 单位高度（对应神经元数量）\n",
    "    cal_height_ratio : 预期钙信号热图相对运动参数等条图的高度比例\n",
    "    '''\n",
    "    # 神经元数量及时间长度\n",
    "    num_neurons, num_vols = calcium_intensity.shape\n",
    "    \n",
    "    \n",
    "    if ('turn_cor' in col_draw)& ('turn_pc' in col_draw):\n",
    "        # 两者画在一起\n",
    "        turn_merge = True\n",
    "        num_row = len(col_draw)\n",
    "    else:\n",
    "        turn_merge = False\n",
    "        num_row = len(col_draw)+1\n",
    "    \n",
    "    height_ratios = [1.5 for i in range(num_row-1)]\n",
    "    height_ratios.append(cal_height_ratio)\n",
    "    num_sig_cols = len(sig_matrix.columns)\n",
    "    gs = GridSpec(num_row, 4 + num_sig_cols, height_ratios=height_ratios,\n",
    "                   width_ratios=[0.3,25,50,0.3] + [0.5]*num_sig_cols, wspace=wspace, hspace=hspace)\n",
    "    # gs = GridSpec(num_row, 4, height_ratios=height_ratios, width_ratios=[0.3,25,50, 0.3], wspace=wspace, hspace=hspace)\n",
    "    fig_h = (unit_h*num_neurons)/ cal_height_ratio *  sum(height_ratios)\n",
    "    fig = plt.figure(figsize=(unit_w*num_vols+unit_h*num_neurons*1.1, fig_h))\n",
    "    fig.suptitle(suptitle, fontsize=100, fontweight='bold')\n",
    "    # 热图\n",
    "    ax0 = fig.add_subplot(gs[-1, 1])\n",
    "    # 树状图在上方\n",
    "    ax1 = fig.add_subplot(gs[-4:-1, 1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Override the default linewidth.\n",
    "    mpl.rcParams['lines.linewidth'] = font_size*0.2\n",
    "    am.plot_dendrogram(model, truncate_mode=\"level\", p=level, \\\n",
    "                    no_labels=True, orientation='bottom', ax=ax1,color_threshold=threshold,\n",
    "                   above_threshold_color='blue')\n",
    "    ax1.set_xlim(ax1.get_xlim())\n",
    "    # ax1.set_xlim([0.5,2])\n",
    "    ax1.xaxis.set_ticks_position('none')  # 不显示x轴的刻度\n",
    "    ax1.yaxis.set_ticks_position('none')  # 不显示y轴的刻度\n",
    "    ax1.set_xticks([])  # 移除x轴的刻度标记\n",
    "    ax1.set_yticks([])\n",
    "    ax1.invert_yaxis()\n",
    "    for spine in ax1.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    ax_list=list(np.linspace(0,w_p2m.shape[0],24,dtype=int))\n",
    "    # X_sort = w_p2m[idx][:,idx]\n",
    "    X_sort = w_p2m.copy()\n",
    "    # 重新排序之后画热图\n",
    "    \n",
    "    # 设置热图的corlorbar\n",
    "    # [left, bottom, width, height]\n",
    "    cbar_ax = fig.add_axes([0.0, 0.15, 0.01, 0.4])\n",
    "    ax0=sns.heatmap(X_sort, ax=ax0, cmap=cmap, vmin=vmin, vmax=vmax,cbar=True, cbar_ax = cbar_ax, square=False)\n",
    "    cbar_ax.yaxis.set_ticks_position(\"left\")  # 将刻度放到左侧\n",
    "    cbar_ax.yaxis.set_label_position(\"left\")  # 将标签放到左侧\n",
    "    cbar_ax.tick_params(labelsize=font_size, pad = font_size*0.75)\n",
    "    cbar_ax.set_ylabel('Correlation', fontsize = font_size*1.25, labelpad = font_size*0.75)\n",
    "    \n",
    "    ax0.set_xticks(ax_list, ax_list,fontsize=font_size)\n",
    "    ax0.set_yticks(ax_list, ax_list,fontsize=font_size)\n",
    "    ax0.tick_params(axis = 'x', pad = font_size*0.75)\n",
    "    ax0.tick_params(axis='y', labelrotation=0,pad = font_size*0.75)  # 将y轴标签设置为水平\n",
    "    # 逆转y轴以对齐钙信号热图\n",
    "    ax0.invert_yaxis()\n",
    "    ax0.set_xlabel(xlabel,fontsize=font_size*1.25, labelpad = font_size*0.75)\n",
    "\n",
    "\n",
    "    bound_pmd = bound_cluster\n",
    "    bound_m1 = bound_cluster\n",
    "    # 画边界\n",
    "    for i in bound_pmd:\n",
    "        ax0.axhline(y=i, color='white', linestyle='--')\n",
    "    for i in bound_m1:\n",
    "        ax0.axvline(x=i, color='white', linestyle='--')\n",
    "    \n",
    "    # 循环画运动参数\n",
    "    for i, col in enumerate(col_draw):\n",
    "        # 添加子图\n",
    "        ax = fig.add_subplot(gs[i, 2])  # 从第一行开始\n",
    "        vector = df[col].values\n",
    "        if ('turn' not in col) & ('forward' not in col):\n",
    "            heatmap_data = vector[np.newaxis, :]  # 变为 1 行 N 列\n",
    "            im = ax.imshow(heatmap_data, cmap='jet', aspect='auto')  # 绘制热图\n",
    "\n",
    "            # 调整 colorbar 参数\n",
    "            cax = fig.add_subplot(gs[i, 3])  # colorbar 放在右侧\n",
    "            cbar = plt.colorbar(im, cax=cax, fraction=0.5, orientation='vertical', aspect = 3)\n",
    "            if 'smoothed_' in col:\n",
    "                col = col.replace('smoothed_', '')\n",
    "            cbar.ax.set_title(col, fontsize = font_size*0.85, pad = font_size*0.25 )\n",
    "            cbar.ax.tick_params(labelsize=font_size*0.5, width=5, length=5, pad = font_size*0.25)  # 设置刻度大小和宽度\n",
    "            # 设置标题和轴\n",
    "            ax.set_xticks([])  # 隐藏x轴刻度\n",
    "            ax.set_yticks([])  # 隐藏y轴刻度\n",
    "        elif ('turn' in col) & (turn_merge==False):\n",
    "            heatmap_data = vector[np.newaxis, :]  # 变为 1 行 N 列\n",
    "            # Define two colors\n",
    "            colors = [ 'grey','#FFC832']\n",
    "            # Create a ListedColormap\n",
    "            two_color_cmap = ListedColormap(colors)\n",
    "            im = ax.imshow(heatmap_data, cmap=two_color_cmap, aspect='auto')  # 选择 colormap\n",
    "            # 添加颜色条\n",
    "            cax = fig.add_subplot(gs[i, 3])  # colorbar 放在右侧\n",
    "            cbar = plt.colorbar(im, cax=cax, fraction=0.5, orientation='vertical', aspect = 3)  # 通过 plt.colorbar 添加颜色条\n",
    "            cbar.ax.set_title(col, fontsize = font_size*0.85, pad = font_size*0.25 )\n",
    "            ax.set_xticks([])  # 设置x轴刻度\n",
    "            ax.set_yticks([])  # 隐藏y轴刻度\n",
    "        elif 'forward_quies' == col:\n",
    "            # 不只输出forward,将quies加上\n",
    "            heatmap_data = vector[np.newaxis, :]  # 变为 1 行 N 列\n",
    "            # Define two colors\n",
    "            colors = [ 'red','blue','white']\n",
    "            # Create a ListedColormap\n",
    "            cmap = ListedColormap(colors)\n",
    "            bounds = [-0.5, 0.5, 1.5, 2.5]\n",
    "            norm = BoundaryNorm(bounds, cmap.N)\n",
    "            im = ax.imshow(heatmap_data, cmap=cmap, norm=norm, aspect='auto')\n",
    "            # 添加颜色条\n",
    "            cax = fig.add_subplot(gs[i, 3])  # colorbar 放在右侧\n",
    "            cbar = plt.colorbar(im, cax=cax, fraction=0.5, orientation='vertical', aspect = 3)  # 通过 plt.colorbar 添加颜色条\n",
    "            cbar.ax.set_title(col, fontsize = font_size*0.85, pad = font_size*0.25 )\n",
    "            ax.set_xticks([])  # 设置x轴刻度\n",
    "            ax.set_yticks([])  # 隐藏y轴刻度\n",
    "        elif 'forward' == col:\n",
    "            heatmap_data = vector[np.newaxis, :]  # 变为 1 行 N 列\n",
    "            # Define two colors\n",
    "            colors = [ 'red','blue']\n",
    "            # Create a ListedColormap\n",
    "            two_color_cmap = ListedColormap(colors)\n",
    "            im = ax.imshow(heatmap_data, cmap=two_color_cmap, aspect='auto')  # 选择 colormap\n",
    "            # 添加颜色条\n",
    "            cax = fig.add_subplot(gs[i, 3])  # colorbar 放在右侧\n",
    "            cbar = plt.colorbar(im, cax=cax, fraction=0.5, orientation='vertical', aspect = 3)  # 通过 plt.colorbar 添加颜色条\n",
    "            cbar.ax.set_title(col, fontsize = font_size*0.85, pad = font_size*0.25 )\n",
    "            ax.set_xticks([])  # 设置x轴刻度\n",
    "            ax.set_yticks([])  # 隐藏y轴刻度\n",
    "\n",
    "    # 倒数第二行\n",
    "    if turn_merge:\n",
    "        ax = fig.add_subplot(gs[-2, 2])  # 第一行\n",
    "        vector_pc = df['turn_pc'].values\n",
    "        vector_cor = df['turn_cor'].values\n",
    "\n",
    "        heatmap_data_pc = vector_pc[np.newaxis, :]\n",
    "        heatmap_data_cor = vector_cor[np.newaxis, :]\n",
    "\n",
    "        # --------- PC 层：灰色(0) + 黄色(1)\n",
    "        color_pc = ['grey', '#FFC832']\n",
    "        cmap_pc = ListedColormap(color_pc)\n",
    "        ax.imshow(heatmap_data_pc, cmap=cmap_pc, aspect='auto')\n",
    "\n",
    "        cax = fig.add_subplot(gs[-2, 3])  # colorbar 放在右侧\n",
    "        cbar = plt.colorbar(im, cax=cax, fraction=0.5, orientation='vertical', aspect = 3)\n",
    "        cbar.ax.set_title('coiling/turn', fontsize = font_size*0.85, pad = font_size*0.25 )\n",
    "        cbar.ax.tick_params(labelsize=font_size*0.5, width=5, length=5, pad = font_size*0.25)\n",
    "\n",
    "        # 去掉坐标\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    \n",
    "    # 绘制钙信号热力图 \n",
    "    ax = fig.add_subplot(gs[-1, 2])  # 最后一行\n",
    "    heatmap=sns.heatmap(calcium_intensity, vmin=heatmap_range[0], vmax=heatmap_range[1],\n",
    "                        xticklabels=np.arange(num_vols)[::show_vol_stride],\n",
    "                        yticklabels=neuron_ids[::show_id_stride],cbar=False,cmap='jet',\n",
    "                         cbar_kws={'orientation':'horizontal'}, ax=ax)\n",
    "    \n",
    "    # 调整colorbar位置到heatmap下方\n",
    "    fig = ax.get_figure()\n",
    "    # 获取heatmap的位置信息\n",
    "    pos = ax.get_position()\n",
    "\n",
    "    # 将colorbar放在heatmap正下方，与其等宽\n",
    "    cax = fig.add_axes([pos.x0, pos.y0 - 0.08, pos.width, 0.02])  # 在heatmap下方0.08的位置\n",
    "\n",
    "    text_str = 'ΔR/R0'\n",
    "    colorbar = plt.colorbar(heatmap.collections[0], cax=cax, orientation='horizontal')\n",
    "    colorbar.ax.tick_params(labelsize=font_size, pad=font_size*0.75)\n",
    "    colorbar.set_label(text_str, fontsize=font_size*1.25, labelpad=font_size*0.75)\n",
    "    \n",
    "    # # 竖直白线根据轨迹分区\n",
    "    # if len(start_indices):\n",
    "    #     x_sticks = start_indices[1:-1]\n",
    "    #     for x in x_sticks:\n",
    "    #         ax.axvline(x=x, color='white', linestyle='--', linewidth=font_size*0.12)  # Adjust color and linestyle as needed\n",
    "    \n",
    "    # 横向根据聚类结果分块\n",
    "    if len(bound_cluster):\n",
    "        for i in bound_cluster:\n",
    "            ax.axhline(y=i, color='white', linestyle='--', linewidth=font_size*0.12)\n",
    "    \n",
    "    # ax.set_yticks(ticks=np.arange(0, num_neurons, show_id_stride), labels=neuron_ids[::show_id_stride],fontsize=font_size, \n",
    "    #               color=font_color)\n",
    "#     ax.set_xticks(ticks=np.arange(0, num_vols, show_vol_stride), labels=np.arange(num_vols)[::show_vol_stride],fontsize=font_size, rotation=45, color=font_color)\n",
    "    ax.set_xticks(ticks=np.arange(0, num_vols, show_vol_stride), labels=df.Vol_Time.astype(int).values[::show_vol_stride],\n",
    "                  fontsize=font_size, rotation=0, color=font_color)\n",
    "    ax.tick_params(pad = font_size*0.75)\n",
    "    #     ax.set_xticks(ticks = df.Vol_Time\n",
    "    # plt.xticks(ticks=np.arange(0, num_vols, show_vol_stride), labels=np.arange(0,1300,100),fontsize=font_size, rotation=45, color=font_color)\n",
    "    # plt.title('Calcium activity traces (ΔR/R0) Heatmap',fontsize=font_size,)\n",
    "    ax.set_xlabel('Time(s)',fontsize=font_size*1.25, color=font_color, labelpad = font_size*0.75)\n",
    "#     ax.set_ylabel('Neuron Index',fontsize=font_size*1.25,color=font_color, labelpad = font_size*0.75)\n",
    "    # plt.axis('off')\n",
    "    # plt.gca().spines['left'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    # 设置y轴的刻度位置，使其从顶部开始，因为神经元通常从顶部向下绘制\n",
    "    ax.invert_yaxis()\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.yaxis.set_label_position('right')\n",
    "\n",
    "    # 绘制显著性热图\n",
    "    event_order_color = ['Velocity', 'Speed','CTX','Angular Velocity','Curvature','Forw-Rev','RevStart','RevEnd', 'Turn', 'TurnStart','TurnEnd']\n",
    "    # 获取 colormap 对象（新 API）\n",
    "    # cmap = plt.colormaps['tab20']  # 或 'viridis', 'Set3' 等\n",
    "    # Tol Bright 12 colors (RGB from Paul Tol's scientific color schemes)\n",
    "    tol_bright_12 = [\n",
    "        \"#332288\",  # dark blue\n",
    "        \"#88CCEE\",  # cyan\n",
    "        \"#44AA99\",  # teal\n",
    "        \"#117733\",  # green\n",
    "        \"#AA4499\",  # purple\n",
    "        \"#6699CC\",  # sky blue\n",
    "        \"#888888\",  # gray\n",
    "        \"#661100\",  # brown\n",
    "        \"#DDCC77\",  # sand\n",
    "        \"#999933\",  # olive\n",
    "        \"#882255\",  \n",
    "        \"#CC6677\",  # rose\n",
    "    ]\n",
    "\n",
    "    color_dict = {event: tol_bright_12[i % len(tol_bright_12)] for i, event in enumerate(event_order_color)}\n",
    "\n",
    "    # 根据事件数量生成颜色字典\n",
    "    # color_dict = {event: cmap(i / len(event_order_color)) for i, event in enumerate(event_order_color)}\n",
    "    # 画显著性热图\n",
    "    existing_columns = [col for col in event_order_color if col in sig_matrix.columns]\n",
    "    sig_matrix_ordered = sig_matrix[existing_columns]\n",
    "    for j, event in enumerate(sig_matrix_ordered.columns):\n",
    "        ax_sig = fig.add_subplot(gs[-1, 3+j], sharey=ax)  # 在原 calcium heatmap 右侧追加\n",
    "        data = sig_matrix_ordered[[event]].values  # 单列矩阵 (num_neurons, 1)\n",
    "        cmap_sig = ListedColormap(['white', color_dict[event]])  # 白=不显著，红=显著\n",
    "        \n",
    "        sns.heatmap(\n",
    "        data,\n",
    "        cmap=cmap_sig,\n",
    "        cbar=False,\n",
    "        ax=ax_sig,\n",
    "        vmin=0, vmax=1,        # 固定范围，防止自动缩放\n",
    "        xticklabels=False,\n",
    "        yticklabels=False,\n",
    "        square=False\n",
    "        )\n",
    "        ax_sig.set_xticks([])\n",
    "        # ax_sig.set_yticks([])\n",
    "        ax_sig.invert_yaxis()\n",
    "        ax_sig.set_xlabel(\n",
    "            event, \n",
    "            fontsize=font_size * 0.7,   # 调小字号\n",
    "            labelpad=font_size * 0.2,   # 与热图间距\n",
    "            rotation=60,                # 旋转以防重叠\n",
    "            ha='right'                  # 对齐方式\n",
    "        )\n",
    "        # 移除上方默认标题\n",
    "        ax_sig.set_title(\"\")\n",
    "        \n",
    "        # 去掉边框\n",
    "        for spine in ax_sig.spines.values():\n",
    "            spine.set_visible(False)\n",
    "        # if j == len(sig_matrix.columns):\n",
    "        #     ax_sig.set_yticks(np.linspace(0.5, len(data)-0.5, 5))  # 例如显示 5 个刻度\n",
    "        #     ax_sig.set_yticklabels(\n",
    "        #     np.linspace(1, len(data), 5, dtype=int),\n",
    "        #     fontsize=font_size * 0.6\n",
    "        #     )\n",
    "        #     ax_sig.tick_params(axis='y', which='both', left=False, right=True)  # 刻度线放右侧\n",
    "        # else:\n",
    "        #     ax_sig.set_yticks([])\n",
    "\n",
    "#     ax.gca().invert_yaxis()\n",
    "#     plt.subplots_adjust(left=0.125, bottom=0.1, right=0.1, top=0.1, wspace=0.2, hspace=0.35)\n",
    "    # plt.show()\n",
    "    if smooth_kernel:\n",
    "        plt.savefig(f'{signal_save_path}/{filename}clus_cal_heatmap(smooth_{smooth_kernel}).png', transparent=False,dpi=100)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.savefig(f'{signal_save_path}/{filename}clus_cal_heatmap.png', transparent=False,dpi=100)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1c4abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_path = r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI'+'\\\\251024LabeledHeatmap'\n",
    "os.makedirs(s_path, exist_ok=True)\n",
    "# 合并所有的子df，满足条件的收集\n",
    "# df_p_sign_all = []\n",
    "for f_path in sub_folder_path:\n",
    "    f = os.path.basename(f_path)\n",
    "    # 读取与荧光对齐的运动数据\n",
    "    file_df = [f for f in os.listdir(f_path+'\\\\') if '_MotionMidlineMatchVol.pkl' in f]\n",
    "    if not len(file_df):\n",
    "        # raise FileNotFoundError(\"No folder containing 'AnalysisFigs' found.\")\n",
    "        pass\n",
    "    df_mot_vol = pd.read_pickle(os.path.join(f_path,file_df[0]))\n",
    "\n",
    "    # 读取重新排序后的荧光数据以及分析结果csv\n",
    "    fig_folder = [f for f in os.listdir(f_path) if 'AnalysisFigs' in f]\n",
    "    folders = [\n",
    "        f for f in os.listdir(f_path)\n",
    "        if 'AnalysisFigs' in f and os.path.isdir(os.path.join(f_path, f))\n",
    "    ]\n",
    "\n",
    "    if not folders:\n",
    "        raise FileNotFoundError(\"No folder containing 'AnalysisFigs' found.\")\n",
    "    # 步骤2：获取每个文件夹的最后修改时间\n",
    "    folder_with_time = [\n",
    "        (f, os.path.getmtime(os.path.join(f_path, f)))  # getmtime 返回时间戳\n",
    "        for f in folders\n",
    "    ]\n",
    "    # 步骤3：按修改时间降序排序，取最新的\n",
    "    latest_folder = max(folder_with_time, key=lambda x: x[1])[0]\n",
    "    save_path = f_path+'\\\\'+latest_folder\n",
    "    corr_path = f_path+'\\\\'+latest_folder+'\\\\CorrAnalysis\\\\'\n",
    "\n",
    "    p_val_path = [f for f in os.listdir(corr_path) if '_corr_p_cor.csv' in f][0]\n",
    "    df_p_cr = pd.read_csv(corr_path+'\\\\'+p_val_path)\n",
    "    df_p_cr['EventNote'] = df_p_cr['EventNote'].fillna(df_p_cr['Event'])\n",
    "    df_p_cr['sign'] = 0\n",
    "\n",
    "    turn_mask = (df_p_cr['Event'].isin(['turn_pc', 'turn_cor'])) & (df_p_cr['EventNote'].isna())\n",
    "    forward_mask = (df_p_cr['Event'] == 'forward') & (df_p_cr['EventNote'].isna())\n",
    "    df_p_cr['EventNote'] = np.where(turn_mask, 'Turn', \n",
    "                        np.where(forward_mask, 'Forw-Rev', df_p_cr['EventNote']))\n",
    "    # 这里比较奇怪，但是秉持着能用就行的原则，暂且靠两步修改\n",
    "    df_p_cr.loc[df_p_cr['EventNote']=='forward','EventNote'] = 'Forw-Rev'\n",
    "    df_p_cr.loc[df_p_cr['EventNote'].isin(['turn_pc','turn_cor']),'EventNote'] = 'Turn'\n",
    "\n",
    "    df_p_cr.loc[df_p_cr['EventNote']=='curvature','EventNote'] = 'Curvature'\n",
    "    # df_p_cr.loc[(df_p_cr['Event'].isin(['turn_pc', 'turn_cor'])) & \n",
    "    #             (df_p_cr['EventNote'].isna()), 'EventNote'] = 'Turn'\n",
    "    # df_p_cr.loc[(df_p_cr['Event']=='forward') & (df_p_cr['EventNote'].isna()),'EventNote'] = 'Forw-Rev'\n",
    "\n",
    "    df_p_cr.loc[df_p_cr['EventNote']=='CoilingStart','EventNote'] = 'TurnStart'\n",
    "    df_p_cr.loc[df_p_cr['EventNote']=='sm_velocity','EventNote'] = 'Velocity'\n",
    "    df_p_cr.loc[df_p_cr['EventNote']=='sm_speed','EventNote'] = 'Speed'\n",
    "    df_p_cr.loc[df_p_cr['EventNote']=='sm_ang','EventNote'] = 'Angular Velocity'\n",
    "    df_p_cr.loc[df_p_cr['EventNote']=='sm_CTX','EventNote'] = 'CTX'\n",
    "    df_p_cr.loc[df_p_cr['EventNote']=='OmegaStart','EventNote'] = 'TurnStart'\n",
    "    df_p_cr.loc[df_p_cr['EventNote']=='OmegaEnd','EventNote'] = 'TurnEnd'\n",
    "    df_p_cr.loc[(df_p_cr['true_r'].abs()>=0.3) & (df_p_cr['p_cor']<=0.05) &\n",
    "                (df_p_cr['EventNote'].notna()) &\n",
    "                (df_p_cr['EventNote'].isin(['Velocity', 'Speed','CTX','Angular Velocity','Curvature','Turn','Forw-Rev'])), 'sign']  = 1\n",
    "    df_p_cr.loc[(df_p_cr['p_cor']<=0.05) &\n",
    "                (df_p_cr['EventNote'].notna()) &\n",
    "                (df_p_cr['EventNote'].isin(['RevStart','RevEnd', 'TurnStart','TurnEnd'])), 'sign']  = 1\n",
    "    # df_p_cr_sign = df_p_cr_sign[df_p_cr_sign['EventNote'] != 'OmegaStart']\n",
    "    # df_p_cr_sign = df_p_cr[df_p_cr['sign']==1]\n",
    "    # df_p_cr_sign = df_p_cr_sign[df_p_cr_sign['EventNote'] != 'turn_cor']\n",
    "\n",
    "    # 由于把turn_pc和turn_cor都合并了\n",
    "    sig_matrix = df_p_cr.pivot_table(\n",
    "    index='Neuron', \n",
    "    columns='EventNote', \n",
    "    values='sign', \n",
    "    aggfunc='max',   # 或 'mean'，取最大值表示“只要有一次显著就记为显著”\n",
    "    fill_value=0\n",
    "    ).reset_index()\n",
    "    sig_matrix['Neuron_num'] = sig_matrix['Neuron'].str.extract('(\\d+)').astype(int)\n",
    "    # 按数字排序\n",
    "    sig_matrix = sig_matrix.sort_values('Neuron_num')\n",
    "    # 删除临时列\n",
    "    sig_matrix = sig_matrix.drop(columns=['Neuron_num','Neuron']).reset_index(drop=True)\n",
    "    # （可选）将 'Neuron' 设置为索引\n",
    "    # sig_matrix = sig_matrix.set_index('Neuron')\n",
    "    # sig_matrix = df_p_cr.pivot(index='Neuron', columns='EventNote', values='sign')\n",
    "\n",
    "\n",
    "    # 钙信号导入\n",
    "    calcium_intensity= np.load(os.path.join(f_path+'\\\\'+latest_folder, 'calcium_intensity_sorted.npy'))\n",
    "    # 根据mask列作预处理\n",
    "\n",
    "    mask = df_mot_vol['mask'].values.astype(bool)   # True 表示要置 NaN\n",
    "    calcium_intensity[:, mask] = np.nan\n",
    "\n",
    "\n",
    "    # save_p = p_f.split('calcium_intensity.npy')[0]\n",
    "    print('文件大小:neuron*timestamp',calcium_intensity.shape)\n",
    "    # 平滑calcium signal： 均值滤波器 (box filter),处理nan值\n",
    "    # scale = 1.5\n",
    "    # for i in range(calcium_intensity.shape[0]):\n",
    "    #     calcium_intensity[i] = (cv2.blur(calcium_intensity[i], (1, 7))*scale)[:,0]\n",
    "    scale = 1.5\n",
    "    for i in range(calcium_intensity.shape[0]):\n",
    "        row = calcium_intensity[i]\n",
    "        mean_val = np.nanmean(row)\n",
    "        row_no_nan = np.where(np.isnan(row), mean_val, row)\n",
    "        smoothed = cv2.blur(row_no_nan.reshape(-1, 1), (7, 1)) * scale\n",
    "        calcium_intensity[i] = smoothed[:, 0]\n",
    "    calcium_intensity[:, mask] = np.nan\n",
    "    # 求前进速度和速率\n",
    "    df_mot_vol[\"head_velocity\"] = df_mot_vol.apply(WBI.signed_norm, axis=1)\n",
    "    df_mot_vol[\"head_speed\"] = df_mot_vol[\"head_velocity\"].abs()\n",
    "    # 连续运动变量平滑\n",
    "    window_size = 15\n",
    "    # 计算移动平均值\n",
    "    df_mot_vol['sm_velocity'] = df_mot_vol['head_velocity'].rolling(window=window_size, min_periods=1).mean()\n",
    "    df_mot_vol['sm_speed'] = df_mot_vol['head_speed'].rolling(window=window_size, min_periods=1).mean()\n",
    "    # # 平滑ctx\n",
    "    window_size = 15\n",
    "    # 计算移动平均值\n",
    "    df_mot_vol['sm_CTX'] = df_mot_vol['CTX_left'].rolling(window=window_size, min_periods=1).mean()\n",
    "    df_mot_vol['sm_ang'] = df_mot_vol['ang_velocity'].rolling(window=window_size, min_periods=1).mean()\n",
    "\n",
    "    choose_index = 0\n",
    "    thresh = 5\n",
    "    links=['ward','average','average','complete']\n",
    "    affs=['euclidean','cosine','cityblock','cosine']\n",
    "    vmin=-0.5\n",
    "    vmax=1\n",
    "    smooth_kernel = 10\n",
    "    print('calcium_intensity.shape',calcium_intensity.shape)\n",
    "\n",
    "    valid_timepoints = ~mask\n",
    "    calcium_valid = calcium_intensity[:, valid_timepoints]\n",
    "    # 使用 np.corrcoef(calcium_intensity) 计算神经元钙信号的相关性矩阵\n",
    "    # 聚类：使用 am.cluster 和指定的链接方式 (link=links[choose_index]) \n",
    "    # 和距离度量 (aff=affs[choose_index]) 对相关性矩阵进行聚类。\n",
    "    idx=am.cluster(np.corrcoef(calcium_valid),link=links[choose_index],aff=affs[choose_index])\n",
    "    print(idx)\n",
    "    # idx为聚类之后的索引\n",
    "    bound=np.cumsum(am.GetBound(np.corrcoef(calcium_valid),link=links[choose_index],aff=affs[choose_index],\n",
    "                                threshold=thresh).astype(int))\n",
    "    # 调用 am.GetBound 计算矩阵分区的边界（bound），通过 np.cumsum 累积求和获取完整的边界数组\n",
    "    print('边界', bound)\n",
    "\n",
    "    calcium_valid = calcium_valid[idx]\n",
    "    calcium_intensity = calcium_intensity[idx]\n",
    "    # calcium_intensity_smd = calcium_intensity.copy()\n",
    "    # 平滑数据\n",
    "    if smooth_kernel:\n",
    "        for i,k in enumerate(calcium_valid):\n",
    "            calcium_valid[i] = cv2.blur(k,(1,smooth_kernel))[:,0]\n",
    "    # 计算相关性矩阵\n",
    "    w_p2m = np.corrcoef(calcium_valid)\n",
    "\n",
    "    # 聚类并将聚类的结果画在相关性矩阵旁边\n",
    "    link = links[choose_index]\n",
    "    aff = affs[choose_index]\n",
    "    model = AgglomerativeClustering(distance_threshold=0, n_clusters=None,linkage=link, affinity=aff)\n",
    "    model = model.fit(w_p2m)\n",
    "    font_size = 100\n",
    "\n",
    "    '''输入事件开始index列表'''\n",
    "    neuron_ids = np.arange(calcium_valid.shape[0])\n",
    "    df_mot_vol['forward_quies'] = df_mot_vol['forward'].copy()\n",
    "    df_mot_vol.loc[df_mot_vol['quies_pc'] == 1,'forward_quies'] = 2\n",
    "    col_draw = ['sm_velocity','sm_speed', 'sm_ang', 'sm_CTX','curvature', 'forward_quies','turn_pc','turn_cor']\n",
    "    # df_mot_valid = df_mot_vol[df_mot_vol['mask']==0]\n",
    "    calcium_heatmap_sign(calcium_intensity,df_mot_vol, col_draw, f,neuron_ids,model,w_p2m, show_id_stride=10,\n",
    "                    show_vol_stride=500, heatmap_range=(0,0.6),wspace=0.06, hspace=0.2,bound_cluster=bound,\n",
    "                    unit_w=0.03, unit_h = 0.8, cal_height_ratio=30, smooth_kernel=smooth_kernel,\n",
    "                    font_size=font_size, font_color='black', idx = idx, vmin = vmin, vmax = vmax,\n",
    "                        threshold=thresh, xlabel='Neuron Index',level=35,sig_matrix = sig_matrix, signal_save_path=s_path, filename=f)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bf085a",
   "metadata": {},
   "source": [
    "# 检查每个文件的运动参数修改和静息状态\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12936f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_fs = [r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\done',r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\to_do_q']\n",
    "sub_folder_path = []\n",
    "for p_f_all in p_fs:\n",
    "    sub_folder_path  += [os.path.join(p_f_all,f) for f in os.listdir(p_f_all) if os.path.isdir(p_f_all+'\\\\'+f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3407a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_path in sub_folder_path:\n",
    "    f = os.path.basename(f_path)\n",
    "    fig_folder = [f for f in os.listdir(f_path) if 'AnalysisFigs' in f]\n",
    "\n",
    "    folders = [\n",
    "        f for f in os.listdir(f_path)\n",
    "        if 'AnalysisFigs' in f and os.path.isdir(os.path.join(f_path, f))\n",
    "    ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
