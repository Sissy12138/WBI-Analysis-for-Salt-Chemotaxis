{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02db14a9",
   "metadata": {},
   "source": [
    "编辑人:苏则茜\n",
    "Project:Prob-Na-Learning\n",
    "+ WBI行为数据分析：时间轴对齐，运动参数提取\n",
    "+ 数据裁剪，数据拼接"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ed161f",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ab4012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import heapq\n",
    "from scipy.ndimage import label\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.ndimage import grey_opening,grey_closing\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from matplotlib.lines import Line2D\n",
    "import networkx as nx\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy import ndimage\n",
    "from scipy.interpolate import splprep, splev\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from datetime import datetime\n",
    "# 设置字体为 SimHei（黑体）\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 设置字体为 SimHei\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321d2d41",
   "metadata": {},
   "source": [
    "# Preprocessing function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cfdfbb",
   "metadata": {},
   "source": [
    "## Coordination Alignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c57dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Realign_coordinate(p_f, df_motion): \n",
    "    '''\n",
    "    不同琼脂垫空间对齐\n",
    "    2025.2.27：目前stage calibrate设置原点在右下角，这个代码将原点根据四个标定点重新设为左上角。\n",
    "    另外根据x轴轨迹做镜面翻转\n",
    "    '''\n",
    "    \n",
    "    # 初始化\n",
    "    df_ul = pd.DataFrame({})\n",
    "    df_ur = pd.DataFrame({})\n",
    "    df_ll = pd.DataFrame({})\n",
    "    df_lr = pd.DataFrame({})\n",
    "    files = [f for f in os.listdir(p_f) if '.txt' in f ]\n",
    "    \n",
    "    # 找到四个顶点的坐标\n",
    "    for f in files:\n",
    "        if 'upper_left' in f:\n",
    "            # 运动参数位置文件\n",
    "            column_names = [ 'X', 'Y']\n",
    "            df_ul = pd.read_csv(os.path.join(p_f, f),sep=r',', header=None, names=column_names)\n",
    "            if len(df_ul) == 1:\n",
    "                df_ul.index = ['upper_left']\n",
    "            else:\n",
    "                raise ValueError('upper_left 标记数量不对')\n",
    "        if 'upper_right' in f:\n",
    "            # 运动参数位置文件\n",
    "            column_names = [ 'X', 'Y']\n",
    "            df_ur = pd.read_csv(os.path.join(p_f, f),sep=r',', header=None, names=column_names)\n",
    "            if len(df_ur) == 1:\n",
    "                df_ur.index = ['upper_right']\n",
    "            else:\n",
    "                raise ValueError('upper_right 标记数量不对')\n",
    "        if ('lower_left' in f) :\n",
    "            # 运动参数位置文件\n",
    "            column_names = [ 'X', 'Y']\n",
    "            df_ll = pd.read_csv(os.path.join(p_f, f),sep=r',', header=None, names=column_names)\n",
    "            if len(df_ll) == 1:\n",
    "                df_ll.index = ['lower_left']\n",
    "            else:\n",
    "                raise ValueError('lower_left 标记数量不对')\n",
    "        if 'lower_right' in f:\n",
    "            # 运动参数位置文件\n",
    "            column_names = [ 'X', 'Y']\n",
    "            df_lr = pd.read_csv(os.path.join(p_f, f),sep=r',', header=None, names=column_names)\n",
    "            if len(df_lr) == 1:\n",
    "                df_lr.index = ['lower_right']\n",
    "            else:\n",
    "                raise ValueError('lower_right 标记数量不对')\n",
    "\n",
    "    df_label = pd.concat([df_ul, df_ll, df_ur, df_lr])\n",
    "    df_label['X'] = df_label['X'].astype(float)/1000\n",
    "    df_label['Y'] = df_label['Y'].astype(float)/1000\n",
    "    # 调整x坐标(平移y轴)\n",
    "    x_min = (df_label.loc['upper_left','X'] + df_label.loc['lower_left','X'])/2\n",
    "    x_max = (df_label.loc['upper_right','X'] + df_label.loc['lower_right','X'])/2\n",
    "    if x_min > x_max:\n",
    "        # 如果原点在高钠一侧，则需要减去left的坐标后将X坐标值变号\n",
    "        # 目前的情况\n",
    "        df_motion_r = df_motion.copy()\n",
    "        df_motion_r['X'] = df_motion_r['X']-x_min\n",
    "        df_motion_r['X'] = -df_motion_r['X']\n",
    "    else:\n",
    "        df_motion_r = df_motion.copy()\n",
    "        df_motion_r['X'] = df_motion_r['X']-x_min\n",
    "        \n",
    "    # 调整y轴坐标，平移x轴  (另外y轴会和原坐标翻转)\n",
    "    y_min = (df_label.loc['lower_left','Y'] + df_label.loc['lower_right','Y'])/2\n",
    "    y_max = (df_label.loc['upper_left','Y'] + df_label.loc['upper_right','Y'])/2\n",
    "    \n",
    "    if y_min > y_max:\n",
    "        df_motion_r1 = df_motion_r.copy()\n",
    "        df_motion_r1['Y'] = df_motion_r1['Y']-y_max\n",
    "    else:\n",
    "        # 目前的情况\n",
    "        df_motion_r1 = df_motion_r.copy()\n",
    "        df_motion_r1['Y'] = df_motion_r1['Y']-y_max\n",
    "        df_motion_r1['Y'] = -df_motion_r1['Y']\n",
    "    return df_label, df_motion_r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "720233e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Realign_coordinate_by_edge(p_f, df_motion):\n",
    "    '''\n",
    "    旧数据标记edge0和edge45,需要判断0和4.5哪一个在左侧,然后将x轴原点设置在0g边缘,且正方向与梯度相同\n",
    "    只修改x轴,不改y轴数据\n",
    "    '''\n",
    "    # 初始化\n",
    "    df_ul = pd.DataFrame({})\n",
    "    df_ur = pd.DataFrame({})\n",
    "    df_ll = pd.DataFrame({})\n",
    "    df_lr = pd.DataFrame({})\n",
    "    edge0_x, edge45_x = None, None  # 初始化\n",
    "\n",
    "    files = [f for f in os.listdir(p_f) if ('.txt' in f) and ('edge' in f)]\n",
    "    # 找到两个边界文件\n",
    "    for f in files:\n",
    "        if 'edge0' in f:\n",
    "            edge0 = np.loadtxt(os.path.join(p_f, f), delimiter=',')\n",
    "            edge0_x = edge0[:, 0]\n",
    "        elif 'edge45' in f:\n",
    "            edge45 = np.loadtxt(os.path.join(p_f, f), delimiter=',')\n",
    "            edge45_x = edge45[:, 0]\n",
    "\n",
    "    # 检查是否都找到\n",
    "    if edge0_x is None or edge45_x is None:\n",
    "        raise FileNotFoundError(\"需要同时包含 edge0 和 edge45 文件，但在 {} 中未找到完整文件\".format(p_f))\n",
    "    \n",
    "    rand_seq_0 = np.random.randint(0, 2, size=len(edge0_x))\n",
    "    mean_x0 = np.mean(edge0_x[rand_seq_0==1])/1000\n",
    "    rand_seq_45 = np.random.randint(0, 2, size=len(edge45_x))\n",
    "    mean_x45 = np.mean(edge45_x[rand_seq_45==1])/1000\n",
    "    print(f'edge0的x平均坐标为{mean_x0},edge45的x平均坐标为{mean_x45}')\n",
    "    if mean_x0 > mean_x45:\n",
    "        print(\"0的坐标更大，说明需要在减去0边界的x坐标后完成坐标轴转换\")\n",
    "        df_motion_r = df_motion.copy()\n",
    "        df_motion_r['X'] = df_motion_r['X']-mean_x0\n",
    "        df_motion_r['X'] = -df_motion_r['X']\n",
    "    else:\n",
    "        print(\"不需要坐标轴转换，只需要将原点平移到edge0\")\n",
    "        df_motion_r = df_motion.copy()\n",
    "        df_motion_r['X'] = df_motion_r['X']-mean_x0\n",
    "    \n",
    "    # 作图验证\n",
    "    plt.scatter(df_motion_r['X'], df_motion_r['Y'], s=0.7, c=df_motion_r['Time'], cmap='Reds')\n",
    "    plt.title(os.path.basename(p_f))\n",
    "    plt.show()\n",
    "    \n",
    "    return df_motion_r\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feaa427",
   "metadata": {},
   "source": [
    "## Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cee792f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_and_draw(df, n, alg_spd = 1, CTX = 0, speed = 0,turn=1, reorientation=1):\n",
    "    # 将轨迹分段可视化\n",
    "    df_idx_list = np.arange(0, len(df), n)   # 切数据\n",
    "    for i, idx in enumerate(df_idx_list[:-1]):\n",
    "        df_d = df.loc[idx: df_idx_list[i+1], :]\n",
    "        plt.figure()\n",
    "        plt.scatter(df_d.X,df_d.Y, s=0.8,c = df_d.Time, cmap='jet')\n",
    "        ax = plt.gca()\n",
    "        plt.title(f'idx{idx}')\n",
    "        plt.colorbar(label='Time(s)')\n",
    "        ax.set_aspect(1)\n",
    "        plt.show()\n",
    "        \n",
    "        if alg_spd:\n",
    "            #画角速度\n",
    "            fig, ax = plt.subplots(1,2)\n",
    "            ax1 = ax[0].scatter(df_d.X,df_d.Y, s=0.8,c = df_d.agl_speed, cmap='jet')\n",
    "            plt.title(f'idx{idx} agl_speed')\n",
    "            plt.colorbar(ax1, label='Time(s)')\n",
    "            ax[0].set_aspect(1)\n",
    "            ax[1].hist(df_d.agl_speed)\n",
    "            plt.show()\n",
    "        if CTX:\n",
    "            # 画CTX\n",
    "            fig, ax = plt.subplots(1,2)\n",
    "            ax1 = ax[0].scatter(df_d.X,df_d.Y, s=0.8,c = df_d.CTX_left, cmap='jet')\n",
    "            plt.title(f'idx{idx} CTX')\n",
    "            plt.colorbar(ax1, label='Time(s)')\n",
    "            ax[0].set_aspect(1)\n",
    "            ax[1].hist(df_d.CTX_left)\n",
    "            ax[1].set_title('CTX_left distribution')\n",
    "            plt.show()\n",
    "        if speed:\n",
    "            # 画速度\n",
    "            fig, ax = plt.subplots(1,2)\n",
    "            ax1 = ax[0].scatter(df_d.X,df_d.Y, s=0.8,c = df_d.speed, cmap='jet')\n",
    "            plt.title(f'idx{idx} agl_speed')\n",
    "            plt.colorbar(ax1,label='Time(s)')\n",
    "            ax[0].set_aspect(1)\n",
    "            ax[1].hist(df_d.speed)\n",
    "            ax[1].set_title('speed distribution')\n",
    "            plt.show()\n",
    "        if reorientation:\n",
    "            fig, ax = plt.subplots(1,2)\n",
    "            ax[1].scatter(df_d.X, df_d.Y, c = 'grey',s=0.8, alpha=0.05)\n",
    "            ax[0].scatter(df_d.X, df_d.Y, c = 'grey',s=0.8, alpha=0.05)\n",
    "            df_pt = df_d[df_d.Reorientation==1]\n",
    "            df_tn = df_d[df_d.Event==1]\n",
    "            ax[0].scatter(df_tn.X, df_tn.Y, s = 0.8, c='r')\n",
    "            ax[1].scatter(df_pt.X, df_pt.Y, s = 0.8, c='r')\n",
    "            ax[0].set_title('Sharp turn')\n",
    "            ax[1].set_title('Reorientation')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df6fe100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scatter_Pos_Grad_Dir(df, Pos_CTX_vec, scale_size = 2, folder = '', x_lim=[]):\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    \n",
    "    mean_x = df.X.mean()\n",
    "    mean_y = df.Y.mean()\n",
    "    origin = [mean_x, mean_y]\n",
    "    vector = np.array(Pos_CTX_vec)*scale_size\n",
    "    \n",
    "    plt.quiver(*origin, *vector, angles='xy', scale_units='xy',\n",
    "               scale=1, color='k', label='Pos_CTX_vec')\n",
    "    plt.legend()\n",
    "    plt.scatter(df.X,df.Y, s=0.8,c = df.Time, cmap='jet')\n",
    "    ax = plt.gca()\n",
    "    plt.colorbar(label='Time(s)')\n",
    "    \n",
    "    if len(x_lim):\n",
    "        plt.xlim(*x_lim)\n",
    "    ax.set_aspect(1)\n",
    "    if folder:\n",
    "        fig.savefig(folder+'Pos-Grad-Dir.png')\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32327515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scatter_Pirouette(df, folder = '', x_lim = []):\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    plt.scatter(df.X, df.Y, c = 'grey',s=0.8, alpha=0.05)\n",
    "    df_pt = df[df.Reorientation==1]\n",
    "    plt.scatter(df_pt.X, df_pt.Y, s = 0.8, c='r')\n",
    "    plt.title('Reorientation')\n",
    "    if len(x_lim):\n",
    "        plt.xlim(*x_lim)\n",
    "    ax.set_aspect(1)\n",
    "    if folder:\n",
    "        fig.savefig(folder+'Visual_Reorientation.png')\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bea565e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_color_dict(key_items,color_map='tab10'):\n",
    "    '''\n",
    "    # 提前生成统一的color_dict()\n",
    "    # color(根据dates元素的数量分配，输出以key_items元素(可以是condition或dates)为key的颜色映射字典)\n",
    "    '''\n",
    "    \n",
    "    color_vec_norm = np.linspace(0.01,0.99,len(key_items)+1)\n",
    "    colormap = mpl.colormaps[color_map]\n",
    "    colors  = colormap(color_vec_norm)\n",
    "    color_dict = {}\n",
    "    for i, d in enumerate(key_items):\n",
    "        color_dict[d] = colors[i]\n",
    "    return color_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "357da5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_time_intervals(df, time_len, time_inv, time_col='Vol_Time'):\n",
    "    \"\"\"\n",
    "    设置时间间隔并为 DataFrame 添加时间段标签。\n",
    "    时间列单位为s，不需要frame_rate\n",
    "\n",
    "    Parameters:\n",
    "    - df: 输入 DataFrame，需包含 'Timestamp' 列。\n",
    "    - time_len: 总时间长度（小时）。\n",
    "    - time_inv: 时间间隔（分钟）。\n",
    "\n",
    "    Returns:\n",
    "    - 更新后的 DataFrame，添加了 'Period_label' 列。\n",
    "    - 时间段标签列表。\n",
    "    \"\"\"\n",
    "    periods = np.arange(0, time_len + 1, time_inv)\n",
    "    labels = [(periods[i] + periods[i + 1]) / 2 for i in range(len(periods) - 1)]\n",
    "    df['Period_label'] = pd.cut(\n",
    "        df[time_col], bins=periods, labels=labels, right=False, include_lowest=True\n",
    "    )\n",
    "    return df, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d3487",
   "metadata": {},
   "source": [
    "## Motion Parameter Extract Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93564dd",
   "metadata": {},
   "source": [
    "### 角度计算  \n",
    "  Pirouette labeling(outdated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69b24a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义角度计算公式\n",
    "def ang_cal(vec_1,vec_2):\n",
    "    dot_pro = np.dot(vec_1, vec_2)\n",
    "    mod_1 = np.sqrt(np.dot(vec_1,vec_1))\n",
    "    mod_2 = np.sqrt(np.dot(vec_2,vec_2)) \n",
    "    if mod_1 == 0 or mod_2 ==0:\n",
    "        angle = 0\n",
    "    else:\n",
    "        cos = dot_pro/(mod_1*mod_2)\n",
    "        if np.isnan(cos) == True:\n",
    "            angle = np.nan\n",
    "        else:  \n",
    "            angle = np.arccos(round(cos,1))  #弧度制\n",
    "    return angle\n",
    "\n",
    "def clws_delta_phi(vec_1, vec_2, vec_0 = [1,0]):\n",
    "    # vec_1 is the first vector, and it rotates to the vec_2\n",
    "    vec_0 = np.array(vec_0)\n",
    "    agl_1 = ang_cal(vec_1,vec_2)\n",
    "    agl_2 = ang_cal(vec_0, vec_1)\n",
    "    agl_3 = ang_cal(vec_0, vec_2)\n",
    "    if agl_1 == 0:\n",
    "        agl_1 = 0\n",
    "        # print('angle = 0°')\n",
    "    elif agl_1 == np.pi:\n",
    "        agl_1 = np.pi\n",
    "        # print('angle = 180°')\n",
    "    elif vec_1[1] >= 0 and vec_2[1] >= 0:    #同时在第一第二象限\n",
    "        if (agl_3 - agl_2) > 0:\n",
    "            agl_1 = (-1)*np.abs(agl_1)\n",
    "        else:\n",
    "            agl_1 = np.abs(agl_1)\n",
    "    elif vec_1[1] <= 0 and vec_2[1] <= 0:    #同时在第三第四象限\n",
    "        if (agl_3 - agl_2) > 0:\n",
    "            agl_1 = np.abs(agl_1)\n",
    "        else:\n",
    "            agl_1 = (-1)*np.abs(agl_1)\n",
    "    elif vec_1[1] >= 0 and vec_2[1] <= 0:\n",
    "        if (agl_3 + agl_2) > np.pi:\n",
    "            agl_1 = (-1)*np.abs(agl_1)\n",
    "        else:                                  #如果等于180°认为是顺时针旋转\n",
    "            agl_1 = np.abs(agl_1)\n",
    "    elif vec_1[1] <= 0 and vec_2[1] >= 0:\n",
    "        if (agl_3 + agl_2) < np.pi:\n",
    "            agl_1 = (-1)*np.abs(agl_1)\n",
    "        else:                                  #如果等于180°认为是顺时针旋转\n",
    "            agl_1 = np.abs(agl_1)   \n",
    "    return agl_1*180/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe6af5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Label_Pirouettes_by_id(g_df,t_crit=6.16, frame_rate = 30,min_agl_spd=None):\n",
    "#     '''根据角速度和turn的间隔标记Pirouette'''\n",
    "#     # 输入：同一个id的df, t_crit(sec)，如果需要重新分turn可以输入min_agl_spd\n",
    "#     # 注意输入的df中不能是不同组混合的，id必须独立\n",
    "#     t_f_crit = t_crit*frame_rate\n",
    "#     if min_agl_spd:\n",
    "#         g_df.loc[:,'Event']=0\n",
    "#         g_df.loc[g_df.agl_speed >= min_agl_spd, 'Event']=1\n",
    "        \n",
    "#     g_df.loc[:,'Reorientation']=g_df['Event']\n",
    "#     g_df = g_df.reset_index(drop=True)\n",
    "#     # nan值是计算速度和角速度时舍弃的点，默认是0不计算c\n",
    "#     event_vec = g_df.Event.fillna(0).values\n",
    "\n",
    "#     # 向后移动一位，上下相减\n",
    "#     diff_vec = event_vec[1:]-event_vec[:-1]\n",
    "#     if (diff_vec==0).all():\n",
    "#         pass\n",
    "#     elif ~(diff_vec==-1).any() or ~(diff_vec==1).any():\n",
    "#         print('只有结尾有turn或只有开头有turn')\n",
    "#     else:\n",
    "#         # 统计所有出现1和-1的索引\n",
    "#         idx_1 = np.where(diff_vec == 1)[0]\n",
    "#         idx_n1 = np.where(diff_vec == -1)[0]\n",
    "#         if np.min(idx_1)<np.min(idx_n1):\n",
    "#             # 如果最小的索引是1而不是-1，说明开头是run，然后才开始出现turn\n",
    "#             if len(idx_1)>len(idx_n1):\n",
    "#                 # 如果1的数量大于-1,说明最后一个turn没有结束\n",
    "# #                 print(f'验证最后是否以turn结束:{(np.max(idx_n1)<np.max(idx_1))}')\n",
    "#                 # 去掉第一个1的索引，用1减去所有-1的索引，判断长度\n",
    "#                 run_lens_btw_turns = idx_1[1:]-idx_n1\n",
    "#                 for i,r in enumerate(run_lens_btw_turns):\n",
    "#                     if r <= t_f_crit:\n",
    "#                         low_b = idx_n1[i]+1\n",
    "#                         upper_b = idx_1[i+1]+1      # 注意idx_1去头，所以索引内加以\n",
    "#                         g_df.loc[low_b:upper_b, 'Reorientation']=1\n",
    "\n",
    "#             elif len(idx_1)==len(idx_n1):\n",
    "#                 # 如果两者数量相同，说明最后以run结尾，这条轨迹前后是完整的多个turn\n",
    "# #                 print(f'验证最后是否以run结束:{(np.max(idx_n1)>np.max(idx_1))}')\n",
    "#                 # 去掉1的所索引的首部和-1的尾部，用1减去-1的索引判断长度\n",
    "#                 run_lens_btw_turns = idx_1[1:]-idx_n1[:-1]\n",
    "#                 for i,r in enumerate(run_lens_btw_turns):\n",
    "#                     if r <= t_f_crit:\n",
    "#                         low_b = idx_n1[i]+1\n",
    "#                         upper_b = idx_1[i+1]+1\n",
    "#                         g_df.loc[low_b:upper_b, 'Reorientation']=1\n",
    "\n",
    "#             # 无论是上述哪种情况，turn的数量都记为出现1的数量\n",
    "#             num_turn = len(idx_1)\n",
    "# #             print(f'Turn number: {num_turn}')\n",
    "#         elif np.min(idx_1)>np.min(idx_n1):\n",
    "#             # 如果最小索引是-1而不是1，说明开头就是turn\n",
    "#             if (len(idx_n1)== len(idx_1)+1):\n",
    "#                 # 如果-1比1多一个，说明以run结尾\n",
    "# #                 print(f'验证最后是否以run结束:{(np.max(idx_n1)>np.max(idx_1))}')\n",
    "#                 # 去掉最后一个-1的索引，用1减去-1\n",
    "#                 run_lens_btw_turns = idx_1-idx_n1[:-1]\n",
    "#                 for i,r in enumerate(run_lens_btw_turns):\n",
    "#                     if r <= t_f_crit:\n",
    "#                         low_b = idx_n1[i]+1\n",
    "#                         upper_b = idx_1[i]+1\n",
    "#                         g_df.loc[low_b:upper_b, 'Reorientation']=1\n",
    "#             elif (len(idx_n1) == len(idx_1)):\n",
    "#                 # 如果-1和1一样多，说明以turn结尾\n",
    "# #                 print(f'验证最后是否以turn结束:{(np.max(idx_n1)<np.max(idx_1))}')\n",
    "#                 # 直接用1的索引减去-1\n",
    "#                 run_lens_btw_turns = idx_1-idx_n1\n",
    "#                 for i,r in enumerate(run_lens_btw_turns):\n",
    "#                     if r <= t_f_crit:\n",
    "#                         low_b = idx_n1[i]+1\n",
    "#                         upper_b = idx_1[i]+1\n",
    "#                         g_df.loc[low_b:upper_b, 'Reorientation']=1\n",
    "#     return g_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07c19145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Insert_SharpTurn(df_als, min_agl = 50, max_agl = 110):\n",
    "#     print('=======================开始事件分类===================================')\n",
    "#     print('注：事件分类仅完成分类（turn = 1, run = 0），tunrning rate的计算较为灵活，在汇总分析作图时使用')\n",
    "#     # 新建一列为Event\n",
    "#     if 'Event' in df_als:\n",
    "#         df_als = df_als.drop('Event', axis = 1)\n",
    "#     df_als['Event'] = np.nan\n",
    "#     # 选择角速度区间\n",
    "#     # sharp turn 标记为1\n",
    "#     df_als.loc[(np.abs(df_als.agl_velocity)>= min_agl)&(np.abs(df_als.agl_velocity) <= max_agl), 'Event'] = 1  \n",
    "#     # run 标记为0\n",
    "#     df_als.loc[(np.abs(df_als.agl_velocity) < min_agl), 'Event'] = 0\n",
    "#     return df_als"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84378803",
   "metadata": {},
   "source": [
    "### 计算连续运动参数变量:速度，CTX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87d38cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 速度，角速度，bearing angle, Dist_to_center, ctx计算函数\n",
    "# 输入：筛选为虫子的csv文件，画圆的csv文件，ID索引，速度平滑，角速度速度平滑，角速度平滑，追踪帧率，跳帧数量，像素长度\n",
    "def Smooth_velocity_calation(df_worms,sm_inv,window_size = 20,\n",
    "                         frame_rate = 38, track_jump_frame = 1,\n",
    "                        X_shift = 0):\n",
    "    # 只适用于线性梯度，因为CTX只计算到左和右边缘的\n",
    "    # 速度平滑窗s sm_inv\n",
    "    # 计算角速度的速度平滑窗s spd_sm_inv\n",
    "    # 角速度平滑床s hlf_sm_inv\n",
    "    \n",
    "    # ======================================数据平滑=================\n",
    "    # 1. 移动窗口平滑\n",
    "    # 对X和Y坐标进行移动平均\n",
    "    df_slide = df_worms.copy()\n",
    "    df_slide['X_org'] = df_slide['X']                     # 将平滑前的轨迹也加入df\n",
    "    df_slide['Y_org'] = df_slide['Y']\n",
    "    df_slide['X'] = df_slide['X'].rolling(window=window_size, center=True).mean()\n",
    "    df_slide['Y'] = df_slide['Y'].rolling(window=window_size, center=True).mean()\n",
    "    \n",
    "    if X_shift:\n",
    "        # 如果X有偏离，向左偏离减去，向右偏移加上，单位mm\n",
    "        df_slide['X'] += X_shift\n",
    "        \n",
    "        \n",
    "    # ======================================速度计算=================\n",
    "    # 根据帧率计算半平滑窗，但是具体计算速度和角速度的时间根据时间戳来确定\n",
    "    print(sm_inv, frame_rate, track_jump_frame)\n",
    "    half_bins_spd = int((sm_inv*frame_rate)//track_jump_frame)\n",
    "    bins_spd = 2*half_bins_spd\n",
    "\n",
    "    trajectory_0 = df_slide[['X','Y','Time']].values      # 提取x,y坐标和时间戳\n",
    "    trajectory_1 = (trajectory_0.copy()).astype('float')                            # 转float数据类型\n",
    "    x = trajectory_1[:,0]\n",
    "    y = trajectory_1[:,1]\n",
    "    delta_x = (x[bins_spd:]-x[:len(x)-bins_spd])                       # 得到减去头尾数据点的delta_x和delta_y\n",
    "    delta_y = (y[bins_spd:]-y[:len(y)-bins_spd])\n",
    "    time_step = trajectory_1[:,2] \n",
    "    print('time_step', time_step)\n",
    "    time_step_vec = time_step[bins_spd:]-time_step[:len(time_step)-bins_spd]        # 得到减去头尾数据点的对应delta-x和delta-y的时间\n",
    "    print('平均时间间隔'+str(np.average(time_step_vec))+'应该等于总平滑窗'+str(sm_inv*2))\n",
    "    mean_time_inv = np.average(time_step_vec)   # 平均时间间隔\n",
    "    velocity_bef = np.dstack((delta_x/time_step_vec,delta_y/time_step_vec))[0]      # 使用dstack函数合并x,y方向计算的速度为一个矩阵\n",
    "    speed_bef = np.linalg.norm(velocity_bef, axis = 1).reshape(-1,1)\n",
    "    nan_bin_vec = np.full((half_bins_spd,2),np.nan)\n",
    "    nan_bin_spd = np.full((half_bins_spd,1),np.nan)\n",
    "    velocity = np.vstack((nan_bin_vec, velocity_bef, nan_bin_vec))                  # 速度向量\n",
    "    speed = np.vstack((nan_bin_spd, speed_bef, nan_bin_spd))                        # 速率向量\n",
    "    \n",
    "    df_idx = df_slide[['X','X_org','Y','Y_org','Time']].copy()      \n",
    "    df_idx['speed'] = pd.Series(speed[:,0],index = df_idx.index)                    # 将speed和velocity加入dataframe\n",
    "    df_idx['x_velocity'] = pd.Series(velocity[:,0],index = df_idx.index)\n",
    "    df_idx['y_velocity'] = pd.Series(velocity[:,1],index = df_idx.index)\n",
    "\n",
    "    return df_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f28e463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 速度，角速度，bearing angle, Dist_to_center, ctx计算函数\n",
    "# 输入：筛选为虫子的csv文件，画圆的csv文件，ID索引，速度平滑，角速度速度平滑，角速度平滑，追踪帧率，跳帧数量，像素长度\n",
    "def Sliding_CTX_calation_old(df_worms, grad_vec,sm_inv, spd_sm_inv, hlf_sm_inv,window_size = 20,\n",
    "                         frame_rate = 20, track_jump_frame = 1,\n",
    "                        X_shift = 0):\n",
    "    # 只适用于线性梯度，因为CTX只计算到左和右边缘的\n",
    "    # 速度平滑窗s sm_inv\n",
    "    # 计算角速度的速度平滑窗s spd_sm_inv\n",
    "    # 角速度平滑床s hlf_sm_inv\n",
    "    \n",
    "    # ======================================数据平滑=================\n",
    "    # 1. 移动窗口平滑\n",
    "    # 对X和Y坐标进行移动平均\n",
    "    df_slide = df_worms.copy()\n",
    "    df_slide['X_org'] = df_slide['X']                     # 将平滑前的轨迹也加入df\n",
    "    df_slide['Y_org'] = df_slide['Y']\n",
    "    df_slide['X'] = df_slide['X'].rolling(window=window_size, center=True).mean()\n",
    "    df_slide['Y'] = df_slide['Y'].rolling(window=window_size, center=True).mean()\n",
    "    \n",
    "    if X_shift:\n",
    "        # 如果X有偏离，向左偏离减去，向右偏移加上，单位mm\n",
    "        df_slide['X'] += X_shift\n",
    "        \n",
    "        \n",
    "    # ======================================速度计算=================\n",
    "    \n",
    "    \n",
    "    # 根据帧率计算半平滑窗，但是具体计算速度和角速度的时间根据时间戳来确定\n",
    "    print(sm_inv, frame_rate, track_jump_frame)\n",
    "    half_bins_spd = int((sm_inv*frame_rate)//track_jump_frame)\n",
    "    bins_spd = 2*half_bins_spd\n",
    "\n",
    "    trajectory_0 = df_slide[['X','Y','Time']].values      # 提取x,y坐标和时间戳\n",
    "    trajectory_1 = (trajectory_0.copy()).astype('float')                            # 转float数据类型\n",
    "    x = trajectory_1[:,0]\n",
    "    y = trajectory_1[:,1]\n",
    "    delta_x = (x[bins_spd:]-x[:len(x)-bins_spd])                       # 得到减去头尾数据点的delta_x和delta_y\n",
    "    delta_y = (y[bins_spd:]-y[:len(y)-bins_spd])\n",
    "    time_step = trajectory_1[:,2] \n",
    "    print('time_step', time_step)\n",
    "    time_step_vec = time_step[bins_spd:]-time_step[:len(time_step)-bins_spd]        # 得到减去头尾数据点的对应delta-x和delta-y的时间\n",
    "    print('平均时间间隔'+str(np.average(time_step_vec))+'应该等于总平滑窗'+str(sm_inv*2))\n",
    "    mean_time_inv = np.average(time_step_vec)   # 平均时间间隔\n",
    "    velocity_bef = np.dstack((delta_x/time_step_vec,delta_y/time_step_vec))[0]      # 使用dstack函数合并x,y方向计算的速度为一个矩阵\n",
    "    speed_bef = np.linalg.norm(velocity_bef, axis = 1).reshape(-1,1)\n",
    "    nan_bin_vec = np.full((half_bins_spd,2),np.nan)\n",
    "    nan_bin_spd = np.full((half_bins_spd,1),np.nan)\n",
    "    velocity = np.vstack((nan_bin_vec, velocity_bef, nan_bin_vec))                  # 速度向量\n",
    "    speed = np.vstack((nan_bin_spd, speed_bef, nan_bin_spd))                        # 速率向量\n",
    "    \n",
    "    df_idx = df_slide[['X','X_org','Y','Y_org','Time']].copy()      \n",
    "    df_idx['speed'] = pd.Series(speed[:,0],index = df_idx.index)                    # 将speed和velocity加入dataframe\n",
    "    df_idx['x_velocity'] = pd.Series(velocity[:,0],index = df_idx.index)\n",
    "    df_idx['y_velocity'] = pd.Series(velocity[:,1],index = df_idx.index)\n",
    "    \n",
    "    # ======================================================角速度计算===========\n",
    "\n",
    "    half_bins_spd_agl = int((spd_sm_inv*frame_rate)//track_jump_frame)\n",
    "    bins_spd_agl = 2*half_bins_spd_agl                                 # 角速度速度平滑窗\n",
    "    hlf_agl_bins = int((hlf_sm_inv*frame_rate)//track_jump_frame)      # 角速度半平滑窗\n",
    "    print('角速度半平滑窗：', hlf_agl_bins)\n",
    "    trajectory_0 = df_slide[['X','Y','Time']].values      # 提取x,y坐标和时间戳\n",
    "    trajectory_1 = (trajectory_0.copy()).astype('float')                            # 转float数据类型\n",
    "    x = trajectory_1[:,0]\n",
    "    y = trajectory_1[:,1]\n",
    "    delta_x = (x[bins_spd_agl:]-x[:len(x)-bins_spd_agl])                                     # 得到减去头尾数据点的delta_x和delta_y\n",
    "    delta_y = (y[bins_spd_agl:]-y[:len(y)-bins_spd_agl])\n",
    "    time_step = trajectory_1[:,2]   \n",
    "    time_step_vec = time_step[bins_spd_agl:]-time_step[:len(time_step)-bins_spd_agl]        # 得到减去头尾数据点的对应delta-x和delta-y的时间\n",
    "    velocity_bef = np.dstack((delta_x/time_step_vec,delta_y/time_step_vec))[0]             # 使用dstack函数合并x,y方向计算的速度为一个矩阵\n",
    "    speed_bef = np.linalg.norm(velocity_bef, axis = 1).reshape(-1,1)\n",
    "    nan_bin_vec = np.full((half_bins_spd_agl,2),np.nan)\n",
    "    nan_bin_spd = np.full((half_bins_spd_agl,1),np.nan)\n",
    "    velocity = np.vstack((nan_bin_vec, velocity_bef, nan_bin_vec))\n",
    "    speed = np.vstack((nan_bin_spd, speed_bef, nan_bin_spd))[:,0]\n",
    "    time_step_vector = np.vstack((nan_bin_spd, time_step_vec.reshape(-1,1), nan_bin_spd))[:,0]\n",
    "    \n",
    "    df_speed_cal = pd.DataFrame(speed,columns = ['speed'])              # 生成一个包含speed的df并提取索引\n",
    "    \n",
    "#     idx_vec = df_speed_cal.index                                        # 生成索引列表时先掐头去尾再取非零值\n",
    "#     df_washed_speed = df_speed_cal[half_bins_spd_agl:len(idx_vec)-half_bins_spd_agl]\n",
    "#     idx_nz_vec = df_washed_speed[df_washed_speed['speed']!=0].index     # 索引是相对于总长度，但是这个列表中直接去掉了头尾速度为nan的和速率为0的点的索引\n",
    "#     df_speed_cal['agl_velocity'] = pd.Series([np.nan]*len(idx_vec))\n",
    "\n",
    "#     for i in range(hlf_agl_bins,len(idx_nz_vec)-hlf_agl_bins):\n",
    "#         n = hlf_agl_bins\n",
    "#         agl_i = clws_delta_phi(velocity[idx_nz_vec[i-n]],velocity[idx_nz_vec[i+n]]) \n",
    "#         time_end= time_step[idx_nz_vec[i+n]]\n",
    "#         time_start = time_step[idx_nz_vec[i-n]]\n",
    "#         delta_t_i = time_end-time_start\n",
    "# #         print(\"timestamp\", time_start, time_start)\n",
    "# #         print('角度计算时间间隔：',delta_t_i)\n",
    "#         agl_vel_i = agl_i/delta_t_i\n",
    "\n",
    "#         if np.isnan(agl_vel_i) == False:\n",
    "#             df_speed_cal['agl_velocity'].loc[idx_nz_vec[i]] = agl_vel_i\n",
    "#         else:\n",
    "# #             print(velocity[idx_nz_vec[i-n]],velocity[idx_nz_vec[i+n]])\n",
    "#             df_speed_cal['agl_velocity'].loc[idx_nz_vec[i]] = 0 \n",
    "#     # 将angular_velocity和angular_speed加入dataframe(df_idx)\n",
    "#     df_idx['agl_velocity'] = pd.Series(df_speed_cal['agl_velocity'].values,index = df_idx.index)\n",
    "#     # df_idx.loc[:,'x_velocity_agl'] = velocity[:,0]\n",
    "#     # df_idx.loc[:,'y_velocity_agl'] = velocity[:,1]\n",
    "#     df_idx.loc[df_idx.speed == 0, 'agl_velocity'] = 0                 # 将speed为0的点角速度设为0\n",
    "#     df_idx['agl_speed'] = np.abs(df_idx['agl_velocity'])\n",
    "    \n",
    "    # ===========================================计算CTX=====================================\n",
    "    vec_left = grad_vec\n",
    "    vel_vec = df_idx[['x_velocity','y_velocity']].values\n",
    "    bearing_left = []\n",
    "    \n",
    "    ctxs = []\n",
    "    for i in range(len(vel_vec)):\n",
    "        agl_i_left = clws_delta_phi(vec_left,vel_vec[i,:])\n",
    "        agl_i_left = agl_i_left/180*np.pi     # bearing angle使用的是弧度制\n",
    "        bearing_left.append(agl_i_left)                                      # 使用弧度制\n",
    "        \n",
    "        vel_vec_i = vel_vec[i,:]\n",
    "        deno = np.sqrt(vel_vec_i[0]**2+vel_vec_i[1]**2)\n",
    "        if deno==0:\n",
    "            ctx_i = 0.0\n",
    "        else:\n",
    "            ctx_i = -vel_vec_i[0]/deno\n",
    "        ctxs.append(ctx_i)\n",
    "        \n",
    "    df_idx['CTX_left'] = pd.Series(ctxs, index = df_idx.index)\n",
    "    df_idx['bearing_left'] = pd.Series(bearing_left, index = df_idx.index)\n",
    "#     df_idx['CTX_left']=df_idx['bearing_left'].apply(np.cos,axis = 0)\n",
    "    \n",
    "\n",
    "\n",
    "    return df_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6139cbc",
   "metadata": {},
   "source": [
    "### 前后后退"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7984a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_smth_forward_reverse(df, close_size = 50, open_size = 50):\n",
    "    '''\n",
    "    df: 包含angle_m列\n",
    "    返回：df：包含平滑后的forward列\n",
    "    '''\n",
    "    # 前进后退\n",
    "    # 根据阈值分割前进后退\n",
    "    threshold = 120\n",
    "    df.loc[:,'forward'] = 0\n",
    "    df.loc[df[\"angle_m\"]>=threshold,'forward'] = 1\n",
    "\n",
    "    # 平滑reversal\n",
    "    # 先进行闭操作（先膨胀后腐蚀）：填充小的空洞\n",
    "    closed = ndimage.binary_closing(df['forward'].values, structure=np.ones(close_size))\n",
    "    # 再进行开操作（先腐蚀后膨胀）：去除小的噪声点\n",
    "    opened = ndimage.binary_opening(closed, structure=np.ones(open_size))\n",
    "    # 将结果转换为整数并添加到 DataFrame\n",
    "    df['forward'] = opened.astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f835abdd",
   "metadata": {},
   "source": [
    "### 身体前进方向速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3f0dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算根据运动方向旋转后的朝头部方向运动向量\n",
    "def rotation_mat_2(theta_degrees, mov_vec):\n",
    "    mov_vec = np.array(mov_vec)\n",
    "    if (theta_degrees == np.nan) or (theta_degrees == None):\n",
    "        return None\n",
    "    if (mov_vec is None) or (mov_vec.any()==np.nan):\n",
    "        return None\n",
    "    \"\"\"\n",
    "    统一的 2D 旋转矩阵\n",
    "    θ > 0: 逆时针旋转\n",
    "    θ < 0: 顺时针旋转\n",
    "    \"\"\"\n",
    "    theta_rad = -np.radians(theta_degrees)\n",
    "    cos_theta = np.cos(theta_rad)\n",
    "    sin_theta = np.sin(theta_rad)\n",
    "    rot_mat =  np.array([\n",
    "        [cos_theta, -sin_theta],\n",
    "        [sin_theta,  cos_theta]\n",
    "    ])\n",
    "    return np.dot(rot_mat, mov_vec)\n",
    "\n",
    "rotation_mat_vec = np.vectorize(rotation_mat_2)\n",
    "# 求向量投影\n",
    "def project_vector_A_on_B(vector_A, vector_B):\n",
    "    \"\"\"\n",
    "    返回C向量,方向与B相同,长度为A的投影\n",
    "    \"\"\"\n",
    "    # 转换为numpy数组\n",
    "    A = np.array(vector_A)\n",
    "    B = np.array(vector_B)\n",
    "    # 计算向量B的单位向量\n",
    "    B_norm = np.linalg.norm(B)\n",
    "    if B_norm == 0:\n",
    "        print('B向量不能为零')\n",
    "        return None\n",
    "        # raise ValueError(\"向量B不能为零向量\")\n",
    "    B_unit = B / B_norm\n",
    "    \n",
    "    # 计算向量A在向量B上的投影长度\n",
    "    projection_length = np.dot(A, B_unit)\n",
    "    # 计算向量C = 投影长度 × 单位向量B\n",
    "    vector_C = projection_length * B_unit\n",
    "    return vector_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceb7e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_head_moving(df):\n",
    "    '''\n",
    "    df: 包含'x_velocity'和'y_velocity'列\n",
    "    返回 df includes:\n",
    "        'moving_vec': moving direction vector;\n",
    "        'heading_vec': heading vector ;\n",
    "       \"head_moving\": the component of velocity projected on the direction of heading\n",
    "    '''\n",
    "    # 运动方向向量\n",
    "    df.loc[:,'moving_vec'] = df.apply(lambda x: (x['x_velocity'], x['y_velocity']),axis = 1)\n",
    "\n",
    "    # 头部朝向向量\n",
    "    df.loc[:,'heading_vec'] = df.apply(lambda x: rotation_mat_2(x['angle_md'], x['moving_vec']), axis=1)\n",
    "    # 求投影头部朝向后的运动向量\n",
    "    df.loc[:,'head_moving'] = df.apply(lambda x: project_vector_A_on_B(x['moving_vec'], x['heading_vec']), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9232f2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_bearing_ctx(df, grad_vec=[-1,0]):\n",
    "    '''\n",
    "    df: 包含头部方向的运动向量'head_moving'\n",
    "    '''\n",
    "    vec_left = grad_vec\n",
    "    vel_vec = np.vstack(df['head_moving'].values)\n",
    "    bearing_left = []\n",
    "    \n",
    "    ctxs = []\n",
    "    for i in range(len(vel_vec)):\n",
    "        agl_i_left = clws_delta_phi(vec_left,vel_vec[i,:])\n",
    "        agl_i_left = agl_i_left/180*np.pi     # bearing angle使用的是弧度制\n",
    "        bearing_left.append(agl_i_left)                                      # 使用弧度制\n",
    "        \n",
    "        vel_vec_i = vel_vec[i,:]\n",
    "        deno = np.sqrt(vel_vec_i[0]**2+vel_vec_i[1]**2)\n",
    "        if deno==0:\n",
    "            ctx_i = 0.0\n",
    "        else:\n",
    "            ctx_i = -vel_vec_i[0]/deno\n",
    "        ctxs.append(ctx_i)\n",
    "        \n",
    "    df['CTX_left'] = pd.Series(ctxs, index = df.index)\n",
    "    df['bearing_left'] = pd.Series(bearing_left, index = df.index)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c24e26",
   "metadata": {},
   "source": [
    "### 标记Omega turn和头部曲率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0a14d2",
   "metadata": {},
   "source": [
    "#### 骨架合并与拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8b00fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_length(coords: np.ndarray) -> float:\n",
    "    \"\"\"polyline 长度（逐段欧氏距离累加）。coords: (N,2)\"\"\"\n",
    "    if coords is None or len(coords) < 2:\n",
    "        return 0.0\n",
    "    d = np.diff(coords, axis=0)\n",
    "    return float(np.sum(np.sqrt((d**2).sum(axis=1))))\n",
    "\n",
    "def quantize_point(pt, q=1):\n",
    "    \"\"\"把像素点量化到网格上（容差聚类）。q=1 等价于原始整数像素匹配。\"\"\"\n",
    "    return (int(round(pt[0]/q)*q), int(round(pt[1]/q)*q))\n",
    "\n",
    "def cut_paths_to_edges(all_paths, q=1):\n",
    "    \"\"\"\n",
    "    把多条骨架在“端点”和“交叉点”处切段，返回 MultiGraph：\n",
    "    - 节点：关键点坐标（量化后）\n",
    "    - 边：两关键点之间的子折线，数据里带 coords/length\n",
    "    \"\"\"\n",
    "    # 1) 统计每个像素（量化后）被多少条路径/多少次命中，用于发现交叉\n",
    "    occ = {}  # key -> list of (path_idx, local_idx)\n",
    "    for pi, path in enumerate(all_paths):\n",
    "        if path is None or len(path) == 0:\n",
    "            continue\n",
    "        for si, pt in enumerate(path):\n",
    "            key = quantize_point(pt, q)\n",
    "            occ.setdefault(key, []).append((pi, si))\n",
    "\n",
    "    # 2) 关键点：每条 polyline 的首尾点 + 被多个 path 命中的点（交叉/重合点）\n",
    "    keypoints = set()\n",
    "    for pi, path in enumerate(all_paths):\n",
    "        if path is None or len(path) == 0:\n",
    "            continue\n",
    "        keypoints.add(quantize_point(path[0], q))\n",
    "        keypoints.add(quantize_point(path[-1], q))\n",
    "    for key, hits in occ.items():\n",
    "        # 命中数量>1，基本可视为交叉/共点（或一个 path 在该点有重复）\n",
    "        if len(hits) > 1:\n",
    "            keypoints.add(key)\n",
    "\n",
    "    # 3) 在关键点处把每条 polyline 切段，生成边\n",
    "    G = nx.MultiGraph()\n",
    "    # 节点位置（用于方向判断）\n",
    "    node_pos = {}  # key(node) -> 原始坐标（选第一次出现的真实像素）\n",
    "    for kp in keypoints:\n",
    "        # 选一个代表性坐标（量化格内实际像素），尽量从 occ 里取真实像素\n",
    "        if kp in occ:\n",
    "            pi, si = occ[kp][0]\n",
    "            node_pos[kp] = tuple(map(int, all_paths[pi][si]))\n",
    "        else:\n",
    "            node_pos[kp] = (int(kp[0]), int(kp[1]))\n",
    "        G.add_node(kp)\n",
    "\n",
    "    for pi, path in enumerate(all_paths):\n",
    "        if path is None or len(path) < 2:\n",
    "            continue\n",
    "        # 找到该 path 上属于关键点的索引\n",
    "        cut_idx = []\n",
    "        for si, pt in enumerate(path):\n",
    "            if quantize_point(pt, q) in keypoints:\n",
    "                cut_idx.append(si)\n",
    "        # 确保首尾在里头\n",
    "        if 0 not in cut_idx:\n",
    "            cut_idx.insert(0, 0)\n",
    "        if (len(path)-1) not in cut_idx:\n",
    "            cut_idx.append(len(path)-1)\n",
    "        # 去重并排序\n",
    "        cut_idx = sorted(set(cut_idx))\n",
    "        # 相邻关键点之间形成一条边\n",
    "        for a, b in zip(cut_idx[:-1], cut_idx[1:]):\n",
    "            if b <= a:\n",
    "                continue\n",
    "            sub = path[a:b+1]\n",
    "            if len(sub) < 2:\n",
    "                continue\n",
    "            u = quantize_point(sub[0], q)\n",
    "            v = quantize_point(sub[-1], q)\n",
    "            w = path_length(sub)\n",
    "            # 可能 u==v（零长度/回折），跳过\n",
    "            if u == v or w == 0:\n",
    "                continue\n",
    "            # 入图，边上存 coords 和 length\n",
    "            G.add_edge(u, v, length=w, coords=sub)\n",
    "\n",
    "    # 把 node 真实坐标也记录上（便于后续方向判断）\n",
    "    nx.set_node_attributes(G, {n: {'pos': node_pos[n]} for n in G.nodes})\n",
    "    return G\n",
    "\n",
    "def oriented_coords(edge_data, start_node_pos):\n",
    "    \"\"\"\n",
    "    根据起点节点位置，返回边的坐标正向/反向（避免连接时倒序）。\n",
    "    edge_data['coords'] 是边的折线；start_node_pos 是当前节点实际坐标\n",
    "    \"\"\"\n",
    "    coords = edge_data['coords']\n",
    "    if len(coords) == 0:\n",
    "        return coords\n",
    "    # 与起点更接近的一端作为开头\n",
    "    d0 = np.linalg.norm(coords[0] - start_node_pos)\n",
    "    d1 = np.linalg.norm(coords[-1] - start_node_pos)\n",
    "    return coords if d0 <= d1 else coords[::-1]\n",
    "\n",
    "def extract_non_branching_chains(G: nx.MultiGraph):\n",
    "    \"\"\"\n",
    "    提取所有“非分叉链”：中间节点度数=2，端点为“度!=2 的节点”或到头。\n",
    "    同时处理纯环（整个连通分量所有节点度数=2）的情况。\n",
    "    返回：list of dict，每个 dict 包含 {'nodes': [...], 'coords': np.ndarray, 'length': float}\n",
    "    \"\"\"\n",
    "    chains = []\n",
    "    visited = set()  # 记录已走过的具体边 (u,v,key)（无向，按排序存）\n",
    "\n",
    "    def mark(u,v,k):  # 无向规范化\n",
    "        return (u, v, k) if u <= v else (v, u, k)\n",
    "\n",
    "    deg = dict(G.degree())\n",
    "    terminals = [n for n,d in deg.items() if d != 2]\n",
    "\n",
    "    # —— 从端点出发的所有链 —— #\n",
    "    for start in terminals:\n",
    "        for _, nbr, key, data in G.edges(start, keys=True, data=True):\n",
    "            m = mark(start, nbr, key)\n",
    "            if m in visited:\n",
    "                continue\n",
    "            # 开始沿着非分叉链走\n",
    "            path_nodes = [start]\n",
    "            path_coords = []\n",
    "            cur, prev = start, None\n",
    "\n",
    "            while True:\n",
    "                # 选择从 cur 出发且未访问的边\n",
    "                next_edge = None\n",
    "                for _, nb, k, d in G.edges(cur, keys=True, data=True):\n",
    "                    mk = mark(cur, nb, k)\n",
    "                    if mk in visited:\n",
    "                        continue\n",
    "                    # 避免立刻折返（如果有其它可选）\n",
    "                    if prev is not None and nb == prev:\n",
    "                        continue\n",
    "                    next_edge = (cur, nb, k, d)\n",
    "                    break\n",
    "                if next_edge is None:\n",
    "                    # 如果没有其它边，就看看能不能把“回退那条”也并上（首步情况）\n",
    "                    for _, nb, k, d in G.edges(cur, keys=True, data=True):\n",
    "                        mk = mark(cur, nb, k)\n",
    "                        if mk not in visited:\n",
    "                            next_edge = (cur, nb, k, d)\n",
    "                            break\n",
    "                if next_edge is None:\n",
    "                    break\n",
    "\n",
    "                u, v, k, d = next_edge\n",
    "                # 方向化坐标并拼接（避免重复第一个点）\n",
    "                start_pos = np.array(G.nodes[u]['pos'])\n",
    "                seg = oriented_coords(d, start_pos)\n",
    "                if len(path_coords) == 0:\n",
    "                    path_coords = seg.copy()\n",
    "                else:\n",
    "                    path_coords = np.vstack([path_coords, seg[1:]])\n",
    "                visited.add(mark(u, v, k))\n",
    "\n",
    "                prev, cur = u, v\n",
    "                path_nodes.append(cur)\n",
    "                # 到达端点（度!=2）就停止\n",
    "                if deg[cur] != 2:\n",
    "                    break\n",
    "\n",
    "            if len(path_coords) >= 2:\n",
    "                chains.append({\n",
    "                    'nodes': path_nodes,\n",
    "                    'coords': path_coords,\n",
    "                    'length': path_length(path_coords)\n",
    "                })\n",
    "\n",
    "    # —— 处理纯环：该连通分量所有节点度数都为2 —— #\n",
    "    # 还有未访问的边说明它们属于环\n",
    "    for u, v, k in list(G.edges(keys=True)):\n",
    "        m = mark(u, v, k)\n",
    "        if m in visited:\n",
    "            continue\n",
    "        # 从 u 出发沿环走到无法继续\n",
    "        path_nodes = [u]\n",
    "        path_coords = []\n",
    "        cur, prev = u, None\n",
    "        while True:\n",
    "            next_edge = None\n",
    "            for _, nb, kk, d in G.edges(cur, keys=True, data=True):\n",
    "                mk = mark(cur, nb, kk)\n",
    "                if mk in visited:\n",
    "                    continue\n",
    "                # 在环里第一次可以任意选边，之后避免直接折返\n",
    "                if prev is not None and nb == prev:\n",
    "                    continue\n",
    "                next_edge = (cur, nb, kk, d)\n",
    "                break\n",
    "            if next_edge is None:\n",
    "                # 没有未访问边了，环走完\n",
    "                break\n",
    "            a, b, kk, d = next_edge\n",
    "            start_pos = np.array(G.nodes[a]['pos'])\n",
    "            seg = oriented_coords(d, start_pos)\n",
    "            if len(path_coords) == 0:\n",
    "                path_coords = seg.copy()\n",
    "            else:\n",
    "                path_coords = np.vstack([path_coords, seg[1:]])\n",
    "            visited.add(mark(a, b, kk))\n",
    "            prev, cur = a, b\n",
    "            path_nodes.append(cur)\n",
    "\n",
    "        if len(path_coords) >= 2:\n",
    "            chains.append({\n",
    "                'nodes': path_nodes,\n",
    "                'coords': path_coords,\n",
    "                'length': path_length(path_coords)\n",
    "            })\n",
    "\n",
    "    return chains\n",
    "\n",
    "def merge_and_find_longest_non_branching(all_paths, quant=1):\n",
    "    \"\"\"\n",
    "    主入口：\n",
    "    1) 在交叉/端点处切段并建图\n",
    "    2) 提取所有非分叉链（含纯环）\n",
    "    3) 返回最长链的坐标和长度\n",
    "    \"\"\"\n",
    "    G = cut_paths_to_edges(all_paths, q=quant)\n",
    "    chains = extract_non_branching_chains(G)\n",
    "    if not chains:\n",
    "        return None, 0.0, chains, G\n",
    "    longest = max(chains, key=lambda c: c['length'])\n",
    "    chain_dict = chains[0]\n",
    "    all_coords = chain_dict['coords']\n",
    "    # 返回所有轨迹\n",
    "    # all_chains = list({key: value['coords'] for key, value in chain_dict.items()}.values())\n",
    "    return longest['coords'], longest['length'], all_coords, G\n",
    "def merge_and_find_non_branching(all_paths, quant=1):\n",
    "    \"\"\"\n",
    "    主入口：\n",
    "    1) 在交叉/端点处切段并建图\n",
    "    2) 提取所有非分叉链（含纯环）\n",
    "    3) 返回所有链的坐标\n",
    "    \"\"\"\n",
    "    G = cut_paths_to_edges(all_paths, q=quant)\n",
    "    chains = extract_non_branching_chains(G)\n",
    "    if not chains:\n",
    "        return None, G\n",
    "    # chains是list，找一个元素，使得其在某个指标下最大，指标为元素长度\n",
    "    # chain的每个元素是一条链的各个信息\n",
    "    chains = sorted(chains, key=lambda c: c['length'], reverse=True)\n",
    "    all_seq_path = [i['coords'] for i in chains]\n",
    "    # 返回所有轨迹\n",
    "    # all_chains = list({key: value['coords'] for key, value in chain_dict.items()}.values())\n",
    "    return all_seq_path, G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780bccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分相关函数\n",
    "def path_length(path):\n",
    "    \"\"\"计算一条 path 的几何长度\"\"\"\n",
    "    diffs = np.diff(path, axis=0)\n",
    "    return np.sum(np.sqrt((diffs ** 2).sum(axis=1)))\n",
    "\n",
    "def build_graph(paths, tol=1e-6):\n",
    "    \"\"\"把所有 paths 合并成一张图\"\"\"\n",
    "    G = nx.Graph()\n",
    "    node_id = {}\n",
    "\n",
    "    def get_node_id(point):\n",
    "        for nid, coord in node_id.items():\n",
    "            if np.allclose(coord, point, atol=tol):\n",
    "                return nid\n",
    "        nid = len(node_id)\n",
    "        node_id[nid] = point\n",
    "        return nid\n",
    "\n",
    "    for path in paths:\n",
    "        src, dst = path[0], path[-1]\n",
    "        src_id, dst_id = get_node_id(src), get_node_id(dst)\n",
    "        length = path_length(path)\n",
    "        G.add_edge(src_id, dst_id, weight=length, coords=path)\n",
    "\n",
    "    return G, node_id\n",
    "\n",
    "def longest_path(paths):\n",
    "    \"\"\"返回合并后图上的最长路径坐标\"\"\"\n",
    "    G, node_id = build_graph(paths)\n",
    "    degrees = dict(G.degree())\n",
    "    endpoints = [n for n, d in degrees.items() if d == 1]\n",
    "\n",
    "    longest_len = -1\n",
    "    longest_coords = None\n",
    "\n",
    "    for i in range(len(endpoints)):\n",
    "        for j in range(i+1, len(endpoints)):\n",
    "            u, v = endpoints[i], endpoints[j]\n",
    "            for path_nodes in nx.all_simple_paths(G, u, v):\n",
    "                coords = []\n",
    "                total_len = 0\n",
    "                for k in range(len(path_nodes)-1):\n",
    "                    a, b = path_nodes[k], path_nodes[k+1]\n",
    "                    edge = G[a][b]\n",
    "                    coords_edge = edge[\"coords\"]\n",
    "\n",
    "                    # 判断方向\n",
    "                    if np.allclose(coords_edge[0], node_id[a]):\n",
    "                        coords.extend(coords_edge.tolist())\n",
    "                    else:\n",
    "                        coords.extend(coords_edge[::-1].tolist())\n",
    "\n",
    "                    total_len += edge[\"weight\"]\n",
    "\n",
    "                if total_len > longest_len:\n",
    "                    longest_len = total_len\n",
    "                    longest_coords = np.array(coords)\n",
    "\n",
    "    return longest_coords\n",
    "def longest_path_old(paths):\n",
    "    \"\"\"返回合并后图上的最长路径坐标\"\"\"\n",
    "    G, node_id = build_graph(paths)\n",
    "    degrees = dict(G.degree())\n",
    "    endpoints = [n for n, d in degrees.items() if d == 1]\n",
    "\n",
    "    longest_len = -1\n",
    "    longest_coords = None\n",
    "\n",
    "    for i in range(len(endpoints)):\n",
    "        for j in range(i+1, len(endpoints)):\n",
    "            u, v = endpoints[i], endpoints[j]\n",
    "            for path_nodes in nx.all_simple_paths(G, u, v):\n",
    "                coords = []\n",
    "                total_len = 0\n",
    "                for k in range(len(path_nodes)-1):\n",
    "                    edge = G[path_nodes[k]][path_nodes[k+1]]\n",
    "                    coords.extend(edge[\"coords\"].tolist())\n",
    "                    total_len += edge[\"weight\"]\n",
    "                if total_len > longest_len:\n",
    "                    longest_len = total_len\n",
    "                    longest_coords = np.array(coords)\n",
    "\n",
    "    return longest_coords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7ca4a0",
   "metadata": {},
   "source": [
    "#### 身体曲率计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d9c15da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_skeleton(skeleton, step=1.0):\n",
    "    \"\"\"\n",
    "    把骨架按固定像素间距重采样\n",
    "    skeleton: (N,2) 数组\n",
    "    step: 每隔多少像素取一个点\n",
    "    \"\"\"\n",
    "    skeleton = np.array(skeleton)\n",
    "    if len(skeleton) < 3:\n",
    "        return skeleton\n",
    "    \n",
    "    # 去掉重复点\n",
    "    diffs = np.diff(skeleton, axis=0)\n",
    "    mask = np.any(diffs != 0, axis=1)\n",
    "    skeleton = skeleton[np.r_[True, mask]]\n",
    "    if len(skeleton) < 3:\n",
    "        return skeleton\n",
    "    \n",
    "    x, y = skeleton[:,0], skeleton[:,1]\n",
    "    seglen = np.sqrt(np.diff(x)**2 + np.diff(y)**2)\n",
    "    dist = np.concatenate(([0], np.cumsum(seglen)))   # 单位：像素\n",
    "    total_len = dist[-1]\n",
    "    \n",
    "    # 归一化到 [0,1] 供 splprep 使用\n",
    "    u = dist / total_len\n",
    "    try:\n",
    "        tck, _ = splprep([x, y], s=0, u=u)\n",
    "    except Exception as e:\n",
    "        print(\"splprep error:\", e)\n",
    "        return skeleton\n",
    "    \n",
    "    # 在 [0,total_len] 上等间距采样\n",
    "    new_dist = np.arange(0, total_len, step)\n",
    "    new_u = new_dist / total_len\n",
    "    new_points = np.array(splev(new_u, tck)).T\n",
    "    return new_points\n",
    "\n",
    "def resample_skeleton_2(skeleton, step=1.0):\n",
    "    # 等像素间距采样\n",
    "    total_len = len(skeleton)\n",
    "    if total_len <= step*2:\n",
    "        return []\n",
    "    idx_series = np.arange(0,total_len, step)\n",
    "    selected_points = skeleton[idx_series,:]\n",
    "    return selected_points\n",
    "\n",
    "def curvature_from_angles(skeleton, step=1.0):\n",
    "    \"\"\"\n",
    "    通过角度差计算骨架曲率\n",
    "    返回：\n",
    "        curvatures: 每个点的角度差 (带正负号)\n",
    "        mean_curvature: 曲率强度指标\n",
    "    \"\"\"\n",
    "    pts = resample_skeleton_2(skeleton, step=step)\n",
    "    if not len(pts):\n",
    "        return np.nan\n",
    "\n",
    "    diffs = np.diff(pts, axis=0)\n",
    "    angles = np.arctan2(diffs[:,1], diffs[:,0])\n",
    "    # 解开角度防止跳变\n",
    "    angles_unwrapped = np.unwrap(angles)\n",
    "    # 相邻角度差\n",
    "    dtheta = np.diff(angles_unwrapped)\n",
    "    # # 曲率指标（你可以换成 np.mean(np.abs(dtheta))）\n",
    "    # mean_curvature = np.sqrt(np.mean(dtheta**2))\n",
    "    return np.degrees(dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "022f8148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 等间距重采样和滑动平均\n",
    "\n",
    "def moving_average(data, window_size=5):\n",
    "    \"\"\"对二维数据做滑动平均\"\"\"\n",
    "    kernel = np.ones(window_size) / window_size\n",
    "    x = np.convolve(data[:,0], kernel, mode='same')\n",
    "    y = np.convolve(data[:,1], kernel, mode='same')\n",
    "    return np.vstack((x,y)).T\n",
    "def resample_and_smooth(points, window_size=5):\n",
    "    # --- 等弧长重采样 ---\n",
    "    x, y = points[:,0], points[:,1]\n",
    "    dist = np.sqrt(np.diff(x)**2 + np.diff(y)**2)\n",
    "    s = np.concatenate(([0], np.cumsum(dist)))\n",
    "    total_length = s[-1]\n",
    "    s_uniform = np.linspace(0, total_length, len(points))\n",
    "    fx = interp1d(s, x, kind='linear')\n",
    "    fy = interp1d(s, y, kind='linear')\n",
    "    resampled = np.vstack((fx(s_uniform), fy(s_uniform))).T\n",
    "    \n",
    "    # --- 平滑 ---\n",
    "    smoothed = moving_average(resampled, window_size)\n",
    "    return resampled, smoothed\n",
    "def remove_outliers_by_jump(points, max_step=10):\n",
    "    \"\"\"\n",
    "    去掉瞬间跨度过大的点\n",
    "    points: (N,2) array\n",
    "    max_step: 相邻点最大允许移动距离 (像素)\n",
    "    \"\"\"\n",
    "    x, y = points[:,0], points[:,1]\n",
    "    dist = np.sqrt(np.diff(x)**2 + np.diff(y)**2)\n",
    "    # 第一个点保留\n",
    "    mask = np.ones(len(points), dtype=bool)\n",
    "    \n",
    "    # 如果跨度大于阈值，就把后一帧去掉\n",
    "    mask[1:][dist > max_step] = False\n",
    "    \n",
    "    return points[mask]\n",
    "def resample_and_dthatas(long_paths, step):\n",
    "    # 采样和平均\n",
    "    resampled = {}\n",
    "    # smoothed = {}\n",
    "    for key, skelon in long_paths.items():\n",
    "        if type(skelon) == type(None):\n",
    "            resampled[key] =  []\n",
    "        else:\n",
    "            # 去掉瞬移离群点\n",
    "            skelon = remove_outliers_by_jump(skelon, max_step=10)\n",
    "            resampled[key],_ = resample_and_smooth(skelon, window_size=50)\n",
    "    dtheta = {}\n",
    "    for key, skelon in resampled.items():\n",
    "        if type(None)==type(skelon):\n",
    "            dtheta[key] = None\n",
    "        elif (len(skelon)) < 200:\n",
    "            dtheta[key] = None\n",
    "        else:\n",
    "            dtheta_i = curvature_from_angles(skelon, step=step)\n",
    "            sum_dtheta_i = round(np.sum(dtheta_i),2)\n",
    "            dtheta[key]={'dtheta':dtheta_i,'sum_dtheta':sum_dtheta_i}\n",
    "    return resampled, dtheta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce05923",
   "metadata": {},
   "source": [
    "#### 路径比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e5bd110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 求路径比例和前两条路径长度的df\n",
    "def path_ratio(paths):\n",
    "    ratios = {}\n",
    "    len_dict = {}\n",
    "    for key, value in paths.items():\n",
    "        if len(value) >= 2:\n",
    "            # 如果大于2，求前两个的比例\n",
    "            len_ls = [len(path) for path in value]\n",
    "            len_ls.sort(reverse=True)\n",
    "            ratio = len_ls[0]/len_ls[1]\n",
    "            lens = len_ls[:2]\n",
    "        else:\n",
    "            ratio = np.nan\n",
    "            lens = []\n",
    "        ratios[key] = ratio\n",
    "        len_dict[key] = lens\n",
    "    df_ratio = pd.Series(ratios, name='path_ratio').to_frame()\n",
    "    df_len = pd.Series(len_dict, name='path_len').to_frame()\n",
    "    df = df_ratio.join(df_len, how='left')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0088b3",
   "metadata": {},
   "source": [
    "#### 标记turn主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b72e81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cor_turn_reversal(df,  after_turn_rev_lim = 50):\n",
    "    '''\n",
    "    df:包含已经平滑后的turn_pc列, 以及'forward'列\n",
    "    return: 包含两列的子df: 'turn_cor', 'forward_subs_turn'\n",
    "    '''\n",
    "    # 首先根据turn将reversal切断，只保留不为turn的reversal段\n",
    "    df.loc[:, 'forward_subs_turn'] = df['forward'].copy()\n",
    "    df.loc[df['turn_pc']==1,'forward_subs_turn'] = 0\n",
    "    df.loc[:,'turn_cor']  = df['turn_pc'].copy()\n",
    "\n",
    "    # 计算所有reversal段的长度 ，如果大于threshold,看前面是否有turn，有的话将这个turn删除\n",
    "    n = len(df)\n",
    "    # 找到连续的 reversal 段\n",
    "    df['turn_group'] = (df[\"turn_cor\"].diff().ne(0)).cumsum() * df[\"turn_cor\"]\n",
    "    # 遍历每个 reversal 区间\n",
    "    for gid, grp in df.groupby('turn_group'):\n",
    "        if gid == 0:\n",
    "            continue\n",
    "        # turn 段的结束位置（label）与位置索引（整数位置）\n",
    "        end_label = grp.index[-1]\n",
    "        end_pos = df.index.get_loc(end_label)\n",
    "\n",
    "        # 寻找紧接着出现 reversal 的位置（允许 small gap）\n",
    "        start_search_pos = end_pos + 1\n",
    "        if start_search_pos >= n:\n",
    "            # 如果数据到头了，舍弃\n",
    "            continue\n",
    "        found_pos = None\n",
    "\n",
    "        for offset in range(after_turn_rev_lim + 1):\n",
    "            p = start_search_pos + offset\n",
    "            if p >= n:\n",
    "                break\n",
    "            if df['forward_subs_turn'].iat[p] == 1:\n",
    "                found_pos = p\n",
    "                break\n",
    "        if found_pos is None:\n",
    "            # 没有紧接的 reversal\n",
    "            continue\n",
    "\n",
    "        # 计数 reversal 连续长度\n",
    "        q = found_pos\n",
    "        while q + 1 < n and df['forward_subs_turn'].iat[q + 1] == 1:\n",
    "            # 遍历reversal的长度，当超过reversal时停\n",
    "            q += 1\n",
    "        rev_len = q - found_pos + 1\n",
    "\n",
    "        if rev_len >= after_turn_rev_lim:\n",
    "            # 仅把这个 turn 段（grp.index）置 0：相当于不算这个turn\n",
    "            df.loc[grp.index, \"turn_cor\"] = 0\n",
    "            # 另外将这一段turn对应的前进状态改为reversal，便于后续分类转向行为\n",
    "            df.loc[grp.index, \"forward_subs_turn\"] = 1 \n",
    "        else:\n",
    "            df.iloc[found_pos:found_pos+rev_len, df.columns.get_loc('forward_subs_turn')] = 0\n",
    "            # 如果这个长度小于阈值，则仍然保留turn，并且把接着的这个reverse变为前进\n",
    "    return df[['turn_cor', 'forward_subs_turn']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3751b31",
   "metadata": {},
   "source": [
    "##### 可视化验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9d6c6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 求1的开始和结束点\n",
    "def get_turn_interval(df, col_name):\n",
    "    # labels打印矩形\n",
    "    labels = df[col_name].values\n",
    "    n = len(labels)\n",
    "    # 找出连续的 label==1 区间\n",
    "    turn_intervals = []\n",
    "    in_turn = False\n",
    "    start = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        if labels[i] == 1 and not in_turn:\n",
    "            # turn开始\n",
    "            start = i\n",
    "            in_turn = True\n",
    "        elif labels[i] != 1 and in_turn:\n",
    "            # turn结束\n",
    "            end = i - 1\n",
    "            turn_intervals.append((start, end))\n",
    "            in_turn = False\n",
    "\n",
    "    # 如果最后一个点也是turn状态\n",
    "    if in_turn:\n",
    "        turn_intervals.append((start, n - 1))\n",
    "    return turn_intervals\n",
    "def visualize_turn_correction(p_f, df, close_size = 50, open_size = 50, x_lim = []):\n",
    "    '''\n",
    "    这个函数是可视化turn的矫正(删除reversal内部的)\n",
    "    '''\n",
    "    # 可视化验证\n",
    "    reversal_ints = get_turn_interval(df, 'forward')\n",
    "    subs_reversal_ints = get_turn_interval(df, 'forward_subs_turn')\n",
    "\n",
    "    # Turns: 开闭后的turn\n",
    "    # turn_ints = get_turn_interval(df, 'turn')\n",
    "    turn_pc_ints = get_turn_interval(df, 'turn_pc')\n",
    "    turn_cor_ints = get_turn_interval(df, 'turn_cor')\n",
    "\n",
    "    if 'label' in df.columns:\n",
    "        # artificial labeling\n",
    "        label_ints = get_turn_interval(df, 'label')\n",
    "        # 绘图\n",
    "        fig,ax = plt.subplots(5,1,figsize=(20,10), sharex=True)\n",
    "        for start, end in subs_reversal_ints:\n",
    "            ax[-1].axvspan(start, end, color='blue', alpha=1)  # alpha控制透明度\n",
    "        for start, end in label_ints:\n",
    "            ax[-1].axvspan(start, end, color='blue', alpha=1)  # alpha控制透明度\n",
    "        ax[-1].set_title(f'artificial labels')\n",
    "    else:\n",
    "        fig,ax = plt.subplots(4,1,figsize=(20,10), sharex=True)\n",
    "\n",
    "    # 矫正前自动标记\n",
    "    for start, end in reversal_ints:\n",
    "        ax[0].axvspan(start, end, color='blue', alpha=1)  # alpha控制透明度\n",
    "    for start, end in turn_pc_ints:\n",
    "        ax[0].axvspan(start, end, color='orange', alpha=1)  # alpha控制透明度\n",
    "    ax[0].set_title(f'automated labeling of turn close:{close_size},open:{open_size}')\n",
    "\n",
    "    # 矫正后标记\n",
    "    for start, end in subs_reversal_ints:\n",
    "        ax[1].axvspan(start, end, color='blue', alpha=1)  # alpha控制透明度\n",
    "    for start, end in turn_cor_ints:\n",
    "        ax[1].axvspan(start, end, color='orange', alpha=1)  # alpha控制透明度\n",
    "    ax[1].set_title(f'corrected turn labeling')\n",
    "\n",
    "    # 纯平滑后的reversal\n",
    "    for start, end in subs_reversal_ints:\n",
    "        ax[2].axvspan(start, end, color='blue', alpha=1)  # alpha控制透明度\n",
    "    ax[2].set_title(f'reversal_substract_turn')\n",
    "\n",
    "    # 平滑前的reversal\n",
    "    for start, end in reversal_ints:\n",
    "        ax[3].axvspan(start, end, color='blue', alpha=1)  # alpha控制透明度\n",
    "    ax[3].set_title(f'reversal')\n",
    "\n",
    "    desired_ticks = np.arange(0, len(df), 2000) # 生成一个数组 [10, 30, 50, 70, 90]\n",
    "    ax[-1].set_xticks(desired_ticks)\n",
    "    if len(x_lim):\n",
    "        ax[-1].set_xlim(*x_lim)\n",
    "    plt.savefig(p_f+'\\\\visual_turn_correction.png', bbox_inches='tight')\n",
    "    # plt.show()\n",
    "\n",
    "def visualize_turn_labeling(p_f, df,path_ratio_uplim,dtheta_lim, close_size = 50, open_size = 50, x_lim=[]):\n",
    "    '''\n",
    "    可视化turn的标注条件和标注\n",
    "    '''\n",
    "    # 可视化验证\n",
    "    reversal_ints = get_turn_interval(df, 'forward')\n",
    "    turn_ints = get_turn_interval(df, 'turn')\n",
    "    # 开闭后的turn\n",
    "    turn_pc_ints = get_turn_interval(df, 'turn_pc')\n",
    "    # circular\n",
    "    cir_ints = get_turn_interval(df, 'circular')\n",
    "    # branching\n",
    "    bra_ints = get_turn_interval(df, 'branching')\n",
    "    # path_ratio\n",
    "    df['path_ratio_dis'] = np.where(df['path_ratio'] <= path_ratio_uplim, 1, 0)\n",
    "    ratio_ints = get_turn_interval(df,'path_ratio_dis')\n",
    "    # sum_dtheta\n",
    "    df['sum_dtheta_dis'] = np.where(df['sum_dtheta'].abs() >= dtheta_lim , 1, 0)\n",
    "    dtheta_ints = get_turn_interval(df, \"sum_dtheta_dis\")\n",
    "\n",
    "    if 'label' in df.columns:\n",
    "        # artificial labeling\n",
    "        label_ints = get_turn_interval(df, 'label')\n",
    "        # 绘图\n",
    "        fig,ax = plt.subplots(7,1,figsize=(20,10), sharex=True)\n",
    "        for start, end in label_ints:\n",
    "            ax[-1].axvspan(start, end, color='red', alpha=1)  # alpha控制透明度\n",
    "        ax[-1].set_title('artificial labeling of turn')\n",
    "    else:\n",
    "        fig,ax = plt.subplots(6,1,figsize=(20,10), sharex=True)\n",
    "\n",
    "    # 绘制人工打标记\n",
    "\n",
    "    for start, end in turn_ints:\n",
    "        ax[-2].axvspan(start, end, color='orange', alpha=1)  # alpha控制透明度\n",
    "    ax[-2].set_title('automated labeling of turn')\n",
    "    # for start, end in reversal_ints:\n",
    "    #     ax[1].axvspan(start, end, color='blue', alpha=1)  # alpha控制透明度\n",
    "\n",
    "    for start, end in cir_ints:\n",
    "        ax[0].axvspan(start, end, color='orange', alpha=1)  # alpha控制透明度\n",
    "    ax[0].set_title('circular')\n",
    "    for start, end in bra_ints:\n",
    "        ax[1].axvspan(start, end, color='orange', alpha=1)  # alpha控制透明度\n",
    "    ax[1].set_title('branching')\n",
    "    for start, end in ratio_ints:\n",
    "        ax[2].axvspan(start, end, color='orange', alpha=1)  # alpha控制透明度\n",
    "    ax[2].set_title('path_ratio')\n",
    "    for start, end in dtheta_ints:\n",
    "        ax[3].axvspan(start, end, color='orange', alpha=1)  # alpha控制透明度\n",
    "    ax[3].set_title('sum_dtheta')\n",
    "    desired_ticks = np.arange(0, len(df), 2000) # 生成一个数组 [10, 30, 50, 70, 90]\n",
    "    ax[-1].set_xticks(desired_ticks)\n",
    "    for start, end in reversal_ints:\n",
    "        ax[4].axvspan(start, end, color='blue', alpha=1)  # alpha控制透明度\n",
    "    for start, end in turn_pc_ints:\n",
    "        ax[4].axvspan(start, end, color='orange', alpha=1)  # alpha控制透明度\n",
    "    ax[4].set_title(f'turn_open_closed. close:{close_size},open:{open_size}')\n",
    "    if len(x_lim):\n",
    "        ax[-1].set_xlim(*x_lim)\n",
    "    plt.savefig(p_f+'\\\\visual_turn_labeling.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79de44f",
   "metadata": {},
   "source": [
    "#### 头部曲率和角速度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be78131e",
   "metadata": {},
   "source": [
    "确定骨架和头朝向函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f95ed311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数根据咽喉位置决定翻转\n",
    "def process_skeleton(points, pos_phr, n_segments=30):\n",
    "    \"\"\"\n",
    "    points: list of (x, y)\n",
    "    pos_phr: (x, y) 咽喉点\n",
    "    n_segments: 要分的段数\n",
    "    \"\"\"\n",
    "    # 1. 转成 DataFrame\n",
    "    points = np.array(points)\n",
    "    points = resample_skeleton(points,step=1)\n",
    "    n_points = len(points)\n",
    "\n",
    "    # 2. 找最近的点\n",
    "    pos_phr = np.array(pos_phr)\n",
    "    dist = np.linalg.norm(points - pos_phr, axis=1)\n",
    "    idx_phr = np.argmin(dist)\n",
    "    # 4. 比较长度\n",
    "    # len_left = idx_phr\n",
    "    # len_right = len(dist)-idx_phr\n",
    "    # 3. 计算左侧累计长度\n",
    "    len_left = np.sum(\n",
    "        np.linalg.norm(points[1:idx_phr+1] - points[:idx_phr], axis=1)\n",
    "    )\n",
    "    # 4. 计算右侧累计长度\n",
    "    len_right = np.sum(\n",
    "        np.linalg.norm(points[idx_phr+1:] - points[idx_phr:-1], axis=1)\n",
    "    )\n",
    "\n",
    "    # 5. 是否翻转\n",
    "    if len_left > len_right:\n",
    "        points = points[::-1]\n",
    "    return points\n",
    "def select_backbone(paths, closest_idx,pos_phr, longest_paths):\n",
    "    '''\n",
    "    提取最长骨架，确定头朝向\n",
    "    '''\n",
    "    # 提取原最接近咽喉的骨架\n",
    "    closest_path = {}\n",
    "    for key, all_paths in paths.items():   # paths 是 dict 的情况\n",
    "        idx = closest_idx[key]\n",
    "        closest_path[key] = all_paths[idx]\n",
    "    # 选择骨架\n",
    "    sel_paths = {}\n",
    "    for key, longest in longest_paths.items():\n",
    "        closest = closest_path[key]\n",
    "        if type(longest)==type(None):\n",
    "            # 重合并无骨架，选择closest\n",
    "            sel_paths[key] = closest_path[key]\n",
    "            continue\n",
    "        # 计算头尾距离\n",
    "        head = longest[0]\n",
    "        tail = longest[-1]\n",
    "        closest_head = closest[0]\n",
    "        dist_head = (head[0]-closest_head[0])**2 + (head[1]-closest_head[1])**2\n",
    "        dist_tail = (tail[0]-closest_head[0])**2 + (tail[1]-closest_head[1])**2\n",
    "        if len(longest) > len(closest) & (min(dist_tail, dist_head) <= 10):\n",
    "            # 两条轨迹的头是一样的，否则即使longest更长也不要\n",
    "            sel_paths[key] = longest\n",
    "        else:\n",
    "            sel_paths[key] = closest\n",
    "    # 根据咽喉坐标,距离咽喉近的设为头\n",
    "    rev_sel_path = {}\n",
    "    for key, sel in sel_paths.items():\n",
    "        pos_phr_i = pos_phr[key]\n",
    "        re_pos_phr_i = [pos_phr_i[1], pos_phr_i[0]]\n",
    "        rev_sel = process_skeleton(sel, re_pos_phr_i)\n",
    "        rev_sel_path[key] = rev_sel\n",
    "    return rev_sel_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19553a60",
   "metadata": {},
   "source": [
    "计算曲率函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c82f94fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_angle(vector1, vector2):\n",
    "    \"\"\"\n",
    "        计算带符号的角度（-180° 到 180°）\n",
    "        正角度表示从 vector1 到 vector2 是逆时针旋转\n",
    "        负角度表示顺时针旋转\n",
    "        \"\"\"\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    cross_product = np.cross(vector1, vector2)  # 在 2D 中，这给出标量值\n",
    "    magnitude1 = np.linalg.norm(vector1)\n",
    "    magnitude2 = np.linalg.norm(vector2)\n",
    "    denominator = magnitude1 * magnitude2\n",
    "    if denominator < 1e-10:  # 设置一个很小的阈值\n",
    "        # 处理零向量的情况\n",
    "        cos_theta = 1.0 if np.allclose(vector1, vector2) else np.nan\n",
    "        sin_theta = 0.0\n",
    "    else:\n",
    "        cos_theta = dot_product / (magnitude1 * magnitude2)\n",
    "        sin_theta = cross_product / (magnitude1 * magnitude2)\n",
    "    # 使用 arctan2 获取带符号的角度\n",
    "    angle_rad = np.arctan2(sin_theta, cos_theta)\n",
    "    return np.degrees(angle_rad)\n",
    "\n",
    "def label_segments(points, step=30):\n",
    "    df_bb = pd.DataFrame(points, columns=['X', 'Y'])\n",
    "    seg_len = np.linalg.norm(points[1:] - points[:-1], axis=1)\n",
    "    # 累计距离\n",
    "    cumdist = np.concatenate([[0], np.cumsum(seg_len)])\n",
    "    # 分段编号\n",
    "    seg_id = (cumdist // step).astype(int)\n",
    "    df_bb = df_bb.copy()\n",
    "    df_bb['seg_id'] = seg_id\n",
    "    colors_bgr = [\n",
    "    (255, 0, 0),     # 蓝色\n",
    "    (0, 255, 0),     # 绿色\n",
    "    (0, 0, 255),     # 红色\n",
    "    (0, 255, 255),   # 黄色 (BGR: cyan+red)\n",
    "    (255, 0, 255),   # 洋红 (magenta)\n",
    "    (255, 255, 0)    # 青色 (cyan)\n",
    "    ]\n",
    "    # 建立 seg_id 到颜色的映射\n",
    "    dict_colors = {key: colors_bgr[key % len(colors_bgr)] for key in range(len(colors_bgr))}\n",
    "    df_bb['color'] = df_bb['seg_id'].apply(lambda x: dict_colors[x%6])\n",
    "    return df_bb\n",
    "def label_segments_curvature(points,pos_phr, step=30):\n",
    "    if not len(points):\n",
    "        return None, None, None\n",
    "    df_bb = pd.DataFrame(points, columns=['X', 'Y'])\n",
    "    seg_len = np.linalg.norm(points[1:] - points[:-1], axis=1)\n",
    "    # 累计距离\n",
    "    cumdist = np.concatenate([[0], np.cumsum(seg_len)])\n",
    "    # 分段编号\n",
    "    seg_id = (cumdist // step).astype(int)\n",
    "    df_bb = df_bb.copy()\n",
    "    df_bb['seg_id'] = seg_id\n",
    "\n",
    "    # 分段后根据咽喉所在段求头部曲率\n",
    "    pos_phr = np.array([pos_phr[0],pos_phr[1]])\n",
    "    dist = np.linalg.norm(points - pos_phr, axis=1)\n",
    "    idx_phr = np.argmin(dist)\n",
    "    df_phr = df_bb.iloc[idx_phr]\n",
    "    seg_phr_idx = df_bb.iloc[idx_phr]['seg_id']\n",
    "    # 提取靠后的点\n",
    "    # seg_pos_idx = (seg_phr_idx-2)\n",
    "    df_seg_pos = df_bb[df_bb['seg_id']==(seg_phr_idx+6)]\n",
    "    # 头部顶点\n",
    "    df_start = df_bb.iloc[0]\n",
    "    if not len(df_seg_pos):\n",
    "        curvature = None\n",
    "        pos_phr = None\n",
    "        phr_node = None\n",
    "    else:\n",
    "        df_pos_end = df_seg_pos.iloc[-1]\n",
    "        # 指向向量\n",
    "        pos_phr = [df_phr['X']-df_pos_end['X'], df_phr['Y']-df_pos_end['Y']]\n",
    "        phr_node = [df_start['X']-df_phr['X'], df_start['Y']-df_phr['Y']]\n",
    "        curvature = calc_angle(pos_phr, phr_node)\n",
    "\n",
    "    # 根据前两段求头部指向向量用于计算角速度\n",
    "    df_seg2 = df_bb[df_bb['seg_id']==2]\n",
    "    if not len(df_seg2):\n",
    "        head_vector = [np.nan, np.nan]\n",
    "    else:\n",
    "        seg2_end = df_seg2.iloc[-1]\n",
    "        head_vector = [df_start['X']-seg2_end['X'], df_start['Y']-seg2_end['Y']]\n",
    "\n",
    "    return df_bb, curvature, head_vector, pos_phr, phr_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2d449a",
   "metadata": {},
   "source": [
    "计算头部角速度函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29ce4e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_head_agl_velocity(df, window_size=300, frame_rate=38):\n",
    "    '''\n",
    "    对向量的角度变化进行滤波计算\n",
    "    '''\n",
    "    # 平滑计算角速度\n",
    "    head_vectors =  df['head_vector']\n",
    "    head_vec_filled = head_vectors.apply(lambda v: v if isinstance(v, (list, np.ndarray)) else [np.nan, np.nan])\n",
    "    head_arr = np.vstack(head_vec_filled)\n",
    "    dy = head_arr[:,0]\n",
    "    dx = head_arr[:,1]\n",
    "    # 假设 dx, dy shape (T,)\n",
    "    angles = np.arctan2(dy,dx)          # radians\n",
    "    angles_interp = pd.Series(angles).interpolate(limit_direction=\"both\").to_numpy()\n",
    "    angles_unwrapped = np.unwrap(angles_interp)\n",
    "\n",
    "    # 采样间隔 dt (s) —— 例：300帧 = 15s -> dt = 15/300 = 0.05\n",
    "    dt = 1 / frame_rate  # = 0.05\n",
    "\n",
    "    angles_unwrapped = np.array(angles_unwrapped, dtype=float)\n",
    "    mask = np.isfinite(angles_unwrapped)\n",
    "    angles_clean = angles_unwrapped[mask]\n",
    "\n",
    "    # 2. 设置合适的窗口\n",
    "    window = min(window_size, len(angles_clean) // 2 * 2 + 1)  # 不超过数据长度的最大奇数\n",
    "    if window < 3: \n",
    "        window = 3  # 最小窗口\n",
    "\n",
    "    # 3. 滤波\n",
    "    angular_velocity = savgol_filter(\n",
    "        angles_clean,\n",
    "        window_length=window,\n",
    "        polyorder=1,\n",
    "        deriv=1,\n",
    "        delta=dt,\n",
    "        mode=\"interp\"\n",
    "    )\n",
    "    # 若需要度/秒：\n",
    "    angular_velocity_deg = np.degrees(angular_velocity)\n",
    "    df['ang_velocity'] = angular_velocity_deg\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582020a9",
   "metadata": {},
   "source": [
    "#### Turn和曲率主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63562f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 输入中线地址，输出包含中线相关参数的df\n",
    "# def get_omega_turn_curvature(mid_line_path, path_ratio_uplim = 1.5, path_uplim=200, dtheta_lim=220,\n",
    "#                               cl_turn_size = 50, op_turn_size = 50, visualize_turn=True,\n",
    "#                               seg_pixel_step = 13, agl_window = 300, frame_rate=38, ):\n",
    "#     '''\n",
    "#     mid_line_path:中线文件路径\n",
    "#     '''\n",
    "#     npz_data = np.load(mid_line_path, allow_pickle=True)\n",
    "#     data = npz_data['arr_0'].item()\n",
    "#     # data_keys = list(data.keys())\n",
    "#     paths= {key: value['all_paths'] for key, value in data.items()}\n",
    "#     closest_idx = {key: value['closest path'] for key, value in data.items()}\n",
    "#     pos_phr = {key: value['pos_phr'] for key, value in data.items()}\n",
    "#     vector_h = {key: value['vector_h'] for key, value in data.items()} \n",
    "#     circular = {key: value['circular'] for key, value in data.items()}\n",
    "#     branching = {key: value['branching'] for key, value in data.items()}\n",
    "\n",
    "#     # 骨架拆分\n",
    "#     seq_paths = {}\n",
    "#     for key, value in paths.items():\n",
    "#         # print(merge_and_find_non_branching(value, quant=3))\n",
    "#         seq_path_i, _ = merge_and_find_non_branching(\n",
    "#             value,\n",
    "#             quant=3   # 若不同段的交点不完全重合，可设 quant=2 或 3 像素，把近点聚成同一节点\n",
    "#         )\n",
    "#         seq_paths[key] = seq_path_i\n",
    "#     # 骨架合并，得到最长骨架\n",
    "#     longest_paths = {}\n",
    "#     for key, value in seq_paths.items():\n",
    "#         longest_coords = longest_path(value)\n",
    "#         longest_paths[key] = longest_coords\n",
    "\n",
    "#     # 对最常骨架重采样计算曲率\n",
    "#     resampled, dtheta = resample_and_dthatas(longest_paths,step=20)\n",
    "#     sum_dtheta = {\n",
    "#         key: (value['sum_dtheta'] if isinstance(value, dict) and 'sum_dtheta' in value else None)\n",
    "#         for key, value in dtheta.items()\n",
    "#         }\n",
    "#     # 曲率计算结果生成df\n",
    "#     df_sum_dtheta = pd.Series(sum_dtheta, name='sum_dtheta')\n",
    "#     print(f'df_sum_dtheta的长度{len(df_sum_dtheta)}和最大index{df_sum_dtheta.index.max()}')\n",
    "#     # 计算路径比例\n",
    "#     df = path_ratio(paths)\n",
    "#     df['sum_dtheta'] = df_sum_dtheta\n",
    "#     # 合并环形和分叉信息\n",
    "#     df_cir_branching = pd.DataFrame.from_dict(\n",
    "#         {\"circular\": circular, \"branching\": branching},\n",
    "#         orient=\"index\").T\n",
    "#     df[[\"circular\", \"branching\"]] = df_cir_branching[[\"circular\", \"branching\"]]\n",
    "\n",
    "#     # 分类turn\n",
    "#     df['path_lim'] = df['path_len'].apply(\n",
    "#         lambda x: 1 if (isinstance(x, (list, tuple, np.ndarray)) and len(x) > 1 and x[1] >= path_uplim) else 0\n",
    "#     )\n",
    "#     df['turn'] = 0\n",
    "#     df.loc[\n",
    "#         (df['circular'] == 1) |\n",
    "#         (df['branching'] == 1) |\n",
    "#         ((df['path_ratio'] <= path_ratio_uplim)&(df['path_lim'] == 1)) |\n",
    "#         (df['sum_dtheta'].abs() >= dtheta_lim)\n",
    "#         ,\n",
    "#         'turn'] = 1\n",
    "#     # 平滑turn\n",
    "#     closed = ndimage.binary_closing(df['turn'].values, structure=np.ones(cl_turn_size))\n",
    "#     # 再进行开操作（先腐蚀后膨胀）：去除小的噪声点\n",
    "#     opened = ndimage.binary_opening(closed, structure=np.ones(op_turn_size))\n",
    "#     # 将结果转换为整数并添加到 DataFrame\n",
    "#     df['turn_pc'] = opened.astype(int)\n",
    "#     df_turn_forw = df[['turn_pc', 'forward']]\n",
    "#     df[['turn_cor', 'forward_subs_turn']] = get_cor_turn_reversal(df_turn_forw)\n",
    "\n",
    "#     if visualize_turn:\n",
    "#         visualize_turn_labeling(df,path_ratio_uplim,dtheta_lim, cl_turn_size, op_turn_size)\n",
    "#         visualize_turn_correction(df, close_size=cl_turn_size, open_size=op_turn_size)\n",
    "    \n",
    "#     # 计算曲率\n",
    "#     rev_sel_path = select_backbone(paths, closest_idx,pos_phr, longest_paths)\n",
    "#     curvature = {}\n",
    "#     head_vector = {}\n",
    "#     post_phr = {}\n",
    "#     phr_noses = {}\n",
    "#     for key, sel in rev_sel_path.items():\n",
    "#         pos_phr_i = pos_phr[key]\n",
    "#         re_pos_phr_i = [pos_phr_i[1], pos_phr_i[0]]\n",
    "#         df_bb_i, curvature_i, head_vector_i, post_phr_i, phr_noses_i = label_segments_curvature(sel,re_pos_phr_i, step=seg_pixel_step)\n",
    "#         curvature[key] = curvature_i\n",
    "#         head_vector[key] = head_vector_i\n",
    "#         post_phr[key] = post_phr_i\n",
    "#         phr_noses[key] = phr_noses_i\n",
    "#     df_cur = pd.Series(curvature, name='curvature')\n",
    "#     df_head_vec = pd.Series(head_vector, name='head_vector')\n",
    "#     df_sel = pd.Series(rev_sel_path, name='sel_paths')\n",
    "#     df['curvature'] = df_cur\n",
    "#     df['head_vector'] = df_head_vec\n",
    "#     df['sel_paths'] = df_sel\n",
    "#     df = cal_head_agl_velocity(df, window_size=agl_window, frame_rate=frame_rate)\n",
    "#     print(df.columns)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4931eab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入中线地址，和运动参数df\n",
    "# 输出包含中线相关参数（以及时间列‘Time’）的df\n",
    "def get_omega_turn_curvature(p_f, df_merged, mid_line_path, path_ratio_uplim = 1.5, path_uplim=200, dtheta_lim=220,\n",
    "                              cl_turn_size = 50, op_turn_size = 50, cl_rev_size = 50, op_rev_size = 50,\n",
    "                                visualize_turn=True, seg_pixel_step = 13, agl_window = 300, frame_rate=38):\n",
    "    '''\n",
    "    处理中线标记前进后退和turn,reversal等加入运动参数df\n",
    "    df_merged: 包含运动数据和其它中线数据(row和choose_frame)\n",
    "    mid_line_path:中线文件路径\n",
    "    '''\n",
    "    npz_data = np.load(mid_line_path, allow_pickle=True)\n",
    "    data = npz_data['arr_0'].item()\n",
    "    # data_keys = list(data.keys())\n",
    "    paths= {key: value['all_paths'] for key, value in data.items()}\n",
    "    closest_idx = {key: value['closest path'] for key, value in data.items()}\n",
    "    pos_phr = {key: value['pos_phr'] for key, value in data.items()}\n",
    "    # angle_m = {key: value['angle_m'] for key, value in data.items()}\n",
    "    vector_h = {key: value['vector_h'] for key, value in data.items()} \n",
    "    circular = {key: value['circular'] for key, value in data.items()}\n",
    "    branching = {key: value['branching'] for key, value in data.items()}\n",
    "\n",
    "    # 前进后退\n",
    "    df_mot_slice = df_merged[['Time','X', 'Y',\"x_velocity\",\"y_velocity\", 'angle_m','angle_md']].copy()\n",
    "    df_mot_slice = label_smth_forward_reverse(df_mot_slice, close_size = cl_rev_size, open_size = op_rev_size)\n",
    "    # 运动方向向量\n",
    "    df_mot_slice.loc[:,'moving_vec'] = df_mot_slice.apply(lambda x: (x['x_velocity'], x['y_velocity']),axis = 1)\n",
    "    # 头部朝向向量\n",
    "    df_mot_slice.loc[:,'heading_vec'] = df_mot_slice.apply(lambda x: rotation_mat_2(x['angle_md'], x['moving_vec']), axis=1)\n",
    "    # 求投影头部朝向后的运动向量\n",
    "    df_mot_slice.loc[:,'head_moving'] = df_mot_slice.apply(lambda x: project_vector_A_on_B(x['moving_vec'], x['heading_vec']), axis=1)\n",
    "\n",
    "    # 骨架拆分\n",
    "    seq_paths = {}\n",
    "    for key, value in paths.items():\n",
    "        # print(merge_and_find_non_branching(value, quant=3))\n",
    "        seq_path_i, _ = merge_and_find_non_branching(\n",
    "            value,\n",
    "            quant=3   # 若不同段的交点不完全重合，可设 quant=2 或 3 像素，把近点聚成同一节点\n",
    "        )\n",
    "        seq_paths[key] = seq_path_i\n",
    "    # 骨架合并，得到最长骨架\n",
    "    longest_paths = {}\n",
    "    for key, value in seq_paths.items():\n",
    "        longest_coords = longest_path(value)\n",
    "        longest_paths[key] = longest_coords\n",
    "\n",
    "    # 对最常骨架重采样计算曲率\n",
    "    resampled, dtheta = resample_and_dthatas(longest_paths,step=20)\n",
    "    sum_dtheta = {\n",
    "        key: (value['sum_dtheta'] if isinstance(value, dict) and 'sum_dtheta' in value else None)\n",
    "        for key, value in dtheta.items()\n",
    "        }\n",
    "    # 曲率计算结果生成df\n",
    "    df_sum_dtheta = pd.Series(sum_dtheta, name='sum_dtheta')\n",
    "    print(f'df_sum_dtheta的长度{len(df_sum_dtheta)}和最大index{df_sum_dtheta.index.max()}')\n",
    "    # 计算路径比例\n",
    "    df = path_ratio(paths)\n",
    "    df.loc[:,'sum_dtheta'] = df_sum_dtheta\n",
    "    # 合并环形和分叉信息\n",
    "    df_cir_branching = pd.DataFrame.from_dict(\n",
    "        {\"circular\": circular, \"branching\": branching},\n",
    "        orient=\"index\").T\n",
    "    df[[\"circular\", \"branching\"]] = df_cir_branching[[\"circular\", \"branching\"]].copy()\n",
    "\n",
    "    # 分类turn\n",
    "    df['path_lim'] = df['path_len'].apply(\n",
    "        lambda x: 1 if (isinstance(x, (list, tuple, np.ndarray)) and len(x) > 1 and x[1] >= path_uplim) else 0\n",
    "    )\n",
    "    df['turn'] = 0\n",
    "    df.loc[\n",
    "        (df['circular'] == 1) |\n",
    "        (df['branching'] == 1) |\n",
    "        ((df['path_ratio'] <= path_ratio_uplim)&(df['path_lim'] == 1)) |\n",
    "        (df['sum_dtheta'].abs() >= dtheta_lim)\n",
    "        ,\n",
    "        'turn'] = 1\n",
    "    # 平滑turn\n",
    "    closed = ndimage.binary_closing(df['turn'].values, structure=np.ones(cl_turn_size))\n",
    "    # 再进行开操作（先腐蚀后膨胀）：去除小的噪声点\n",
    "    opened = ndimage.binary_opening(closed, structure=np.ones(op_turn_size))\n",
    "    # 将结果转换为整数并添加到 DataFrame\n",
    "    df.loc[:,'turn_pc'] = opened.astype(int)\n",
    "\n",
    "\n",
    "    # 合并前进后退信息\n",
    "    df[['Time','forward', 'moving_vec', 'heading_vec', 'head_moving']] = df_mot_slice[['Time', 'forward', 'moving_vec', 'heading_vec', 'head_moving']].copy()\n",
    "    df_turn_forw = df[['turn_pc', 'forward']].copy()\n",
    "    df[['turn_cor', 'forward_subs_turn']] = get_cor_turn_reversal(df_turn_forw)\n",
    "\n",
    "    if visualize_turn:\n",
    "        visualize_turn_labeling(p_f, df,path_ratio_uplim,dtheta_lim, cl_turn_size, op_turn_size)\n",
    "        visualize_turn_correction(p_f, df, close_size=cl_turn_size, open_size=op_turn_size)\n",
    "\n",
    "    # 计算曲率\n",
    "    rev_sel_path = select_backbone(paths, closest_idx,pos_phr, longest_paths)\n",
    "    curvature = {}\n",
    "    head_vector = {}\n",
    "    post_phr = {}\n",
    "    phr_noses = {}\n",
    "    for key, sel in rev_sel_path.items():\n",
    "        pos_phr_i = pos_phr[key]\n",
    "        re_pos_phr_i = [pos_phr_i[1], pos_phr_i[0]]\n",
    "        df_bb_i, curvature_i, head_vector_i, post_phr_i, phr_noses_i = label_segments_curvature(sel,re_pos_phr_i, step=seg_pixel_step)\n",
    "        curvature[key] = curvature_i\n",
    "        head_vector[key] = head_vector_i\n",
    "        post_phr[key] = post_phr_i\n",
    "        phr_noses[key] = phr_noses_i\n",
    "    df_cur = pd.Series(curvature, name='curvature')\n",
    "    df_head_vec = pd.Series(head_vector, name='head_vector')\n",
    "    df_sel = pd.Series(rev_sel_path, name='sel_paths')\n",
    "    df['curvature'] = df_cur\n",
    "    df['head_vector'] = df_head_vec\n",
    "    df['sel_paths'] = df_sel\n",
    "    df = cal_head_agl_velocity(df, window_size=agl_window, frame_rate=frame_rate)\n",
    "    print('Columns:',df.columns)\n",
    "    return df\n",
    "    # 最后得到的中线df的key和运动相同，并且时间是一样的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13acb14",
   "metadata": {},
   "source": [
    "## 单文件处理函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b61cbd1",
   "metadata": {},
   "source": [
    "### 函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b9aa469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_points(points):\n",
    "    \"\"\"确保骨架点是 (N,2) int32 数组\"\"\"\n",
    "    arr = np.array(points, dtype=np.float32)\n",
    "    arr = np.vstack(arr)                # 去掉长度为1的维度\n",
    "\n",
    "    arr = arr.astype(np.int32)           # OpenCV 要 int32\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82f3ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_contained_or_not(p_f, label_corner = True):\n",
    "    '''\n",
    "    判断文件夹中是否包含所需要的文件\n",
    "    '''\n",
    "    if label_corner:\n",
    "        required_files = ['stage_data.txt', 'c1.txt',\n",
    "                        'upper_left.txt', 'lower_left.txt', 'upper_right.txt',\n",
    "                        'lower_right.txt']   # 数据处理需要的文件\n",
    "    else:   \n",
    "        required_files = ['stage_data.txt', 'c1.txt',\n",
    "                        'edge0.txt', 'edge45.txt']   # 数据处理需要的文件\n",
    "    required_files_set = set(required_files)\n",
    "    files = [f for f in os.listdir(p_f) if '.txt' in f ]\n",
    "    files_set = set(files)\n",
    "    is_contained = required_files_set.issubset(files_set)\n",
    "    # 找出missing_files\n",
    "    missing_files = [file for file in required_files if file not in files]\n",
    "    return is_contained, missing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c18f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_traces(p_f, calcium_intensity,df_vol_time, smooth=True, sigma=0.3,delta_y=1.2):\n",
    "    # 平滑和可视化\n",
    "    n_neurons, _ = calcium_intensity.shape\n",
    "    print(f'shape of calcium_traces {calcium_intensity.shape}')\n",
    "    t_max = df_vol_time['Vol_Time'].max()\n",
    "    fig, ax = plt.subplots(figsize=(t_max/100, n_neurons/4))\n",
    "\n",
    "    if 'mask' in df_vol_time.columns:\n",
    "        mask = df_vol_time['mask'].values\n",
    "        time = df_vol_time['Vol_Time'].values\n",
    "        in_mask = False\n",
    "        start = None\n",
    "        for i in range(len(mask)):\n",
    "            if mask[i] == 1 and not in_mask:\n",
    "                in_mask = True\n",
    "                start = time[i]\n",
    "            elif (mask[i] == 0 or i == len(mask)-1) and in_mask:\n",
    "                in_mask = False\n",
    "                end = time[i] if mask[i] == 0 else time[-1]\n",
    "                ax.axvspan(start, end, color='pink', alpha=0.2)\n",
    "\n",
    "    for i in range(n_neurons):\n",
    "        trace = calcium_intensity[i, :]\n",
    "        if smooth:\n",
    "            trace = gaussian_filter1d(trace, sigma=sigma)\n",
    "        plt.plot(df_vol_time['Vol_Time'], trace + i * delta_y,lw=0.5, label=f\"Neuron {i}\")\n",
    "\n",
    "    # 设置坐标轴\n",
    "    plt.xlabel(\"Time (frames)\")\n",
    "    plt.ylabel(\"Neuron index\")\n",
    "    desired_ticks = np.arange(0, df_vol_time['Vol_Time'].max(), 30) # 生成一个数组 [10, 30, 50, 70, 90]\n",
    "    plt.xticks(desired_ticks, rotation=30)\n",
    "    y_positions = np.arange(0, n_neurons * delta_y, delta_y)\n",
    "    plt.yticks(y_positions[:n_neurons], np.arange(n_neurons))\n",
    "    plt.title(f\"Calcium Traces (Gaussian smoothed){sigma}\")\n",
    "    plt.grid(True, linestyle='--', color='grey', linewidth=0.35, alpha=0.5)\n",
    "    plt.savefig(p_f+f'\\\\Cal_traces_Gaussion{sigma}.png', bbox_inches='tight')\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd5f3a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_choose_frame(data, data_keys, data_iou):\n",
    "    # 步骤零点五：根据骨架处理结果筛选符合条件的帧\n",
    "    circle = np.array(list({key: value['circular'] for key, value in data.items()}.values())) \n",
    "    branching = np.array(list({key: value['branching'] for key, value in data.items()}.values())) \n",
    "    choose = np.array(list({key: value['choose_frame'] for key, value in data.items()}.values())) \n",
    "    circular_frames = np.array(data_keys)[circle == 1]\n",
    "    branching_frames = np.array(data_keys)[branching == 1]\n",
    "    merged = list(heapq.merge(circular_frames, branching_frames))\n",
    "    choose_frame = np.array(data_keys)[choose == 1]\n",
    "    # 识别面积抖动区间\n",
    "    # iou = np.load(os.path.join(folder_path,'iou_results.npz'))['iou']\n",
    "    iou = data_iou[data_iou.files[0]] \n",
    "    ano_f = np.vstack([[1, 1], iou]) < 0.7\n",
    "    pre_f= np.where(ano_f[:,0] == True)[0]\n",
    "    post_f= np.where(ano_f[:,1] == True)[0]\n",
    "    ano_merged = list(heapq.merge(pre_f, post_f))\n",
    "    # 排除IOU异常帧\n",
    "    choose_frame = np.setdiff1d(choose_frame, ano_merged)\n",
    "    return choose_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f96fcd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_laser_on_and_off(s_data):\n",
    "    # 提取每个激光照射起始和终止时刻\n",
    "    s_start = s_data[s_data[1] == 2].index\n",
    "    s_stop = s_data[s_data[1] == 3].index\n",
    "    if s_stop.empty:\n",
    "        s_s = [len(s_data[1])]\n",
    "    else:\n",
    "        s_s = []\n",
    "        for m in s_start:\n",
    "            # 如果有多个照射片段，分别找到结束的时间装入s_s\n",
    "            data_1 = (s_stop >= m)\n",
    "            s_s.append(s_stop[data_1 == 1][0])\n",
    "\n",
    "    i=0  # 不考虑其它段，只考虑第一段\n",
    "    #         t_l = int(round((s_data[0][s_start[i] + 1 : s_s[i] - 1]).diff().sum(skipna=True) / (s_s[i] - s_start[i] - 2)))\n",
    "    t_l = (s_data[0][s_start[i] + 1 : s_s[i] - 1]).diff().sum(skipna=True) / (s_s[i] - s_start[i] - 2)\n",
    "    print('时间间隔t_l',t_l)\n",
    "    t = s_data[0].values\n",
    "    # 取从激光照射开始前2帧到激光照射结束的数据\n",
    "    t_frame = np.concatenate([[t[s_start[i]] - t_l *2, t[s_start[i]] - t_l], t[s_start[i]:s_s[i]]])\n",
    "    t_start = s_data[0][s_start[i]] - t_l *2\n",
    "    t_stop = s_data[0][s_s[i] - 1] + t_l\n",
    "    return t_frame, t_start, t_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90327a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对齐时间\n",
    "def get_nearest_value(df1, df2, col_1 = 'Time', col_2 = 'Vol_Time', ind_col = 'Nearest_Index', col1_copy = 'Nearest_Time'):\n",
    "    '''\n",
    "    根据df2的col2找最接近的df1中的col1的值生成新列赋值与df2\n",
    "    '''\n",
    "    nearest_times = []\n",
    "    nearest_indices = []\n",
    "    for vol_time in df2[col_2]:\n",
    "        # 计算时间差的绝对值\n",
    "        differences = np.abs(df1[col_1] - vol_time)\n",
    "        # 找到最小差值的索引\n",
    "        nearest_idx = np.argmin(differences)\n",
    "        # 保存最近时间值和索引\n",
    "        nearest_times.append(df1.iloc[nearest_idx, df1.columns.get_loc(col_1)])\n",
    "        nearest_indices.append(nearest_idx)\n",
    "\n",
    "    # 将结果存入 DataFrame\n",
    "    df2[col1_copy] = nearest_times\n",
    "    df2[ind_col] = nearest_indices\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "709408b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_mot_matched_vol_t(df_mat_cut,p_f, df_vol, ext_name = '', write=True):\n",
    "    '''\n",
    "    荧光对时: 根据df_vol_time中'Time'提取df_mat_cut中的数据列并写出\n",
    "    '''\n",
    "    folder_name = os.path.basename(os.path.normpath(p_f))\n",
    "    df_vol = get_nearest_value(df_mat_cut, df_vol, col_1 = 'Time', col_2 = 'Vol_Time', ind_col = 'Nearest_Index', col1_copy = 'Nearest_Time')\n",
    "    # 将df_motionz中的运动参数(有中线加上中线)按照索引对应到视频帧文件的时间戳上\n",
    "    columns_to_add = df_mat_cut.columns\n",
    "    for col in columns_to_add:\n",
    "        df_vol[col] = df_mat_cut.iloc[df_vol['Nearest_Index'].values][col].values\n",
    "        fn_motion_output = folder_name+ext_name\n",
    "    if write:\n",
    "        df_vol.to_csv(os.path.join(p_f, fn_motion_output), index = False)\n",
    "    print(f'写出与神经数据时间戳对应的运动/中线参数文件到:{fn_motion_output}')\n",
    "    return df_vol\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44b403b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加入condition\n",
    "def add_condition_info(folder_name, df_matched):\n",
    "    features = folder_name.split('_')\n",
    "    if len(features) <3:\n",
    "        print('文件名异常，未检测到Condition信息')\n",
    "    else:\n",
    "        # 如果Condition信息存在，在df_vol_time中加入condition信息\n",
    "        df_matched['Date'] = features[0]\n",
    "        df_matched['Rep_id'] = features[-1]\n",
    "        condition_ls = features[-2].split('-')\n",
    "        print(f'日期:{features[0]}, 编号：{features[-1]}\\n Conditions:{condition_ls}')\n",
    "        for i, c in enumerate(condition_ls):\n",
    "            if len(condition_ls) > 1:\n",
    "                con_col = 'Condition'+str(i)\n",
    "                df_matched[con_col] = c\n",
    "            else:\n",
    "                df_matched['Condition'] = features[-2]\n",
    "        if len(condition_ls) > 1:\n",
    "            df_matched['Date_Con_Rep'] = features[-2]\n",
    "    return df_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96e5958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTX检查\n",
    "def check_ctx(p_f, df):\n",
    "    df_test = df[['Time','X','Y','CTX_left']].copy()\n",
    "    fig, ax = plt.subplots(1,2, figsize = (8,3))\n",
    "    s1 = ax[0].scatter(df_test['X'], df_test['Y'], s = 1, c=df_test['CTX_left'], cmap='bwr')\n",
    "    ax[0].set_aspect('equal')\n",
    "    plt.colorbar(s1, label='ctx_left')\n",
    "    s2 = ax[1].scatter(df_test['X'], df_test['Y'], s = 1, c=df_test['Time'], cmap='Greens')\n",
    "    ax[1].set_aspect('equal')\n",
    "    plt.colorbar(s2, label='Time')\n",
    "    output_path = p_f+'\\\\ctx_check.png'  # 替换为你的目标文件夹路径\n",
    "    plt.savefig(output_path, bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "def check_reversal_turn(p_f, df):\n",
    "    # Reversal turn检查\n",
    "    df_test = df[['Time','X','Y','forward', 'forward_subs_turn','turn_pc','turn_cor']].copy()\n",
    "    fig, ax = plt.subplots(1,3, figsize = (12,5))\n",
    "    ax[0].scatter(df_test['X'], df_test['Y'], s = 1, color='grey')\n",
    "    ax[0].scatter(df_test.loc[df_test['forward_subs_turn']==1,'X'], df_test.loc[df_test['forward_subs_turn']==1,'Y'], s = 1, color='blue')\n",
    "    ax[0].scatter(df_test.loc[df_test['turn_cor']==1,'X'], df_test.loc[df_test['turn_cor']==1,'Y'], s = 1, color='#FFC832')\n",
    "    ax[0].set_title('forward_turn_correction')\n",
    "    ax[0].set_aspect('equal')\n",
    "\n",
    "    ax[1].scatter(df_test['X'], df_test['Y'], s = 1, color='grey')\n",
    "    ax[1].scatter(df_test.loc[df_test['forward_subs_turn']==1,'X'], df_test.loc[df_test['forward_subs_turn']==1,'Y'], s = 1, color='blue')\n",
    "    ax[1].scatter(df_test.loc[df_test['turn_pc']==1,'X'], df_test.loc[df_test['turn_pc']==1,'Y'], s = 1, color='#FFC832')\n",
    "    ax[1].set_title('forward_turn')\n",
    "    ax[1].set_aspect('equal')\n",
    "\n",
    "    ax[2].scatter(df_test['X'], df_test['Y'], s = 1, color='grey')\n",
    "    ax[2].scatter(df_test.loc[df_test['forward']==1,'X'], df_test.loc[df_test['forward']==1,'Y'], s = 1, color='blue')\n",
    "    ax[2].set_title('original forward-reversal')\n",
    "    ax[2].set_aspect('equal')\n",
    "    output_path = p_f+'\\\\reversal-turn_check.png'  # 替换为你的目标文件夹路径\n",
    "    plt.savefig(output_path, bbox_inches='tight', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2deaac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_df_on_laser_t(df,p_f, basename, t_start, t_stop, ext_name):\n",
    "    '''输出df_cut保存csv文件并返回这个df'''\n",
    "    track_start_index = np.searchsorted(df.Time.values, t_start) - 1   # 截取激光照射段的载物台数据时间戳\n",
    "    track_end_index = np.searchsorted(df.Time.values, t_stop)\n",
    "    df_cut = df.loc[track_start_index:track_end_index, :]\n",
    "    df_cut.to_csv(os.path.join(p_f, basename+ext_name), index = False)\n",
    "    return df_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41c7d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_check(p_f,df, new_data):\n",
    "    '''\n",
    "    利用视频检查df_merged_2对运动的分割\n",
    "    保存到原文件夹\n",
    "    '''\n",
    "    # 读取视频\n",
    "    if new_data:\n",
    "        cap = cv2.VideoCapture(os.path.join(p_f, \"c1_onnx.mp4\"))\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(os.path.join(p_f, \"c1_new_onnx.mp4\"))\n",
    "    # cap = cv2.VideoCapture(os.path.join(folder_path, \"c1_onnx.mp4\"))\n",
    "    # 或者从文件夹中读取，行数与视频帧数相同\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"视频总帧数{total_frames}是否等于df行数:\", total_frames==len(df))\n",
    "\n",
    "    # 写出视频\n",
    "    # 获取视频参数\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # 输出文件路径\n",
    "    save_path = os.path.join(p_f, \"skel_turn_check.mp4\")\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # 保存为 mp4\n",
    "    out = cv2.VideoWriter(save_path, fourcc, fps, (width, height))\n",
    "\n",
    "    # 计算头部朝向时的切割像素长度\n",
    "    body_l = 200\n",
    "    delay = 20\n",
    "    step = 5\n",
    "    start_frame = 20000\n",
    "    # 结束帧\n",
    "    frame_idx_end = total_frames\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "    error_ls = []\n",
    "\n",
    "    for frame_idx in range(start_frame, total_frames, step):\n",
    "        # 视频定位当前帧\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)  # 定位到 frame_idx\n",
    "        ret, frame = cap.read()\n",
    "        if frame is None:\n",
    "            continue\n",
    "        if not ret:\n",
    "            break\n",
    "        # 显示帧索引\n",
    "        cv2.putText(frame, f\"Frame: {frame_idx}\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        # 画出向量\n",
    "        # color_vector_h = (128, 0, 128)  # 紫色\n",
    "        color_vector_m = (0, 165, 255)    # 明黄色\n",
    "        # color_vector_mh= (216, 191, 216) # 淡紫色\n",
    "        \n",
    "        row = df.iloc[frame_idx]\n",
    "        # 时间\n",
    "        time_i = row.Time\n",
    "        cv2.putText(frame, f\"Time:{time_i}s\", (10, 50), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        # 读取咽喉点坐标\n",
    "        angle_md = round(row.angle_md,2)\n",
    "        cv2.putText(frame, f\"angle_md:{angle_md}\", (250, 30), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        \n",
    "        # 骨架\n",
    "        sel_path = row.sel_paths\n",
    "    \n",
    "        # 校正turn\n",
    "        if row.turn_cor == 1:\n",
    "            cv2.putText(frame, f\"turn_cor\", (250, 50), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 0, 255), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, f\"turn_cor\", (250, 50), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.75, (200, 200, 200), 2)\n",
    "        # 后退\n",
    "        if row.forward == 1:\n",
    "            cv2.putText(frame, f\"reversal\", (250, 70), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 0, 0), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, f\"forward\", (250, 70), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.75, (200, 200, 200), 2)\n",
    "        if row.turn_pc == 1:\n",
    "            color_bb = (0,0,255)\n",
    "        else:\n",
    "            color_bb = color_vector_m\n",
    "        if isinstance(sel_path, np.ndarray):\n",
    "            points_raw = sel_path\n",
    "            midline_points = normalize_points(points_raw)  # 返回 (N,2) int32\n",
    "            j = 0\n",
    "            for (x, y) in midline_points:\n",
    "                # 打印第一帧\n",
    "                if j == 0:\n",
    "                    cv2.circle(frame, (y,x), 10, (255,0,255), thickness=-1)\n",
    "                cv2.circle(frame, (y,x), 3, color_bb, -1)\n",
    "                j += 1\n",
    "        else:\n",
    "            print('不存在骨架:frame',frame_idx)\n",
    "            continue\n",
    "            \n",
    "        # cv2.imshow(\"Skeleton Check\", frame)\n",
    "        key = cv2.waitKey(delay) & 0xFF   # 播放速度 (30ms/帧)，也可以改大\n",
    "        if key == ord('q'):   # 按 q 退出\n",
    "            break\n",
    "        elif key == ord(' '): # 按空格暂停\n",
    "            cv2.waitKey(0)\n",
    "        # 写入视频文件\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d33c6",
   "metadata": {},
   "source": [
    "### 单文件处理主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7095ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_wbi_processing(p_f, label_corner, new_data, half_width = 20,x_shift  = 0):\n",
    "    ##### 1. 参数定义与数据检查\n",
    "    is_contained, missing_files = is_contained_or_not(p_f, label_corner=label_corner)\n",
    "    if is_contained:\n",
    "        pass\n",
    "    else:\n",
    "        print(f'missing files{missing_files}')\n",
    "    #### 2.钙信号数据处理和检查\n",
    "    # + 需要对时将钙信号帧转为时间信息方便查看异常帧/时间段\n",
    "    # 数据读取(在步骤一已读取可省略)\n",
    "    basename = os.path.basename(os.path.normpath(p_f))\n",
    "    files = [f for f in os.listdir(p_f)]\n",
    "    for f in files:\n",
    "        if ('laser-data' in f)or (\"s-data\" in f):\n",
    "            # 读取激光激活数据\n",
    "            print('读取激光照射时间数据并转为s_data')\n",
    "            try:\n",
    "                s_data = pd.read_csv(p_f + '\\laser-data.txt', header=None)  #读取激光激活数据\n",
    "            except FileNotFoundError:\n",
    "                s_data = pd.read_csv(p_f + '\\s-data.txt', header=None)\n",
    "            # 注意：这里s_data已经转换成秒\n",
    "            s_data.loc[:,0] = s_data.loc[:,0]/1000\n",
    "        elif 'calcium_intensity.npy' in f:\n",
    "                    # 钙信号数据(* 如果有)\n",
    "                    print(f'读取钙信号数据：{p_f+f}')\n",
    "                    Cal_data_path = os.path.join(p_f, f)\n",
    "                    calcium_intensity= np.load(Cal_data_path)\n",
    "\n",
    "    # 根据激光开始和结束时间生成vol_time时间戳\n",
    "    t_frame, _, _ = get_laser_on_and_off(s_data)\n",
    "    df_vol_time = pd.DataFrame(t_frame, columns=['Vol_Time']) \n",
    "\n",
    "    print(calcium_intensity.shape)\n",
    "    print(len(df_vol_time))\n",
    "    visualize_traces(p_f, calcium_intensity,df_vol_time, smooth=True, sigma=0.3,delta_y=1.2 )\n",
    "    \n",
    "    #### 3. 运动参数计算和视频对时\n",
    "    # 数据读取\n",
    "    basename = os.path.basename(os.path.normpath(p_f))\n",
    "    files = [f for f in os.listdir(p_f)]\n",
    "    print(f'\\n\\n=======开始处理{basename}中运动信息====')\n",
    "    for f in files:\n",
    "        if 'stage_data' in f:\n",
    "            # 使用载物台位置信息计算速度角速度\n",
    "            print('读取载物台位置信息文件')\n",
    "            column_names = ['Time','p_X','p_Y', 'X', 'Y']\n",
    "            df_stage = pd.read_csv(os.path.join(p_f, f),sep=r'\\s+', header=None,\n",
    "                                    names=column_names)\n",
    "            columns_to_clean = ['Time', 'p_X', 'p_Y', 'X', 'Y']\n",
    "            for col in columns_to_clean:\n",
    "                df_stage[col] = df_stage[col].astype(str).str.replace(',', '', regex=False).astype(float)\n",
    "\n",
    "            df_motion = df_stage[['Time','X','Y']]/1000  # 转换单位为s和mm\n",
    "            # 转换坐标，统一x轴坐标起点为0，终点为4.5\n",
    "            # 保证p_f中有四个顶点文件\n",
    "            if label_corner:\n",
    "                df_label, df_motion = Realign_coordinate(p_f, df_motion)\n",
    "            else:\n",
    "                df_motion = Realign_coordinate_by_edge(p_f, df_motion)\n",
    "        elif 'c1.txt' in f:\n",
    "            # 读取视频帧文件\n",
    "            print('读取视频帧时间戳文件并转为f_data')\n",
    "            f_data = np.loadtxt(p_f + '\\c1.txt', delimiter=',') # 读取相机时间戳\n",
    "            if new_data: \n",
    "                # 202502之后的数据是新数据，视频帧率为30-40Hz\n",
    "                t_c = f_data[f_data[:,3] == 1, 1]/1000\n",
    "            else:\n",
    "                # 旧数据视频帧率150Hz 每隔5帧取一帧（适用于老数据）\n",
    "                indices = np.concatenate(([0], np.arange(5, len(f_data), 5)))\n",
    "                t_c = f_data[indices, 1].astype(int)/1000\n",
    "        elif ('laser-data' in f)or (\"s-data\" in f):\n",
    "            # 读取激光激活数据\n",
    "            print('读取激光照射时间数据并转为s_data')\n",
    "            try:\n",
    "                s_data = pd.read_csv(p_f + '\\laser-data.txt', header=None)  #读取激光激活数据\n",
    "            except FileNotFoundError:\n",
    "                s_data = pd.read_csv(p_f + '\\s-data.txt', header=None)\n",
    "            # 注意：这里s_data已经转换成秒\n",
    "            s_data.loc[:,0] = s_data.loc[:,0]/1000\n",
    "    # 步骤一：根据载物台运动位置信息抽取运动参数\n",
    "    mean_frame_rate = np.median(1/np.diff(df_motion.Time.values))\n",
    "    print(np.argmin(np.diff(df_motion.Time.values)))\n",
    "    df_motion_als = Smooth_velocity_calation(df_motion, 0.5, window_size=100, frame_rate=mean_frame_rate,X_shift=x_shift)\n",
    "\n",
    "\n",
    "    # 步骤二： 提取视频帧（根据中线处理结果只保留可用帧）对应的运动参数，输出对齐视频可用帧时间后的运动参数文件\n",
    "    df_motion_pt_sorted = df_motion_als.sort_values('Time')  # 确保 df_motion_pt 也是按时间升序\n",
    "    df_t = pd.DataFrame({'Time': t_c})\n",
    "    df_t = df_t.sort_values('Time')  # merge_asof 要求升序\n",
    "    df_motion_pt_sorted = df_motion_pt_sorted.rename(columns={'Time': 'Stage_time'})\n",
    "    # 使用 merge_asof 匹配最近的时间点\n",
    "    df_matched = pd.merge_asof(\n",
    "        df_t,\n",
    "        \n",
    "        df_motion_pt_sorted,\n",
    "        left_on='Time',\n",
    "        right_on='Stage_time',\n",
    "        direction='nearest'  # 可选：'backward', 'forward', or 'nearest'\n",
    "    )\n",
    "\n",
    "    # 步骤三：加入condition\n",
    "    folder_name = os.path.basename(os.path.normpath(p_f))\n",
    "    df_matched = add_condition_info(folder_name, df_matched)\n",
    "    # 重置中线位置\n",
    "    df_matched['Disp_to_mid'] = df_matched['X']-half_width\n",
    "    # 保存合并运动参数和视频帧对应时间戳的df数据\n",
    "    df_matched.to_csv(os.path.join(p_f,basename+ '_mot_vid.csv'), index=False)\n",
    "    '''文件长度与视频帧数相同'''\n",
    "\n",
    "    #### 2. 中线数据处理和输出\n",
    "    # 数据读取（中线）\n",
    "    basename = os.path.basename(os.path.normpath(p_f))\n",
    "    files = [f for f in os.listdir(p_f)]\n",
    "    print(f'\\n\\n=======开始处理中线信息文件====')\n",
    "    for f in files:\n",
    "        if 'output-0516' in f:\n",
    "            # 中线npz数据(* 如果有)\n",
    "            print(f'读取中线文件：{f}')\n",
    "            midline_path = os.path.join(p_f,f)\n",
    "            npz_data = np.load(midline_path, allow_pickle=True)\n",
    "            data = npz_data['arr_0'].item()\n",
    "            # paths= {key: value['all_paths'] for key, value in data.items()}\n",
    "            data_keys = list(data.keys())   # 存储的符合条件的帧数\n",
    "            midline_extract = True   # 是否包含抽取中线后的文件\n",
    "        elif 'iou_results' in f:\n",
    "            print(f'读取中线处理相关文件{f}')\n",
    "            data_iou = np.load(os.path.join(p_f,'iou_results.npz'))\n",
    "    '''与视频帧数相同的完成对时的运动数据df_matched'''\n",
    "    # 这一步可以直接接上一步，或者从文件夹读取'_mot_vid.csv'\n",
    "    df_matched = df_matched\n",
    "\n",
    "    # 提取可靠帧\n",
    "    choose_frame = get_choose_frame(data, data_keys, data_iou)\n",
    "    df_choose = pd.DataFrame(choose_frame, columns=['key'])\n",
    "    df_choose.loc[:,'choose_frame'] = int(1)\n",
    "    df_choose = df_choose.set_index('key')\n",
    "\n",
    "    # 提取所需中线信息\n",
    "    rows = []\n",
    "    for key in data_keys:\n",
    "        item = data[key]\n",
    "        row = {\n",
    "            'key': key,   # 对应视频帧\n",
    "            'angle_m': item['angle_m'],  # 头部朝向与运动方向夹角绝对值\n",
    "            'angle_md': item['angle_md'],  # 头部朝向与运动方向夹角\n",
    "            'all_paths':item['all_paths'],  # 完整的骨架信息\n",
    "            'closest_idx':item['closest path'], # 最近的骨架id\n",
    "        }\n",
    "        rows.append(row)\n",
    "    df_summary = pd.DataFrame(rows).set_index('key')\n",
    "\n",
    "\n",
    "    # 保留中线数据\n",
    "    # 保存筛选帧信息：哪些中线的置信度高于阈值\n",
    "    df_merged = df_matched.join(df_summary, how='left')\n",
    "    df_merged = df_merged.join(df_choose, how='left')   # 根据index合并，df_choose里没有的填none\n",
    "\n",
    "    # 中线处理，计算turn\n",
    "    # 输出包含‘Time’作为唯一重合列\n",
    "    df_turn_curv = get_omega_turn_curvature(p_f, df_merged, midline_path, path_ratio_uplim = 1.5, path_uplim=200, dtheta_lim=220,\n",
    "                                cl_turn_size = 50, op_turn_size = 50, visualize_turn=True,\n",
    "                                seg_pixel_step = 13, agl_window = 300, frame_rate=38)\n",
    "\n",
    "    # 根据处理结果计算ctx\n",
    "    df_turn_curv[\"head_moving\"] = df_turn_curv[\"head_moving\"].apply(\n",
    "    lambda x: np.array([np.nan, np.nan]) if x is None else x\n",
    "    )\n",
    "    df_ctx = cal_bearing_ctx(df_turn_curv, grad_vec=[-1,0])\n",
    "    # df_merged_2 = df_merged.join(df_turn_curv, how='left')\n",
    "    df_merged_2 = pd.merge(df_merged, df_ctx, on='Time', how='left')\n",
    "    df_merged_2.to_csv(os.path.join(p_f,basename+ '_mot_vid_mid.csv'), index=False)\n",
    "    '''文件仍然与视频长度相同，包含所有中线处理信息以及筛选帧信息'''\n",
    "    '''写出df_matched: 运动参数;df_merged_2:包含运动参数和所有中线相关信息'''\n",
    "    # 检查结果并输出图片\n",
    "    check_reversal_turn(p_f, df_merged_2)\n",
    "    check_ctx(p_f, df_merged_2)\n",
    "    # 视频检查\n",
    "    video_check(p_f,df_merged_2, new_data)\n",
    "    #### 4. 中线和运动数据裁剪以及与荧光对时\n",
    "    # 数据读取(在步骤一已读取可省略)\n",
    "    basename = os.path.basename(os.path.normpath(p_f))\n",
    "    files = [f for f in os.listdir(p_f)]\n",
    "    for f in files:\n",
    "        if ('laser-data' in f)or (\"s-data\" in f):\n",
    "            # 读取激光激活数据\n",
    "            print('读取激光照射时间数据并转为s_data')\n",
    "            try:\n",
    "                s_data = pd.read_csv(p_f + '\\laser-data.txt', header=None)  #读取激光激活数据\n",
    "            except FileNotFoundError:\n",
    "                s_data = pd.read_csv(p_f + '\\s-data.txt', header=None)\n",
    "            # 注意：这里s_data已经转换成秒\n",
    "            s_data.loc[:,0] = s_data.loc[:,0]/1000\n",
    "\n",
    "    # 步骤五：根据激光开始和结束时间截取荧光拍摄部分的运动数据/时间戳\n",
    "    t_frame, t_start, t_stop = get_laser_on_and_off(s_data)\n",
    "    df_matched_cut = cut_df_on_laser_t(df_matched,p_f, basename, t_start, t_stop, ext_name='_mot_vid_cut.csv')\n",
    "    df_mot_midline_cut = cut_df_on_laser_t(df_merged_2,p_f, basename, t_start, t_stop, ext_name='_mot_midline_cut.csv')\n",
    "    # 步骤六：根据荧光数据时间戳提取对应的运动参数，便于后续合并荧光数据\n",
    "    df_vol_time = pd.DataFrame(t_frame, columns=['Vol_Time'])   # 激光照射时间戳要转换单位为s\n",
    "    df_vol_time.to_csv(os.path.join(p_f, folder_name+'_VotTime.csv'), index = False)\n",
    "    # 有中线, 如果需要mask，write = False\n",
    "    df_mot_mid_vol = get_df_mot_matched_vol_t(df_mot_midline_cut,p_f, df_vol_time.copy(),\n",
    "                                           ext_name = '_MotionMidlineMatchVol.csv', write=True)\n",
    "    print(f'========{p_f}处理完成>.<===============')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1ab12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_f = r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\done\\\\20250221_0g-ov-27.5d_6'\n",
    "single_wbi_processing(p_f, label_corner=True, new_data=True, half_width = 20,x_shift  = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1590fa29",
   "metadata": {},
   "source": [
    "### 多文件处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cd8167",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_all = r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\to_do'\n",
    "key_word = ''\n",
    "nokey_word = '*'\n",
    "file_paths = [os.path.join(file_path_all,f_p) for f_p in os.listdir(file_path_all) if ('trash' not in f_p)&\n",
    "              ('done' not in f_p)&\n",
    "             os.path.isdir(os.path.join(file_path_all,f_p))&\n",
    "             (key_word in f_p)&(nokey_word not in f_p)]\n",
    "\n",
    "print('\\n'.join(file_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb6dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p_f in enumerate(file_paths):\n",
    "    basename = os.path.basename(p_f)\n",
    "    date_str = basename.split('_')[0]\n",
    "    new_data_date = datetime.strptime(\"20250201\", \"%Y%m%d\") \n",
    "    date_end = datetime.strptime(\"20250804\", \"%Y%m%d\")\n",
    "    # 将日期字符串转换为datetime对象\n",
    "    date = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "    # distinguish new data\n",
    "    \n",
    "    if date > new_data_date:\n",
    "        new_data = True\n",
    "        label_corner = True\n",
    "    else:\n",
    "        new_data = False\n",
    "        label_corner = False\n",
    "    print(basename, new_data, label_corner)\n",
    "    if date < date_end:\n",
    "        try:\n",
    "            single_wbi_processing(p_f, label_corner, new_data, half_width = 20,x_shift  = 0)\n",
    "        except:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b21339f",
   "metadata": {},
   "source": [
    "### 异常数据mask并打印钙信号检查\n",
    "根据可能的追踪异常情况，将4中得到的荧光对时文件打mask，提示异常帧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f369e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_f = r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\to_do\\\\20250723_lg9624-5gNa-002-24d-ov_014'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b3f712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '\\\\20250723_lg9624-5gNa-002-24d-ov_014_MotionMidlineMatchVol.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59828ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = pd.read_pickle(p_f+file,).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a034788b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取钙信号数据：Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\done\\\\20250225_0g-ov-24d_004calcium_intensity.npy\n",
      "读取激光照射时间数据并转为s_data\n",
      "时间间隔t_l 0.2998884934756821\n"
     ]
    }
   ],
   "source": [
    "# 求t_frame\n",
    "files = [f for f in os.listdir(p_f)]\n",
    "folder_name = os.path.basename(os.path.normpath(p_f))\n",
    "for f in files:\n",
    "    if ('laser-data' in f)or (\"s-data\" in f):\n",
    "        # 读取激光激活数据\n",
    "        print('读取激光照射时间数据并转为s_data')\n",
    "        try:\n",
    "            s_data = pd.read_csv(p_f + '\\laser-data.txt', header=None)  #读取激光激活数据\n",
    "        except FileNotFoundError:\n",
    "            s_data = pd.read_csv(p_f + '\\s-data.txt', header=None)\n",
    "        # 注意：这里s_data已经转换成秒\n",
    "        s_data.loc[:,0] = s_data.loc[:,0]/1000\n",
    "    elif 'calcium_intensity.npy' in f:\n",
    "                # 钙信号数据(* 如果有)\n",
    "                print(f'读取钙信号数据：{p_f+f}')\n",
    "                Cal_data_path = os.path.join(p_f, f)\n",
    "                calcium_intensity= np.load(Cal_data_path)\n",
    "\n",
    "# 步骤五：根据激光开始和结束时间截取荧光拍摄部分的运动数据/时间戳\n",
    "t_frame, t_start, t_stop = get_laser_on_and_off(s_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7096fda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20250225_0g-ov-24d_004_mot_midline_cut.csv\n"
     ]
    }
   ],
   "source": [
    "# 读入df_mot_midline_cut\n",
    "f_mot_mid_cut = [f for f in os.listdir(p_f) if '_mot_midline_cut' in f][0]\n",
    "print(f_mot_mid_cut)\n",
    "df_mot_midline_cut = pd.read_csv(os.path.join(p_f,f_mot_mid_cut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b1e031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果没有mask\n",
    "df_vol_time = pd.DataFrame(t_frame, columns=['Vol_Time'])   # 激光照射时间戳要转换单位为s\n",
    "df_vol_time.to_csv(os.path.join(p_f, folder_name+'_VotTime.csv'), index = False)\n",
    "# 有中线, 如果需要mask，write = False\n",
    "df_mot_mid_vol = get_df_mot_matched_vol_t(df_mot_midline_cut,p_f, df_vol_time.copy(),\n",
    "                                           ext_name = '_MotionMidlineMatchVol.csv', write=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49985cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果需要mask\n",
    "df_vol_time = pd.DataFrame(t_frame, columns=['Vol_Time'])   # 激光照射时间戳要转换单位为s\n",
    "df_vol_time.loc[:,'mask'] = 0 \n",
    "df_vol_time.loc[df_vol_time['Vol_Time']<= 972,'mask'] = 1\n",
    "df_vol_time.to_csv(os.path.join(p_f, folder_name+'_VotTime.csv'), index = False)\n",
    "\n",
    "# 有中线的vol_time对齐文件\n",
    "df_mot_mid_vol.loc[:,'mask'] = 0 \n",
    "df_mot_mid_vol.loc[df_mot_mid_vol['Vol_Time']<= 972,'mask'] = 1\n",
    "df_mot_mid_vol.to_csv(os.path.join(p_f, folder_name+'_MotionMidlineMatchVol.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88033ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(p_f)]\n",
    "for f in files:\n",
    "    if ('laser-data' in f)or (\"s-data\" in f):\n",
    "        # 读取激光激活数据\n",
    "        print('读取激光照射时间数据并转为s_data')\n",
    "        try:\n",
    "            s_data = pd.read_csv(p_f + '\\laser-data.txt', header=None)  #读取激光激活数据\n",
    "        except FileNotFoundError:\n",
    "            s_data = pd.read_csv(p_f + '\\s-data.txt', header=None)\n",
    "        # 注意：这里s_data已经转换成秒\n",
    "        s_data.loc[:,0] = s_data.loc[:,0]/1000\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d374ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mot_mid_vol = pd.read_csv(os.path.join(p_f, folder_name+\"_MotionMidlineMatchVol.csv\"))\n",
    "# 可视化钙信号检查\n",
    "df_vol_mask = pd.read_csv(os.path.join(p_f, folder_name+\"_VotTime.csv\"))\n",
    "# 有mask会自动标记\n",
    "visualize_traces(p_f, calcium_intensity,df_vol_mask, smooth=True, sigma=0.3,delta_y=1.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd8b344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06832367",
   "metadata": {},
   "source": [
    "### 单文件处理函数（旧）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc476d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_f = r'Y:\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\new_midline_done\\\\20250221_0g-ov-27.5d_6'\n",
    "def single_wbi_data_analysis(p_f, label_corner = True, new_data = True, half_width = 20, x_shift  = 0,\n",
    "                              hlf_spd_inv = 0.5, hlf_agl_spd_inv = 0.2, hlf_agl_inv = 1,\n",
    "                                Pos_CTX_vec = [-1,0]):\n",
    "    \n",
    "    # 检查文件\n",
    "    is_contained, missing_files = is_contained_or_not(p_f, label_corner=label_corner)\n",
    "    if is_contained:\n",
    "        pass\n",
    "    else:\n",
    "        print(f'missing files{missing_files}')\n",
    "        return None\n",
    "\n",
    "    # 数据读取\n",
    "    basename = os.path.basename(os.path.normpath(p_f))\n",
    "    files = [f for f in os.listdir(p_f)]\n",
    "    print(f'\\n\\n=======开始处理{basename}中文件，\\n包含:{files}')\n",
    "    for f in files:\n",
    "        if 'stage_data' in f:\n",
    "            # 使用载物台位置信息计算速度角速度\n",
    "            print('读取载物台位置信息文件')\n",
    "            column_names = ['Time','p_X','p_Y', 'X', 'Y']\n",
    "            df_stage = pd.read_csv(os.path.join(p_f, f),sep=r'\\s+', header=None,\n",
    "                                    names=column_names)\n",
    "            columns_to_clean = ['Time', 'p_X', 'p_Y', 'X', 'Y']\n",
    "            for col in columns_to_clean:\n",
    "                df_stage[col] = df_stage[col].astype(str).str.replace(',', '', regex=False).astype(float)\n",
    "\n",
    "            df_motion = df_stage[['Time','X','Y']]/1000  # 转换单位为s和mm\n",
    "            # 转换坐标，统一x轴坐标起点为0，终点为4.5\n",
    "            # 保证p_f中有四个顶点文件\n",
    "            if label_corner:\n",
    "                df_label, df_motion = Realign_coordinate(p_f, df_motion)\n",
    "            else:\n",
    "                df_motion = Realign_coordinate_by_edge(p_f, df_motion)\n",
    "        elif 'c1.txt' in f:\n",
    "            # 读取视频帧文件\n",
    "            print('读取视频帧时间戳文件并转为f_data')\n",
    "            f_data = np.loadtxt(p_f + '\\c1.txt', delimiter=',') # 读取相机时间戳\n",
    "            if new_data: \n",
    "                # 202502之后的数据是新数据，视频帧率为30-40Hz\n",
    "                t_c = f_data[f_data[:,3] == 1, 1]/1000\n",
    "            else:\n",
    "                # 旧数据视频帧率150Hz 每隔5帧取一帧（适用于老数据）\n",
    "                indices = np.concatenate(([0], np.arange(5, len(f_data), 5)))\n",
    "                t_c = f_data[indices, 1].astype(int)/1000\n",
    "        elif ('laser-data' in f)or (\"s-data\" in f): \n",
    "            # 读取激光激活数据\n",
    "            print('读取激光照射时间数据并转为s_data')\n",
    "            try:\n",
    "                s_data = pd.read_csv(p_f + '\\laser-data.txt', header=None)  #读取激光激活数据\n",
    "            except FileNotFoundError:\n",
    "                s_data = pd.read_csv(p_f + '\\s-data.txt', header=None)\n",
    "            # 注意：这里s_data已经转换成秒\n",
    "            s_data.loc[:,0] = s_data.loc[:,0]/1000\n",
    "        elif 'output-0516' in f:\n",
    "            # 中线npz数据(* 如果有)\n",
    "            print(f'读取中线文件：{f}')\n",
    "            midline_path = os.path.join(p_f,f)\n",
    "            npz_data = np.load(midline_path, allow_pickle=True)\n",
    "            data = npz_data['arr_0'].item()\n",
    "            # paths= {key: value['all_paths'] for key, value in data.items()}\n",
    "            data_keys = list(data.keys())   # 存储的符合条件的帧数\n",
    "            midline_extract = True   # 是否包含抽取中线后的文件\n",
    "        elif 'iou_results' in f:\n",
    "            print(f'读取中线处理相关文件{f}')\n",
    "            data_iou = np.load(os.path.join(p_f,'iou_results.npz'))\n",
    "        \n",
    "            \n",
    "    # 步骤一：根据载物台运动位置信息抽取运动参数\n",
    "    mean_frame_rate = np.median(1/np.diff(df_motion.Time.values))\n",
    "    print(np.argmin(np.diff(df_motion.Time.values)))\n",
    "    df_motion_als = Sliding_CTX_calation(df_motion, Pos_CTX_vec, hlf_spd_inv, hlf_agl_spd_inv, hlf_agl_inv,\n",
    "                                        window_size=100, frame_rate=mean_frame_rate,X_shift=x_shift)\n",
    "\n",
    "\n",
    "    # 步骤二： 提取视频帧（根据中线处理结果只保留可用帧）对应的运动参数，输出对齐视频可用帧时间后的运动参数文件\n",
    "    df_motion_pt_sorted = df_motion_als.sort_values('Time')  # 确保 df_motion_pt 也是按时间升序\n",
    "    df_t = pd.DataFrame({'Time': t_c})\n",
    "    df_t = df_t.sort_values('Time')  # merge_asof 要求升序\n",
    "    df_motion_pt_sorted = df_motion_pt_sorted.rename(columns={'Time': 'Stage_time'})\n",
    "    # 使用 merge_asof 匹配最近的时间点\n",
    "    df_matched = pd.merge_asof(\n",
    "        df_t,\n",
    "        df_motion_pt_sorted,\n",
    "        left_on='Time',\n",
    "        right_on='Stage_time',\n",
    "        direction='nearest'  # 可选：'backward', 'forward', or 'nearest'\n",
    "    )\n",
    "\n",
    "    # 步骤三：加入condition\n",
    "    folder_name = os.path.basename(os.path.normpath(p_f))\n",
    "    df_matched = add_condition_info(folder_name, df_matched)\n",
    "    # 重置中线位置\n",
    "    df_matched['Disp_to_mid'] = df_matched['X']-half_width\n",
    "    # 保存合并运动参数和视频帧对应时间戳的df数据\n",
    "    df_matched.to_csv(os.path.join(p_f,basename+ '_mot_vid.csv'), index=False)\n",
    "    '''文件长度与视频帧数相同'''\n",
    "\n",
    "    # 步骤四:合并中线数据\n",
    "    if midline_extract:\n",
    "\n",
    "        # 整理choose帧\n",
    "        choose_frame = get_choose_frame(data, data_keys, data_iou)\n",
    "        df_choose = pd.DataFrame(choose_frame, columns=['key'])\n",
    "        df_choose.loc[:,'choose_frame'] = int(1)\n",
    "        df_choose = df_choose.set_index('key')\n",
    "\n",
    "        rows = []\n",
    "        for key in data_keys:\n",
    "            item = data[key]\n",
    "            row = {\n",
    "                'key': key,   # 对应视频帧\n",
    "                'angle_m': item['angle_m'],  # 头部朝向与运动方向夹角绝对值\n",
    "                'angle_md': item['angle_md'],  # 头部朝向与运动方向夹角\n",
    "                'all_paths':item['all_paths'],  # 完整的骨架信息\n",
    "                'closest_idx':item['closest path'], # 最近的骨架id\n",
    "            }\n",
    "            rows.append(row)\n",
    "        # 构建 DataFrame\n",
    "        df_summary = pd.DataFrame(rows).set_index('key')\n",
    "        # 保留所有的处理后的帧信息\n",
    "        df_merged = df_matched.join(df_summary, how='left')\n",
    "\n",
    "        # 保存筛选帧信息：哪些中线的置信度高于阈值\n",
    "        df_merged = df_merged.join(df_choose, how='left')   # 根据index合并，df_choose里没有的填none\n",
    "\n",
    "        # 中线处理，计算turn\n",
    "        df_turn_curv = get_omega_turn_curvature(p_f, \n",
    "                                                midline_path, path_ratio_uplim = 1.5, path_uplim=200, dtheta_lim=220,\n",
    "                                cl_turn_size = 50, op_turn_size = 50, visualize_turn=True,\n",
    "                                seg_pixel_step = 13, agl_window = 300, frame_rate=38)\n",
    "        df_merged_2 = df_merged.join(df_turn_curv, how='left')\n",
    "\n",
    "        df_merged_2.to_csv(os.path.join(p_f,basename+ '_mot_vid_mid.csv'), index=False)\n",
    "        '''文件仍然与视频长度相同，包含所有中线处理信息以及筛选帧信息'''\n",
    "\n",
    "    # 步骤五：根据激光开始和结束时间截取荧光拍摄部分的运动数据/时间戳\n",
    "    t_frame, t_start, t_stop = get_laser_on_and_off(s_data)\n",
    "    track_start_index = np.searchsorted(df_matched.Time.values, t_start) - 1   # 截取激光照射段的载物台数据时间戳\n",
    "    track_end_index = np.searchsorted(df_matched.Time.values, t_stop)\n",
    "    df_matched_cut = df_matched.loc[track_start_index:track_end_index, :]\n",
    "    df_vol_time = pd.DataFrame(t_frame, columns=['Vol_Time'])   # 激光照射时间戳要转换单位为s\n",
    "    stage_file = os.path.join(p_f, f's{0+1}.txt')\n",
    "    vol_file = os.path.join(p_f, f't{0+1}.txt')\n",
    "    np.savetxt(stage_file, df_matched_cut[['Time','X_org','Y_org']], fmt='%.4f')  # 存储载物台数据(时间戳是视频帧的)\n",
    "    np.savetxt(vol_file, t_frame, fmt='%.4f')  # 存储荧光每一个volume的数据\n",
    "    df_matched_cut.to_csv(os.path.join(p_f, basename+'_mot_vid_cut.csv'), index = False)\n",
    "    if midline_extract:\n",
    "        df_mot_midline_cut = df_merged_2.loc[track_start_index:track_end_index, :]\n",
    "        df_mot_midline_cut.to_csv(os.path.join(p_f, basename+'_mot_midline_cut.csv'), index = False)\n",
    "\n",
    "    # 步骤六：根据荧光数据时间戳提取对应的运动参数，便于后续合并荧光数据\n",
    "    # 如果有中线数据，就用带中线数据的对齐。否则只用运动参数对齐\n",
    "    if midline_extract:\n",
    "        df_mat_cut = df_mot_midline_cut.copy()\n",
    "        print('有中线数据, 与Volume对齐的运动和中线数据')\n",
    "    else:\n",
    "        df_mat_cut = df_matched_cut.copy()\n",
    "        print('没有中线数据, 输出与Volume时间对齐的运动参数')\n",
    "\n",
    "    df_vol_time = get_nearest_value(df_mat_cut, df_vol_time, col_1 = 'Time', col_2 = 'Vol_Time', ind_col = 'Nearest_Index', col1_copy = 'Nearest_Time')\n",
    "    # 将df_motionz中的运动参数(有中线加上中线)按照索引对应到视频帧文件的时间戳上\n",
    "    columns_to_add = df_mat_cut.columns\n",
    "    for col in columns_to_add:\n",
    "        df_vol_time[col] = df_mat_cut.iloc[df_vol_time['Nearest_Index'].values][col].values\n",
    "    if midline_extract:\n",
    "        fn_motion_output = folder_name+'_MotionMidlineMatchVol.csv'\n",
    "    else:\n",
    "        fn_motion_output = folder_name+'_MotionMatchVol.csv'\n",
    "    df_vol_time.to_csv(os.path.join(p_f, fn_motion_output), index = False)\n",
    "    print(f'写出与神经数据时间戳(不包含钙数据)对应的运动参数文件到:{folder_name}/{fn_motion_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091e99cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数调用\n",
    "file_path_all = r'Y:\\\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\no_binary\\\\new'\n",
    "key_word = ''\n",
    "nokey_word = '*'\n",
    "file_paths = [os.path.join(file_path_all,f_p) for f_p in os.listdir(file_path_all) if ('trash' not in f_p)&\n",
    "              ('done' not in f_p)&\n",
    "             os.path.isdir(os.path.join(file_path_all,f_p))&\n",
    "             (key_word in f_p)&(nokey_word not in f_p)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc6623",
   "metadata": {},
   "source": [
    "#### 单文件处理，旧代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1211c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 单文件处理，旧代码\n",
    "p_f = r'Y:\\SZX\\\\2025_wbi_analysis\\\\good_WBI\\\\new_midline_done\\\\20250221_0g-ov-27.5d_6'\n",
    "label_corner = True\n",
    "new_data = True   # 202502之后的数据是新数据，视频帧率为30-40Hz\n",
    "half_width = 20   # 脂片宽度一半\n",
    "x_shift  = 0 \n",
    "hlf_spd_inv = 0.5\n",
    "hlf_agl_spd_inv = 0.2\n",
    "hlf_agl_inv = 1\n",
    "Pos_CTX_vec = [-1,0]\n",
    "t_crit = 3.8\n",
    "min_agl_spd = 75\n",
    "df_motion = {}\n",
    "df_vol_time = {}\n",
    "calcium = True   # 默认有荧光信号的所有文件都包含钙信号\n",
    "\n",
    "is_contained, missing_files = is_contained_or_not(p_f, label_corner=label_corner)\n",
    "if is_contained:\n",
    "    pass\n",
    "else:\n",
    "    print(f'missing files{missing_files}')\n",
    "\n",
    "\n",
    "# 数据读取\n",
    "basename = os.path.basename(os.path.normpath(p_f))\n",
    "files = [f for f in os.listdir(p_f)]\n",
    "print(f'\\n\\n=======开始处理{basename}中文件，\\n包含:{files}')\n",
    "for f in files:\n",
    "    if 'stage_data' in f:\n",
    "        # 使用载物台位置信息计算速度角速度\n",
    "        print('读取载物台位置信息文件')\n",
    "        column_names = ['Time','p_X','p_Y', 'X', 'Y']\n",
    "        df_stage = pd.read_csv(os.path.join(p_f, f),sep=r'\\s+', header=None,\n",
    "                                names=column_names)\n",
    "        columns_to_clean = ['Time', 'p_X', 'p_Y', 'X', 'Y']\n",
    "        for col in columns_to_clean:\n",
    "            df_stage[col] = df_stage[col].astype(str).str.replace(',', '', regex=False).astype(float)\n",
    "\n",
    "        df_motion = df_stage[['Time','X','Y']]/1000  # 转换单位为s和mm\n",
    "        # 转换坐标，统一x轴坐标起点为0，终点为4.5\n",
    "        # 保证p_f中有四个顶点文件\n",
    "        if label_corner:\n",
    "            df_label, df_motion = Realign_coordinate(p_f, df_motion)\n",
    "        else:\n",
    "            df_motion = Realign_coordinate_by_edge(p_f, df_motion)\n",
    "\n",
    "    elif 'c1.txt' in f:\n",
    "        # 读取视频帧文件\n",
    "        print('读取视频帧时间戳文件并转为f_data')\n",
    "        f_data = np.loadtxt(p_f + '\\c1.txt', delimiter=',') # 读取相机时间戳\n",
    "        if new_data: \n",
    "            # 202502之后的数据是新数据，视频帧率为30-40Hz\n",
    "            t_c = f_data[f_data[:,3] == 1, 1]/1000\n",
    "        else:\n",
    "            # 旧数据视频帧率150Hz 每隔5帧取一帧（适用于老数据）\n",
    "            indices = np.concatenate(([0], np.arange(5, len(f_data), 5)))\n",
    "            t_c = f_data[indices, 1].astype(int)/1000\n",
    "    elif ('laser-data' in f)or (\"s-data\" in f):\n",
    "        # 读取激光激活数据\n",
    "        print('读取激光照射时间数据并转为s_data')\n",
    "        try:\n",
    "            s_data = pd.read_csv(p_f + '\\laser-data.txt', header=None)  #读取激光激活数据\n",
    "        except FileNotFoundError:\n",
    "            s_data = pd.read_csv(p_f + '\\s-data.txt', header=None)\n",
    "        # 注意：这里s_data已经转换成秒\n",
    "        s_data.loc[:,0] = s_data.loc[:,0]/1000\n",
    "    elif 'calcium_intensity.npy' in f:\n",
    "        # 钙信号数据(* 如果有)\n",
    "        print(f'读取钙信号数据：{f}')\n",
    "        Cal_data_path = os.path.join(p_f, f)\n",
    "        calcium_intensity= np.load(Cal_data_path)\n",
    "        Calcium = True    # 包含钙信号数据\n",
    "    elif 'output-0516' in f:\n",
    "        # 中线npz数据(* 如果有)\n",
    "        print(f'读取中线文件：{f}')\n",
    "        midline_path = os.path.join(p_f,f)\n",
    "        npz_data = np.load(midline_path, allow_pickle=True)\n",
    "        data = npz_data['arr_0'].item()\n",
    "        # paths= {key: value['all_paths'] for key, value in data.items()}\n",
    "        data_keys = list(data.keys())   # 存储的符合条件的帧数\n",
    "        midline_extract = True   # 是否包含抽取中线后的文件\n",
    "    elif 'iou_results' in f:\n",
    "        print(f'读取中线处理相关文件{f}')\n",
    "        data_iou = np.load(os.path.join(p_f,'iou_results.npz'))\n",
    "    \n",
    "        \n",
    "# 步骤一：根据载物台运动位置信息抽取运动参数\n",
    "mean_frame_rate = np.median(1/np.diff(df_motion.Time.values))\n",
    "print(np.argmin(np.diff(df_motion.Time.values)))\n",
    "df_motion_als = Sliding_CTX_calation(df_motion, Pos_CTX_vec, hlf_spd_inv, hlf_agl_spd_inv, hlf_agl_inv,\n",
    "                                    window_size=100, frame_rate=mean_frame_rate,X_shift=x_shift)\n",
    "\n",
    "\n",
    "# 步骤二： 提取视频帧（根据中线处理结果只保留可用帧）对应的运动参数，输出对齐视频可用帧时间后的运动参数文件\n",
    "df_motion_pt_sorted = df_motion_als.sort_values('Time')  # 确保 df_motion_pt 也是按时间升序\n",
    "df_t = pd.DataFrame({'Time': t_c})\n",
    "df_t = df_t.sort_values('Time')  # merge_asof 要求升序\n",
    "df_motion_pt_sorted = df_motion_pt_sorted.rename(columns={'Time': 'Stage_time'})\n",
    "# 使用 merge_asof 匹配最近的时间点\n",
    "df_matched = pd.merge_asof(\n",
    "    df_t,\n",
    "    df_motion_pt_sorted,\n",
    "    left_on='Time',\n",
    "    right_on='Stage_time',\n",
    "    direction='nearest'  # 可选：'backward', 'forward', or 'nearest'\n",
    ")\n",
    "\n",
    "# 步骤三：加入condition\n",
    "folder_name = os.path.basename(os.path.normpath(p_f))\n",
    "df_matched = add_condition_info(folder_name, df_matched)\n",
    "# 重置中线位置\n",
    "df_matched['Disp_to_mid'] = df_matched['X']-half_width\n",
    "# 保存合并运动参数和视频帧对应时间戳的df数据\n",
    "df_matched.to_csv(os.path.join(p_f,basename+ '_mot_vid.csv'), index=False)\n",
    "'''文件长度与视频帧数相同'''\n",
    "\n",
    "# 步骤四:合并中线数据\n",
    "if midline_extract:\n",
    "\n",
    "    # 整理choose帧\n",
    "    choose_frame = get_choose_frame(data, data_keys, data_iou)\n",
    "    df_choose = pd.DataFrame(choose_frame, columns=['key'])\n",
    "    df_choose.loc[:,'choose_frame'] = int(1)\n",
    "    df_choose = df_choose.set_index('key')\n",
    "\n",
    "    rows = []\n",
    "    for key in data_keys:\n",
    "        item = data[key]\n",
    "        row = {\n",
    "            'key': key,   # 对应视频帧\n",
    "            'angle_m': item['angle_m'],  # 头部朝向与运动方向夹角绝对值\n",
    "            'angle_md': item['angle_md'],  # 头部朝向与运动方向夹角\n",
    "            'all_paths':item['all_paths'],  # 完整的骨架信息\n",
    "            'closest_idx':item['closest path'], # 最近的骨架id\n",
    "        }\n",
    "        rows.append(row)\n",
    "    # 构建 DataFrame\n",
    "    df_summary = pd.DataFrame(rows).set_index('key')\n",
    "    # 保留所有的处理后的帧信息\n",
    "    df_merged = df_matched.join(df_summary, how='left')\n",
    "\n",
    "    # 保存筛选帧信息：哪些中线的置信度高于阈值\n",
    "    df_merged = df_merged.join(df_choose, how='left')   # 根据index合并，df_choose里没有的填none\n",
    "\n",
    "    # 中线处理，计算turn\n",
    "    df_turn_curv = get_omega_turn_curvature(midline_path, path_ratio_uplim = 1.5, path_uplim=200, dtheta_lim=220,\n",
    "                              cl_turn_size = 50, op_turn_size = 50, visualize_turn=True,\n",
    "                              seg_pixel_step = 13, agl_window = 300, frame_rate=38)\n",
    "    df_merged_2 = df_merged.join(df_turn_curv, how='left')\n",
    "\n",
    "    df_merged_2.to_csv(os.path.join(p_f,basename+ '_mot_vid_mid.csv'), index=False)\n",
    "    '''文件仍然与视频长度相同，包含所有中线处理信息以及筛选帧信息'''\n",
    "\n",
    "# 步骤五：根据激光开始和结束时间截取荧光拍摄部分的运动数据/时间戳\n",
    "t_frame, t_start, t_stop = get_laser_on_and_off(s_data)\n",
    "track_start_index = np.searchsorted(df_matched.Time.values, t_start) - 1   # 截取激光照射段的载物台数据时间戳\n",
    "track_end_index = np.searchsorted(df_matched.Time.values, t_stop)\n",
    "df_matched_cut = df_matched.loc[track_start_index:track_end_index, :]\n",
    "df_vol_time = pd.DataFrame(t_frame, columns=['Vol_Time'])   # 激光照射时间戳要转换单位为s\n",
    "stage_file = os.path.join(p_f, f's{0+1}.txt')\n",
    "vol_file = os.path.join(p_f, f't{0+1}.txt')\n",
    "np.savetxt(stage_file, df_matched_cut[['Time','X_org','Y_org']], fmt='%.4f')  # 存储载物台数据(时间戳是视频帧的)\n",
    "np.savetxt(vol_file, t_frame, fmt='%.4f')  # 存储荧光每一个volume的数据\n",
    "df_matched_cut.to_csv(os.path.join(p_f, basename+'_mot_vid_cut.csv'), index = False)\n",
    "if midline_extract:\n",
    "    df_mot_midline_cut = df_merged_2.loc[track_start_index:track_end_index, :]\n",
    "    df_mot_midline_cut.to_csv(os.path.join(p_f, basename+'_mot_midline_cut.csv'), index = False)\n",
    "\n",
    "# 步骤六：根据荧光数据时间戳提取对应的运动参数，便于后续合并荧光数据\n",
    "# 如果有中线数据，就用带中线数据的对齐。否则只用运动参数对齐\n",
    "if midline_extract:\n",
    "    df_mat_cut = df_mot_midline_cut.copy()\n",
    "    print('有中线数据, 与Volume对齐的运动和中线数据')\n",
    "else:\n",
    "    df_mat_cut = df_matched_cut.copy()\n",
    "    print('没有中线数据, 输出与Volume时间对齐的运动参数')\n",
    "\n",
    "df_vol_time = get_nearest_value(df_mat_cut, df_vol_time, col_1 = 'Time', col_2 = 'Vol_Time', ind_col = 'Nearest_Index', col1_copy = 'Nearest_Time')\n",
    "# 将df_motionz中的运动参数(有中线加上中线)按照索引对应到视频帧文件的时间戳上\n",
    "columns_to_add = df_mat_cut.columns\n",
    "for col in columns_to_add:\n",
    "    df_vol_time[col] = df_mat_cut.iloc[df_vol_time['Nearest_Index'].values][col].values\n",
    "if midline_extract:\n",
    "    fn_motion_output = folder_name+'_MotionMidlineMatchVol.csv'\n",
    "else:\n",
    "    fn_motion_output = folder_name+'_MotionMatchVol.csv'\n",
    "df_vol_time.to_csv(os.path.join(p_f, fn_motion_output), index = False)\n",
    "print(f'写出与神经数据时间戳(不包含钙数据)对应的运动参数文件到:{folder_name}/{fn_motion_output}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
